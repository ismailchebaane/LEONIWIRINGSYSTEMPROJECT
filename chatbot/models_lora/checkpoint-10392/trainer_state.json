{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 10392,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002886836027713626,
      "grad_norm": 2.7018702030181885,
      "learning_rate": 0.0001998267898383372,
      "loss": 4.0151,
      "step": 10
    },
    {
      "epoch": 0.005773672055427252,
      "grad_norm": 6.049013614654541,
      "learning_rate": 0.0001996343341031563,
      "loss": 3.188,
      "step": 20
    },
    {
      "epoch": 0.008660508083140877,
      "grad_norm": 5.78230619430542,
      "learning_rate": 0.00019944187836797538,
      "loss": 2.4523,
      "step": 30
    },
    {
      "epoch": 0.011547344110854504,
      "grad_norm": 11.069697380065918,
      "learning_rate": 0.00019924942263279446,
      "loss": 2.0629,
      "step": 40
    },
    {
      "epoch": 0.014434180138568129,
      "grad_norm": 5.956721305847168,
      "learning_rate": 0.00019905696689761354,
      "loss": 1.633,
      "step": 50
    },
    {
      "epoch": 0.017321016166281754,
      "grad_norm": 9.173463821411133,
      "learning_rate": 0.00019886451116243265,
      "loss": 1.4344,
      "step": 60
    },
    {
      "epoch": 0.02020785219399538,
      "grad_norm": 10.049041748046875,
      "learning_rate": 0.00019867205542725173,
      "loss": 1.3517,
      "step": 70
    },
    {
      "epoch": 0.023094688221709007,
      "grad_norm": 10.721363067626953,
      "learning_rate": 0.00019847959969207084,
      "loss": 0.983,
      "step": 80
    },
    {
      "epoch": 0.025981524249422634,
      "grad_norm": 6.552972316741943,
      "learning_rate": 0.00019828714395688993,
      "loss": 0.9977,
      "step": 90
    },
    {
      "epoch": 0.028868360277136258,
      "grad_norm": 11.090863227844238,
      "learning_rate": 0.00019809468822170904,
      "loss": 0.7565,
      "step": 100
    },
    {
      "epoch": 0.03175519630484989,
      "grad_norm": 8.563178062438965,
      "learning_rate": 0.0001979022324865281,
      "loss": 0.862,
      "step": 110
    },
    {
      "epoch": 0.03464203233256351,
      "grad_norm": 6.624080181121826,
      "learning_rate": 0.0001977097767513472,
      "loss": 1.0582,
      "step": 120
    },
    {
      "epoch": 0.037528868360277134,
      "grad_norm": 9.719734191894531,
      "learning_rate": 0.00019751732101616629,
      "loss": 1.0948,
      "step": 130
    },
    {
      "epoch": 0.04041570438799076,
      "grad_norm": 11.171159744262695,
      "learning_rate": 0.0001973248652809854,
      "loss": 0.6717,
      "step": 140
    },
    {
      "epoch": 0.04330254041570439,
      "grad_norm": 9.98768138885498,
      "learning_rate": 0.00019713240954580448,
      "loss": 0.8305,
      "step": 150
    },
    {
      "epoch": 0.046189376443418015,
      "grad_norm": 7.504433631896973,
      "learning_rate": 0.00019693995381062356,
      "loss": 0.844,
      "step": 160
    },
    {
      "epoch": 0.04907621247113164,
      "grad_norm": 9.462844848632812,
      "learning_rate": 0.00019674749807544267,
      "loss": 0.7516,
      "step": 170
    },
    {
      "epoch": 0.05196304849884527,
      "grad_norm": 10.606456756591797,
      "learning_rate": 0.00019655504234026175,
      "loss": 0.655,
      "step": 180
    },
    {
      "epoch": 0.05484988452655889,
      "grad_norm": 5.414616584777832,
      "learning_rate": 0.00019636258660508084,
      "loss": 0.6113,
      "step": 190
    },
    {
      "epoch": 0.057736720554272515,
      "grad_norm": 8.162571907043457,
      "learning_rate": 0.00019617013086989992,
      "loss": 0.5475,
      "step": 200
    },
    {
      "epoch": 0.06062355658198614,
      "grad_norm": 14.099186897277832,
      "learning_rate": 0.00019597767513471903,
      "loss": 0.7858,
      "step": 210
    },
    {
      "epoch": 0.06351039260969978,
      "grad_norm": 10.377666473388672,
      "learning_rate": 0.0001957852193995381,
      "loss": 0.8815,
      "step": 220
    },
    {
      "epoch": 0.06639722863741339,
      "grad_norm": 8.767287254333496,
      "learning_rate": 0.00019559276366435722,
      "loss": 0.6019,
      "step": 230
    },
    {
      "epoch": 0.06928406466512702,
      "grad_norm": 5.939415454864502,
      "learning_rate": 0.0001954003079291763,
      "loss": 0.5702,
      "step": 240
    },
    {
      "epoch": 0.07217090069284064,
      "grad_norm": 6.64100980758667,
      "learning_rate": 0.0001952078521939954,
      "loss": 0.6947,
      "step": 250
    },
    {
      "epoch": 0.07505773672055427,
      "grad_norm": 7.6178998947143555,
      "learning_rate": 0.00019501539645881447,
      "loss": 0.611,
      "step": 260
    },
    {
      "epoch": 0.0779445727482679,
      "grad_norm": 9.593283653259277,
      "learning_rate": 0.00019482294072363358,
      "loss": 0.4289,
      "step": 270
    },
    {
      "epoch": 0.08083140877598152,
      "grad_norm": 15.629652976989746,
      "learning_rate": 0.00019463048498845266,
      "loss": 0.4157,
      "step": 280
    },
    {
      "epoch": 0.08371824480369515,
      "grad_norm": 7.30057430267334,
      "learning_rate": 0.00019443802925327175,
      "loss": 0.4291,
      "step": 290
    },
    {
      "epoch": 0.08660508083140878,
      "grad_norm": 16.251903533935547,
      "learning_rate": 0.00019424557351809086,
      "loss": 0.5854,
      "step": 300
    },
    {
      "epoch": 0.0894919168591224,
      "grad_norm": 4.354030609130859,
      "learning_rate": 0.00019405311778290994,
      "loss": 0.7304,
      "step": 310
    },
    {
      "epoch": 0.09237875288683603,
      "grad_norm": 13.061318397521973,
      "learning_rate": 0.00019386066204772905,
      "loss": 0.6189,
      "step": 320
    },
    {
      "epoch": 0.09526558891454966,
      "grad_norm": 6.76999568939209,
      "learning_rate": 0.00019366820631254813,
      "loss": 0.4631,
      "step": 330
    },
    {
      "epoch": 0.09815242494226328,
      "grad_norm": 7.221827030181885,
      "learning_rate": 0.0001934757505773672,
      "loss": 0.6144,
      "step": 340
    },
    {
      "epoch": 0.10103926096997691,
      "grad_norm": 8.125635147094727,
      "learning_rate": 0.0001932832948421863,
      "loss": 0.4451,
      "step": 350
    },
    {
      "epoch": 0.10392609699769054,
      "grad_norm": 9.751824378967285,
      "learning_rate": 0.0001930908391070054,
      "loss": 0.8055,
      "step": 360
    },
    {
      "epoch": 0.10681293302540416,
      "grad_norm": 5.630887985229492,
      "learning_rate": 0.0001928983833718245,
      "loss": 0.4458,
      "step": 370
    },
    {
      "epoch": 0.10969976905311778,
      "grad_norm": 11.015256881713867,
      "learning_rate": 0.0001927059276366436,
      "loss": 0.3477,
      "step": 380
    },
    {
      "epoch": 0.1125866050808314,
      "grad_norm": 6.174545764923096,
      "learning_rate": 0.00019251347190146268,
      "loss": 0.6209,
      "step": 390
    },
    {
      "epoch": 0.11547344110854503,
      "grad_norm": 9.540754318237305,
      "learning_rate": 0.00019232101616628176,
      "loss": 0.5763,
      "step": 400
    },
    {
      "epoch": 0.11836027713625866,
      "grad_norm": 2.8325271606445312,
      "learning_rate": 0.00019212856043110085,
      "loss": 0.7454,
      "step": 410
    },
    {
      "epoch": 0.12124711316397228,
      "grad_norm": 5.165116310119629,
      "learning_rate": 0.00019193610469591993,
      "loss": 0.9094,
      "step": 420
    },
    {
      "epoch": 0.12413394919168591,
      "grad_norm": 3.6549150943756104,
      "learning_rate": 0.00019174364896073904,
      "loss": 0.4459,
      "step": 430
    },
    {
      "epoch": 0.12702078521939955,
      "grad_norm": 11.987074851989746,
      "learning_rate": 0.00019155119322555812,
      "loss": 0.3635,
      "step": 440
    },
    {
      "epoch": 0.12990762124711316,
      "grad_norm": 3.3325982093811035,
      "learning_rate": 0.00019135873749037723,
      "loss": 0.4534,
      "step": 450
    },
    {
      "epoch": 0.13279445727482678,
      "grad_norm": 3.8659722805023193,
      "learning_rate": 0.00019116628175519631,
      "loss": 0.419,
      "step": 460
    },
    {
      "epoch": 0.13568129330254042,
      "grad_norm": 6.529635429382324,
      "learning_rate": 0.00019097382602001542,
      "loss": 0.66,
      "step": 470
    },
    {
      "epoch": 0.13856812933025403,
      "grad_norm": 3.7590560913085938,
      "learning_rate": 0.00019078137028483448,
      "loss": 0.5044,
      "step": 480
    },
    {
      "epoch": 0.14145496535796767,
      "grad_norm": 3.4456100463867188,
      "learning_rate": 0.0001905889145496536,
      "loss": 0.3727,
      "step": 490
    },
    {
      "epoch": 0.14434180138568128,
      "grad_norm": 6.374202251434326,
      "learning_rate": 0.00019039645881447267,
      "loss": 0.5569,
      "step": 500
    },
    {
      "epoch": 0.14722863741339492,
      "grad_norm": 6.867483139038086,
      "learning_rate": 0.00019020400307929178,
      "loss": 0.3949,
      "step": 510
    },
    {
      "epoch": 0.15011547344110854,
      "grad_norm": 3.377674102783203,
      "learning_rate": 0.00019001154734411087,
      "loss": 0.3581,
      "step": 520
    },
    {
      "epoch": 0.15300230946882218,
      "grad_norm": 9.9343843460083,
      "learning_rate": 0.00018981909160892995,
      "loss": 0.5896,
      "step": 530
    },
    {
      "epoch": 0.1558891454965358,
      "grad_norm": 12.620224952697754,
      "learning_rate": 0.00018962663587374906,
      "loss": 0.541,
      "step": 540
    },
    {
      "epoch": 0.15877598152424943,
      "grad_norm": 3.5905938148498535,
      "learning_rate": 0.00018943418013856814,
      "loss": 0.2595,
      "step": 550
    },
    {
      "epoch": 0.16166281755196305,
      "grad_norm": 1.7162877321243286,
      "learning_rate": 0.00018924172440338722,
      "loss": 0.4853,
      "step": 560
    },
    {
      "epoch": 0.16454965357967669,
      "grad_norm": 9.974888801574707,
      "learning_rate": 0.0001890492686682063,
      "loss": 0.7851,
      "step": 570
    },
    {
      "epoch": 0.1674364896073903,
      "grad_norm": 1.4078313112258911,
      "learning_rate": 0.00018885681293302542,
      "loss": 0.3673,
      "step": 580
    },
    {
      "epoch": 0.17032332563510394,
      "grad_norm": 10.632586479187012,
      "learning_rate": 0.0001886643571978445,
      "loss": 0.4259,
      "step": 590
    },
    {
      "epoch": 0.17321016166281755,
      "grad_norm": 11.412195205688477,
      "learning_rate": 0.0001884719014626636,
      "loss": 0.3784,
      "step": 600
    },
    {
      "epoch": 0.17609699769053117,
      "grad_norm": 2.328176498413086,
      "learning_rate": 0.0001882794457274827,
      "loss": 0.5459,
      "step": 610
    },
    {
      "epoch": 0.1789838337182448,
      "grad_norm": 6.369441032409668,
      "learning_rate": 0.00018808698999230177,
      "loss": 0.3074,
      "step": 620
    },
    {
      "epoch": 0.18187066974595842,
      "grad_norm": 2.4764273166656494,
      "learning_rate": 0.00018789453425712086,
      "loss": 0.4176,
      "step": 630
    },
    {
      "epoch": 0.18475750577367206,
      "grad_norm": 6.229452133178711,
      "learning_rate": 0.00018770207852193997,
      "loss": 0.775,
      "step": 640
    },
    {
      "epoch": 0.18764434180138567,
      "grad_norm": 10.776385307312012,
      "learning_rate": 0.00018750962278675905,
      "loss": 0.3256,
      "step": 650
    },
    {
      "epoch": 0.1905311778290993,
      "grad_norm": 5.9808502197265625,
      "learning_rate": 0.00018731716705157813,
      "loss": 0.3305,
      "step": 660
    },
    {
      "epoch": 0.19341801385681293,
      "grad_norm": 1.59312903881073,
      "learning_rate": 0.00018712471131639724,
      "loss": 0.3054,
      "step": 670
    },
    {
      "epoch": 0.19630484988452657,
      "grad_norm": 19.27507209777832,
      "learning_rate": 0.00018693225558121633,
      "loss": 0.4931,
      "step": 680
    },
    {
      "epoch": 0.19919168591224018,
      "grad_norm": 11.377371788024902,
      "learning_rate": 0.00018673979984603544,
      "loss": 0.795,
      "step": 690
    },
    {
      "epoch": 0.20207852193995382,
      "grad_norm": 5.303111553192139,
      "learning_rate": 0.00018654734411085452,
      "loss": 0.343,
      "step": 700
    },
    {
      "epoch": 0.20496535796766743,
      "grad_norm": 5.982418537139893,
      "learning_rate": 0.0001863548883756736,
      "loss": 0.2485,
      "step": 710
    },
    {
      "epoch": 0.20785219399538107,
      "grad_norm": 11.31412410736084,
      "learning_rate": 0.00018616243264049268,
      "loss": 0.3536,
      "step": 720
    },
    {
      "epoch": 0.2107390300230947,
      "grad_norm": 6.579715728759766,
      "learning_rate": 0.0001859699769053118,
      "loss": 0.3131,
      "step": 730
    },
    {
      "epoch": 0.21362586605080833,
      "grad_norm": 5.95587158203125,
      "learning_rate": 0.00018577752117013088,
      "loss": 0.4299,
      "step": 740
    },
    {
      "epoch": 0.21651270207852194,
      "grad_norm": 17.047517776489258,
      "learning_rate": 0.00018558506543494999,
      "loss": 0.4993,
      "step": 750
    },
    {
      "epoch": 0.21939953810623555,
      "grad_norm": 2.0757362842559814,
      "learning_rate": 0.00018539260969976907,
      "loss": 0.2191,
      "step": 760
    },
    {
      "epoch": 0.2222863741339492,
      "grad_norm": 2.3716704845428467,
      "learning_rate": 0.00018520015396458815,
      "loss": 0.3196,
      "step": 770
    },
    {
      "epoch": 0.2251732101616628,
      "grad_norm": 8.084259033203125,
      "learning_rate": 0.00018500769822940723,
      "loss": 0.364,
      "step": 780
    },
    {
      "epoch": 0.22806004618937645,
      "grad_norm": 6.034940242767334,
      "learning_rate": 0.00018481524249422632,
      "loss": 0.1963,
      "step": 790
    },
    {
      "epoch": 0.23094688221709006,
      "grad_norm": 2.3532559871673584,
      "learning_rate": 0.00018462278675904543,
      "loss": 0.3895,
      "step": 800
    },
    {
      "epoch": 0.2338337182448037,
      "grad_norm": 4.136029243469238,
      "learning_rate": 0.0001844303310238645,
      "loss": 0.2174,
      "step": 810
    },
    {
      "epoch": 0.23672055427251731,
      "grad_norm": 4.709914684295654,
      "learning_rate": 0.00018423787528868362,
      "loss": 0.2417,
      "step": 820
    },
    {
      "epoch": 0.23960739030023095,
      "grad_norm": 10.071259498596191,
      "learning_rate": 0.0001840454195535027,
      "loss": 0.3563,
      "step": 830
    },
    {
      "epoch": 0.24249422632794457,
      "grad_norm": 6.006901264190674,
      "learning_rate": 0.0001838529638183218,
      "loss": 0.477,
      "step": 840
    },
    {
      "epoch": 0.2453810623556582,
      "grad_norm": 2.361210823059082,
      "learning_rate": 0.00018366050808314087,
      "loss": 0.2585,
      "step": 850
    },
    {
      "epoch": 0.24826789838337182,
      "grad_norm": 2.257328748703003,
      "learning_rate": 0.00018346805234795998,
      "loss": 0.275,
      "step": 860
    },
    {
      "epoch": 0.25115473441108543,
      "grad_norm": 4.5259904861450195,
      "learning_rate": 0.00018327559661277906,
      "loss": 0.894,
      "step": 870
    },
    {
      "epoch": 0.2540415704387991,
      "grad_norm": 4.087200164794922,
      "learning_rate": 0.00018308314087759817,
      "loss": 0.2773,
      "step": 880
    },
    {
      "epoch": 0.2569284064665127,
      "grad_norm": 7.469672679901123,
      "learning_rate": 0.00018289068514241725,
      "loss": 0.3698,
      "step": 890
    },
    {
      "epoch": 0.25981524249422633,
      "grad_norm": 5.329986572265625,
      "learning_rate": 0.00018269822940723636,
      "loss": 0.2875,
      "step": 900
    },
    {
      "epoch": 0.26270207852193994,
      "grad_norm": 3.77105450630188,
      "learning_rate": 0.00018250577367205545,
      "loss": 0.219,
      "step": 910
    },
    {
      "epoch": 0.26558891454965355,
      "grad_norm": 11.049495697021484,
      "learning_rate": 0.00018231331793687453,
      "loss": 0.4128,
      "step": 920
    },
    {
      "epoch": 0.2684757505773672,
      "grad_norm": 4.127928733825684,
      "learning_rate": 0.0001821208622016936,
      "loss": 0.5074,
      "step": 930
    },
    {
      "epoch": 0.27136258660508084,
      "grad_norm": 1.6134694814682007,
      "learning_rate": 0.0001819284064665127,
      "loss": 0.3203,
      "step": 940
    },
    {
      "epoch": 0.27424942263279445,
      "grad_norm": 14.927350997924805,
      "learning_rate": 0.0001817359507313318,
      "loss": 0.6969,
      "step": 950
    },
    {
      "epoch": 0.27713625866050806,
      "grad_norm": 3.870356798171997,
      "learning_rate": 0.00018154349499615089,
      "loss": 0.2381,
      "step": 960
    },
    {
      "epoch": 0.28002309468822173,
      "grad_norm": 7.777241230010986,
      "learning_rate": 0.00018135103926097,
      "loss": 0.1926,
      "step": 970
    },
    {
      "epoch": 0.28290993071593534,
      "grad_norm": 2.4854438304901123,
      "learning_rate": 0.00018115858352578908,
      "loss": 0.3485,
      "step": 980
    },
    {
      "epoch": 0.28579676674364896,
      "grad_norm": 5.941676139831543,
      "learning_rate": 0.0001809661277906082,
      "loss": 0.2882,
      "step": 990
    },
    {
      "epoch": 0.28868360277136257,
      "grad_norm": 2.6469006538391113,
      "learning_rate": 0.00018077367205542724,
      "loss": 0.5407,
      "step": 1000
    },
    {
      "epoch": 0.29157043879907624,
      "grad_norm": 6.830310344696045,
      "learning_rate": 0.00018058121632024635,
      "loss": 0.3962,
      "step": 1010
    },
    {
      "epoch": 0.29445727482678985,
      "grad_norm": 4.560817241668701,
      "learning_rate": 0.00018038876058506544,
      "loss": 0.2228,
      "step": 1020
    },
    {
      "epoch": 0.29734411085450346,
      "grad_norm": 2.3411197662353516,
      "learning_rate": 0.00018019630484988455,
      "loss": 0.377,
      "step": 1030
    },
    {
      "epoch": 0.3002309468822171,
      "grad_norm": 4.143499374389648,
      "learning_rate": 0.00018000384911470363,
      "loss": 0.2824,
      "step": 1040
    },
    {
      "epoch": 0.3031177829099307,
      "grad_norm": 1.2314907312393188,
      "learning_rate": 0.0001798113933795227,
      "loss": 0.1769,
      "step": 1050
    },
    {
      "epoch": 0.30600461893764436,
      "grad_norm": 4.70513916015625,
      "learning_rate": 0.00017961893764434182,
      "loss": 0.5102,
      "step": 1060
    },
    {
      "epoch": 0.30889145496535797,
      "grad_norm": 4.0509796142578125,
      "learning_rate": 0.0001794264819091609,
      "loss": 0.3937,
      "step": 1070
    },
    {
      "epoch": 0.3117782909930716,
      "grad_norm": 6.126905918121338,
      "learning_rate": 0.00017923402617398,
      "loss": 0.2947,
      "step": 1080
    },
    {
      "epoch": 0.3146651270207852,
      "grad_norm": 5.73443078994751,
      "learning_rate": 0.00017904157043879907,
      "loss": 0.3471,
      "step": 1090
    },
    {
      "epoch": 0.31755196304849886,
      "grad_norm": 3.408724308013916,
      "learning_rate": 0.00017884911470361818,
      "loss": 0.2156,
      "step": 1100
    },
    {
      "epoch": 0.3204387990762125,
      "grad_norm": 2.2277238368988037,
      "learning_rate": 0.00017865665896843726,
      "loss": 0.1876,
      "step": 1110
    },
    {
      "epoch": 0.3233256351039261,
      "grad_norm": 1.3994511365890503,
      "learning_rate": 0.00017846420323325637,
      "loss": 0.2791,
      "step": 1120
    },
    {
      "epoch": 0.3262124711316397,
      "grad_norm": 2.0929174423217773,
      "learning_rate": 0.00017827174749807546,
      "loss": 0.1963,
      "step": 1130
    },
    {
      "epoch": 0.32909930715935337,
      "grad_norm": 16.5125789642334,
      "learning_rate": 0.00017807929176289454,
      "loss": 0.3055,
      "step": 1140
    },
    {
      "epoch": 0.331986143187067,
      "grad_norm": 2.072423219680786,
      "learning_rate": 0.00017788683602771362,
      "loss": 0.2463,
      "step": 1150
    },
    {
      "epoch": 0.3348729792147806,
      "grad_norm": 1.257587194442749,
      "learning_rate": 0.00017769438029253273,
      "loss": 0.2916,
      "step": 1160
    },
    {
      "epoch": 0.3377598152424942,
      "grad_norm": 1.2033694982528687,
      "learning_rate": 0.00017750192455735181,
      "loss": 0.2915,
      "step": 1170
    },
    {
      "epoch": 0.3406466512702079,
      "grad_norm": 1.6318583488464355,
      "learning_rate": 0.0001773094688221709,
      "loss": 0.227,
      "step": 1180
    },
    {
      "epoch": 0.3435334872979215,
      "grad_norm": 1.9818540811538696,
      "learning_rate": 0.00017711701308699,
      "loss": 0.6325,
      "step": 1190
    },
    {
      "epoch": 0.3464203233256351,
      "grad_norm": 3.9780163764953613,
      "learning_rate": 0.0001769245573518091,
      "loss": 0.3216,
      "step": 1200
    },
    {
      "epoch": 0.3493071593533487,
      "grad_norm": 1.8839960098266602,
      "learning_rate": 0.0001767321016166282,
      "loss": 0.4989,
      "step": 1210
    },
    {
      "epoch": 0.35219399538106233,
      "grad_norm": 3.327327251434326,
      "learning_rate": 0.00017653964588144728,
      "loss": 0.2444,
      "step": 1220
    },
    {
      "epoch": 0.355080831408776,
      "grad_norm": 1.1906715631484985,
      "learning_rate": 0.00017634719014626636,
      "loss": 0.5045,
      "step": 1230
    },
    {
      "epoch": 0.3579676674364896,
      "grad_norm": 6.069880962371826,
      "learning_rate": 0.00017615473441108545,
      "loss": 0.3666,
      "step": 1240
    },
    {
      "epoch": 0.3608545034642032,
      "grad_norm": 3.7953360080718994,
      "learning_rate": 0.00017596227867590456,
      "loss": 0.3437,
      "step": 1250
    },
    {
      "epoch": 0.36374133949191684,
      "grad_norm": 3.46012020111084,
      "learning_rate": 0.00017576982294072364,
      "loss": 0.4107,
      "step": 1260
    },
    {
      "epoch": 0.3666281755196305,
      "grad_norm": 14.802206039428711,
      "learning_rate": 0.00017557736720554275,
      "loss": 0.4727,
      "step": 1270
    },
    {
      "epoch": 0.3695150115473441,
      "grad_norm": 2.2588560581207275,
      "learning_rate": 0.00017538491147036183,
      "loss": 0.2859,
      "step": 1280
    },
    {
      "epoch": 0.37240184757505773,
      "grad_norm": 3.733863115310669,
      "learning_rate": 0.00017519245573518092,
      "loss": 0.1827,
      "step": 1290
    },
    {
      "epoch": 0.37528868360277134,
      "grad_norm": 2.0324418544769287,
      "learning_rate": 0.000175,
      "loss": 0.4302,
      "step": 1300
    },
    {
      "epoch": 0.378175519630485,
      "grad_norm": 1.9052653312683105,
      "learning_rate": 0.00017480754426481908,
      "loss": 0.2987,
      "step": 1310
    },
    {
      "epoch": 0.3810623556581986,
      "grad_norm": 0.7858559489250183,
      "learning_rate": 0.0001746150885296382,
      "loss": 0.1901,
      "step": 1320
    },
    {
      "epoch": 0.38394919168591224,
      "grad_norm": 2.2024643421173096,
      "learning_rate": 0.00017442263279445727,
      "loss": 0.4752,
      "step": 1330
    },
    {
      "epoch": 0.38683602771362585,
      "grad_norm": 1.529282569885254,
      "learning_rate": 0.00017423017705927638,
      "loss": 0.6554,
      "step": 1340
    },
    {
      "epoch": 0.38972286374133946,
      "grad_norm": 0.9101992249488831,
      "learning_rate": 0.00017403772132409547,
      "loss": 0.2662,
      "step": 1350
    },
    {
      "epoch": 0.39260969976905313,
      "grad_norm": 2.488591432571411,
      "learning_rate": 0.00017384526558891458,
      "loss": 0.4131,
      "step": 1360
    },
    {
      "epoch": 0.39549653579676675,
      "grad_norm": 2.223397731781006,
      "learning_rate": 0.00017365280985373363,
      "loss": 0.4078,
      "step": 1370
    },
    {
      "epoch": 0.39838337182448036,
      "grad_norm": 1.0490058660507202,
      "learning_rate": 0.00017346035411855274,
      "loss": 0.1886,
      "step": 1380
    },
    {
      "epoch": 0.40127020785219397,
      "grad_norm": 1.0217317342758179,
      "learning_rate": 0.00017326789838337182,
      "loss": 0.2354,
      "step": 1390
    },
    {
      "epoch": 0.40415704387990764,
      "grad_norm": 3.4150266647338867,
      "learning_rate": 0.00017307544264819093,
      "loss": 0.2073,
      "step": 1400
    },
    {
      "epoch": 0.40704387990762125,
      "grad_norm": 6.227571487426758,
      "learning_rate": 0.00017288298691301002,
      "loss": 0.2527,
      "step": 1410
    },
    {
      "epoch": 0.40993071593533487,
      "grad_norm": 8.41363525390625,
      "learning_rate": 0.00017269053117782913,
      "loss": 0.3661,
      "step": 1420
    },
    {
      "epoch": 0.4128175519630485,
      "grad_norm": 11.701786041259766,
      "learning_rate": 0.0001724980754426482,
      "loss": 0.1747,
      "step": 1430
    },
    {
      "epoch": 0.41570438799076215,
      "grad_norm": 17.799118041992188,
      "learning_rate": 0.0001723056197074673,
      "loss": 0.4702,
      "step": 1440
    },
    {
      "epoch": 0.41859122401847576,
      "grad_norm": 3.531705617904663,
      "learning_rate": 0.00017211316397228638,
      "loss": 0.4168,
      "step": 1450
    },
    {
      "epoch": 0.4214780600461894,
      "grad_norm": 6.91137170791626,
      "learning_rate": 0.00017192070823710546,
      "loss": 0.3602,
      "step": 1460
    },
    {
      "epoch": 0.424364896073903,
      "grad_norm": 17.463884353637695,
      "learning_rate": 0.00017172825250192457,
      "loss": 0.3445,
      "step": 1470
    },
    {
      "epoch": 0.42725173210161665,
      "grad_norm": 6.326670169830322,
      "learning_rate": 0.00017153579676674365,
      "loss": 0.4204,
      "step": 1480
    },
    {
      "epoch": 0.43013856812933027,
      "grad_norm": 13.162899017333984,
      "learning_rate": 0.00017134334103156276,
      "loss": 0.4311,
      "step": 1490
    },
    {
      "epoch": 0.4330254041570439,
      "grad_norm": 12.803982734680176,
      "learning_rate": 0.00017115088529638184,
      "loss": 0.3704,
      "step": 1500
    },
    {
      "epoch": 0.4359122401847575,
      "grad_norm": 1.0562807321548462,
      "learning_rate": 0.00017095842956120093,
      "loss": 0.3705,
      "step": 1510
    },
    {
      "epoch": 0.4387990762124711,
      "grad_norm": 5.790314197540283,
      "learning_rate": 0.00017076597382602,
      "loss": 0.2412,
      "step": 1520
    },
    {
      "epoch": 0.4416859122401848,
      "grad_norm": 10.546730041503906,
      "learning_rate": 0.00017057351809083912,
      "loss": 0.2684,
      "step": 1530
    },
    {
      "epoch": 0.4445727482678984,
      "grad_norm": 2.2234156131744385,
      "learning_rate": 0.0001703810623556582,
      "loss": 0.5773,
      "step": 1540
    },
    {
      "epoch": 0.447459584295612,
      "grad_norm": 1.9510936737060547,
      "learning_rate": 0.0001701886066204773,
      "loss": 0.4691,
      "step": 1550
    },
    {
      "epoch": 0.4503464203233256,
      "grad_norm": 1.6664289236068726,
      "learning_rate": 0.0001699961508852964,
      "loss": 0.1738,
      "step": 1560
    },
    {
      "epoch": 0.4532332563510393,
      "grad_norm": 5.095754146575928,
      "learning_rate": 0.00016980369515011548,
      "loss": 0.2912,
      "step": 1570
    },
    {
      "epoch": 0.4561200923787529,
      "grad_norm": 2.52308988571167,
      "learning_rate": 0.0001696112394149346,
      "loss": 0.1906,
      "step": 1580
    },
    {
      "epoch": 0.4590069284064665,
      "grad_norm": 11.100685119628906,
      "learning_rate": 0.00016941878367975367,
      "loss": 0.4118,
      "step": 1590
    },
    {
      "epoch": 0.4618937644341801,
      "grad_norm": 1.8342015743255615,
      "learning_rate": 0.00016922632794457275,
      "loss": 0.2868,
      "step": 1600
    },
    {
      "epoch": 0.4647806004618938,
      "grad_norm": 2.821803331375122,
      "learning_rate": 0.00016903387220939183,
      "loss": 0.4208,
      "step": 1610
    },
    {
      "epoch": 0.4676674364896074,
      "grad_norm": 3.163102149963379,
      "learning_rate": 0.00016884141647421094,
      "loss": 0.3173,
      "step": 1620
    },
    {
      "epoch": 0.470554272517321,
      "grad_norm": 13.41313648223877,
      "learning_rate": 0.00016864896073903003,
      "loss": 0.3206,
      "step": 1630
    },
    {
      "epoch": 0.47344110854503463,
      "grad_norm": 1.7113779783248901,
      "learning_rate": 0.00016845650500384914,
      "loss": 0.2395,
      "step": 1640
    },
    {
      "epoch": 0.47632794457274824,
      "grad_norm": 1.9347248077392578,
      "learning_rate": 0.00016826404926866822,
      "loss": 0.3136,
      "step": 1650
    },
    {
      "epoch": 0.4792147806004619,
      "grad_norm": 0.7332725524902344,
      "learning_rate": 0.0001680715935334873,
      "loss": 0.1719,
      "step": 1660
    },
    {
      "epoch": 0.4821016166281755,
      "grad_norm": 6.395208358764648,
      "learning_rate": 0.00016787913779830639,
      "loss": 0.6093,
      "step": 1670
    },
    {
      "epoch": 0.48498845265588914,
      "grad_norm": 1.7642871141433716,
      "learning_rate": 0.0001676866820631255,
      "loss": 0.1557,
      "step": 1680
    },
    {
      "epoch": 0.48787528868360275,
      "grad_norm": 2.960660457611084,
      "learning_rate": 0.00016749422632794458,
      "loss": 0.268,
      "step": 1690
    },
    {
      "epoch": 0.4907621247113164,
      "grad_norm": 3.236741542816162,
      "learning_rate": 0.00016730177059276366,
      "loss": 0.3612,
      "step": 1700
    },
    {
      "epoch": 0.49364896073903003,
      "grad_norm": 4.678720951080322,
      "learning_rate": 0.00016710931485758277,
      "loss": 0.3782,
      "step": 1710
    },
    {
      "epoch": 0.49653579676674364,
      "grad_norm": 3.148599624633789,
      "learning_rate": 0.00016691685912240185,
      "loss": 0.2855,
      "step": 1720
    },
    {
      "epoch": 0.49942263279445726,
      "grad_norm": 2.5543487071990967,
      "learning_rate": 0.00016672440338722096,
      "loss": 0.3977,
      "step": 1730
    },
    {
      "epoch": 0.5023094688221709,
      "grad_norm": 1.7161895036697388,
      "learning_rate": 0.00016653194765204002,
      "loss": 0.3816,
      "step": 1740
    },
    {
      "epoch": 0.5051963048498845,
      "grad_norm": 2.113652467727661,
      "learning_rate": 0.00016633949191685913,
      "loss": 0.4163,
      "step": 1750
    },
    {
      "epoch": 0.5080831408775982,
      "grad_norm": 2.945525646209717,
      "learning_rate": 0.0001661470361816782,
      "loss": 0.3598,
      "step": 1760
    },
    {
      "epoch": 0.5109699769053118,
      "grad_norm": 0.731397807598114,
      "learning_rate": 0.00016595458044649732,
      "loss": 0.3964,
      "step": 1770
    },
    {
      "epoch": 0.5138568129330254,
      "grad_norm": 6.133610725402832,
      "learning_rate": 0.0001657621247113164,
      "loss": 0.392,
      "step": 1780
    },
    {
      "epoch": 0.516743648960739,
      "grad_norm": 2.3937618732452393,
      "learning_rate": 0.00016556966897613551,
      "loss": 0.3148,
      "step": 1790
    },
    {
      "epoch": 0.5196304849884527,
      "grad_norm": 9.488390922546387,
      "learning_rate": 0.0001653772132409546,
      "loss": 0.3845,
      "step": 1800
    },
    {
      "epoch": 0.5225173210161663,
      "grad_norm": 2.616244077682495,
      "learning_rate": 0.00016518475750577368,
      "loss": 0.2017,
      "step": 1810
    },
    {
      "epoch": 0.5254041570438799,
      "grad_norm": 1.1239122152328491,
      "learning_rate": 0.00016499230177059276,
      "loss": 0.3825,
      "step": 1820
    },
    {
      "epoch": 0.5282909930715936,
      "grad_norm": 3.8264076709747314,
      "learning_rate": 0.00016479984603541185,
      "loss": 0.4903,
      "step": 1830
    },
    {
      "epoch": 0.5311778290993071,
      "grad_norm": 1.3716259002685547,
      "learning_rate": 0.00016460739030023096,
      "loss": 0.1911,
      "step": 1840
    },
    {
      "epoch": 0.5340646651270208,
      "grad_norm": 0.9049236178398132,
      "learning_rate": 0.00016441493456505004,
      "loss": 0.2674,
      "step": 1850
    },
    {
      "epoch": 0.5369515011547344,
      "grad_norm": 2.421032190322876,
      "learning_rate": 0.00016422247882986915,
      "loss": 0.3005,
      "step": 1860
    },
    {
      "epoch": 0.539838337182448,
      "grad_norm": 0.9522075057029724,
      "learning_rate": 0.00016403002309468823,
      "loss": 0.2951,
      "step": 1870
    },
    {
      "epoch": 0.5427251732101617,
      "grad_norm": 6.950519561767578,
      "learning_rate": 0.00016383756735950734,
      "loss": 0.2858,
      "step": 1880
    },
    {
      "epoch": 0.5456120092378753,
      "grad_norm": 1.3004443645477295,
      "learning_rate": 0.0001636451116243264,
      "loss": 0.1849,
      "step": 1890
    },
    {
      "epoch": 0.5484988452655889,
      "grad_norm": 4.3394598960876465,
      "learning_rate": 0.0001634526558891455,
      "loss": 0.2711,
      "step": 1900
    },
    {
      "epoch": 0.5513856812933026,
      "grad_norm": 1.6677024364471436,
      "learning_rate": 0.0001632602001539646,
      "loss": 0.2466,
      "step": 1910
    },
    {
      "epoch": 0.5542725173210161,
      "grad_norm": 0.9917011260986328,
      "learning_rate": 0.0001630677444187837,
      "loss": 0.3654,
      "step": 1920
    },
    {
      "epoch": 0.5571593533487298,
      "grad_norm": 2.8531293869018555,
      "learning_rate": 0.00016287528868360278,
      "loss": 0.2172,
      "step": 1930
    },
    {
      "epoch": 0.5600461893764435,
      "grad_norm": 4.683776378631592,
      "learning_rate": 0.0001626828329484219,
      "loss": 0.3251,
      "step": 1940
    },
    {
      "epoch": 0.562933025404157,
      "grad_norm": 1.54999840259552,
      "learning_rate": 0.00016249037721324097,
      "loss": 0.2651,
      "step": 1950
    },
    {
      "epoch": 0.5658198614318707,
      "grad_norm": 1.8153835535049438,
      "learning_rate": 0.00016229792147806006,
      "loss": 0.2567,
      "step": 1960
    },
    {
      "epoch": 0.5687066974595842,
      "grad_norm": 12.297124862670898,
      "learning_rate": 0.00016210546574287914,
      "loss": 0.5075,
      "step": 1970
    },
    {
      "epoch": 0.5715935334872979,
      "grad_norm": 3.161565065383911,
      "learning_rate": 0.00016191301000769822,
      "loss": 0.2438,
      "step": 1980
    },
    {
      "epoch": 0.5744803695150116,
      "grad_norm": 2.0433285236358643,
      "learning_rate": 0.00016172055427251733,
      "loss": 0.1976,
      "step": 1990
    },
    {
      "epoch": 0.5773672055427251,
      "grad_norm": 1.781711459159851,
      "learning_rate": 0.00016152809853733641,
      "loss": 0.2989,
      "step": 2000
    },
    {
      "epoch": 0.5802540415704388,
      "grad_norm": 1.1750695705413818,
      "learning_rate": 0.00016133564280215552,
      "loss": 0.36,
      "step": 2010
    },
    {
      "epoch": 0.5831408775981525,
      "grad_norm": 9.565589904785156,
      "learning_rate": 0.0001611431870669746,
      "loss": 0.3863,
      "step": 2020
    },
    {
      "epoch": 0.586027713625866,
      "grad_norm": 4.169996738433838,
      "learning_rate": 0.0001609507313317937,
      "loss": 0.2506,
      "step": 2030
    },
    {
      "epoch": 0.5889145496535797,
      "grad_norm": 2.208012342453003,
      "learning_rate": 0.00016075827559661277,
      "loss": 0.4927,
      "step": 2040
    },
    {
      "epoch": 0.5918013856812933,
      "grad_norm": 9.77591323852539,
      "learning_rate": 0.00016056581986143188,
      "loss": 0.4622,
      "step": 2050
    },
    {
      "epoch": 0.5946882217090069,
      "grad_norm": 1.5039808750152588,
      "learning_rate": 0.00016037336412625097,
      "loss": 0.2062,
      "step": 2060
    },
    {
      "epoch": 0.5975750577367206,
      "grad_norm": 1.5056836605072021,
      "learning_rate": 0.00016018090839107008,
      "loss": 0.4564,
      "step": 2070
    },
    {
      "epoch": 0.6004618937644342,
      "grad_norm": 8.544675827026367,
      "learning_rate": 0.00015998845265588916,
      "loss": 0.317,
      "step": 2080
    },
    {
      "epoch": 0.6033487297921478,
      "grad_norm": 8.39321517944336,
      "learning_rate": 0.00015979599692070824,
      "loss": 0.2131,
      "step": 2090
    },
    {
      "epoch": 0.6062355658198614,
      "grad_norm": 2.172884702682495,
      "learning_rate": 0.00015960354118552735,
      "loss": 0.3186,
      "step": 2100
    },
    {
      "epoch": 0.609122401847575,
      "grad_norm": 1.5382304191589355,
      "learning_rate": 0.00015941108545034643,
      "loss": 0.206,
      "step": 2110
    },
    {
      "epoch": 0.6120092378752887,
      "grad_norm": 2.0428669452667236,
      "learning_rate": 0.00015921862971516552,
      "loss": 0.3552,
      "step": 2120
    },
    {
      "epoch": 0.6148960739030023,
      "grad_norm": 2.044952154159546,
      "learning_rate": 0.0001590261739799846,
      "loss": 0.4115,
      "step": 2130
    },
    {
      "epoch": 0.6177829099307159,
      "grad_norm": 1.2414518594741821,
      "learning_rate": 0.0001588337182448037,
      "loss": 0.2565,
      "step": 2140
    },
    {
      "epoch": 0.6206697459584296,
      "grad_norm": 5.611726760864258,
      "learning_rate": 0.0001586412625096228,
      "loss": 0.3126,
      "step": 2150
    },
    {
      "epoch": 0.6235565819861432,
      "grad_norm": 1.334958553314209,
      "learning_rate": 0.0001584488067744419,
      "loss": 0.2629,
      "step": 2160
    },
    {
      "epoch": 0.6264434180138568,
      "grad_norm": 0.917085587978363,
      "learning_rate": 0.00015825635103926098,
      "loss": 0.1981,
      "step": 2170
    },
    {
      "epoch": 0.6293302540415704,
      "grad_norm": 3.2142505645751953,
      "learning_rate": 0.00015806389530408007,
      "loss": 0.221,
      "step": 2180
    },
    {
      "epoch": 0.6322170900692841,
      "grad_norm": 0.985752522945404,
      "learning_rate": 0.00015787143956889915,
      "loss": 0.2121,
      "step": 2190
    },
    {
      "epoch": 0.6351039260969977,
      "grad_norm": 9.123259544372559,
      "learning_rate": 0.00015767898383371826,
      "loss": 0.3312,
      "step": 2200
    },
    {
      "epoch": 0.6379907621247113,
      "grad_norm": 1.9394207000732422,
      "learning_rate": 0.00015748652809853734,
      "loss": 0.3517,
      "step": 2210
    },
    {
      "epoch": 0.640877598152425,
      "grad_norm": 1.284178376197815,
      "learning_rate": 0.00015729407236335643,
      "loss": 0.3658,
      "step": 2220
    },
    {
      "epoch": 0.6437644341801386,
      "grad_norm": 1.4618902206420898,
      "learning_rate": 0.00015710161662817553,
      "loss": 0.2313,
      "step": 2230
    },
    {
      "epoch": 0.6466512702078522,
      "grad_norm": 2.630324602127075,
      "learning_rate": 0.00015690916089299462,
      "loss": 0.2568,
      "step": 2240
    },
    {
      "epoch": 0.6495381062355658,
      "grad_norm": 0.8227166533470154,
      "learning_rate": 0.00015671670515781373,
      "loss": 0.2796,
      "step": 2250
    },
    {
      "epoch": 0.6524249422632794,
      "grad_norm": 4.532657146453857,
      "learning_rate": 0.00015652424942263278,
      "loss": 0.2959,
      "step": 2260
    },
    {
      "epoch": 0.6553117782909931,
      "grad_norm": 11.540931701660156,
      "learning_rate": 0.0001563317936874519,
      "loss": 0.4021,
      "step": 2270
    },
    {
      "epoch": 0.6581986143187067,
      "grad_norm": 5.6367506980896,
      "learning_rate": 0.00015613933795227098,
      "loss": 0.2421,
      "step": 2280
    },
    {
      "epoch": 0.6610854503464203,
      "grad_norm": 2.798832893371582,
      "learning_rate": 0.00015594688221709009,
      "loss": 0.2361,
      "step": 2290
    },
    {
      "epoch": 0.663972286374134,
      "grad_norm": 4.750415802001953,
      "learning_rate": 0.00015575442648190917,
      "loss": 0.3544,
      "step": 2300
    },
    {
      "epoch": 0.6668591224018475,
      "grad_norm": 2.142981767654419,
      "learning_rate": 0.00015556197074672828,
      "loss": 0.2996,
      "step": 2310
    },
    {
      "epoch": 0.6697459584295612,
      "grad_norm": 3.266366958618164,
      "learning_rate": 0.00015536951501154736,
      "loss": 0.4227,
      "step": 2320
    },
    {
      "epoch": 0.6726327944572749,
      "grad_norm": 3.9839415550231934,
      "learning_rate": 0.00015517705927636644,
      "loss": 0.3992,
      "step": 2330
    },
    {
      "epoch": 0.6755196304849884,
      "grad_norm": 2.458599805831909,
      "learning_rate": 0.00015498460354118553,
      "loss": 0.3781,
      "step": 2340
    },
    {
      "epoch": 0.6784064665127021,
      "grad_norm": 1.8862957954406738,
      "learning_rate": 0.0001547921478060046,
      "loss": 0.2561,
      "step": 2350
    },
    {
      "epoch": 0.6812933025404158,
      "grad_norm": 4.972912788391113,
      "learning_rate": 0.00015459969207082372,
      "loss": 0.3499,
      "step": 2360
    },
    {
      "epoch": 0.6841801385681293,
      "grad_norm": 1.4091516733169556,
      "learning_rate": 0.0001544072363356428,
      "loss": 0.4082,
      "step": 2370
    },
    {
      "epoch": 0.687066974595843,
      "grad_norm": 5.5718889236450195,
      "learning_rate": 0.0001542147806004619,
      "loss": 0.6315,
      "step": 2380
    },
    {
      "epoch": 0.6899538106235565,
      "grad_norm": 1.2760345935821533,
      "learning_rate": 0.000154022324865281,
      "loss": 0.2822,
      "step": 2390
    },
    {
      "epoch": 0.6928406466512702,
      "grad_norm": 3.0725176334381104,
      "learning_rate": 0.00015382986913010008,
      "loss": 0.2365,
      "step": 2400
    },
    {
      "epoch": 0.6957274826789839,
      "grad_norm": 5.030239105224609,
      "learning_rate": 0.00015363741339491916,
      "loss": 0.2653,
      "step": 2410
    },
    {
      "epoch": 0.6986143187066974,
      "grad_norm": 2.280925750732422,
      "learning_rate": 0.00015344495765973827,
      "loss": 0.299,
      "step": 2420
    },
    {
      "epoch": 0.7015011547344111,
      "grad_norm": 2.7490100860595703,
      "learning_rate": 0.00015325250192455735,
      "loss": 0.1819,
      "step": 2430
    },
    {
      "epoch": 0.7043879907621247,
      "grad_norm": 7.255993366241455,
      "learning_rate": 0.00015306004618937646,
      "loss": 0.3329,
      "step": 2440
    },
    {
      "epoch": 0.7072748267898383,
      "grad_norm": 1.883111834526062,
      "learning_rate": 0.00015286759045419555,
      "loss": 0.3169,
      "step": 2450
    },
    {
      "epoch": 0.710161662817552,
      "grad_norm": 1.9232068061828613,
      "learning_rate": 0.00015267513471901463,
      "loss": 0.2748,
      "step": 2460
    },
    {
      "epoch": 0.7130484988452656,
      "grad_norm": 0.6666805744171143,
      "learning_rate": 0.00015248267898383374,
      "loss": 0.337,
      "step": 2470
    },
    {
      "epoch": 0.7159353348729792,
      "grad_norm": 1.693248987197876,
      "learning_rate": 0.00015229022324865282,
      "loss": 0.3429,
      "step": 2480
    },
    {
      "epoch": 0.7188221709006929,
      "grad_norm": 0.9369313716888428,
      "learning_rate": 0.0001520977675134719,
      "loss": 0.3295,
      "step": 2490
    },
    {
      "epoch": 0.7217090069284064,
      "grad_norm": 6.504411697387695,
      "learning_rate": 0.00015190531177829099,
      "loss": 0.4446,
      "step": 2500
    },
    {
      "epoch": 0.7245958429561201,
      "grad_norm": 1.0601129531860352,
      "learning_rate": 0.0001517128560431101,
      "loss": 0.3529,
      "step": 2510
    },
    {
      "epoch": 0.7274826789838337,
      "grad_norm": 1.300528883934021,
      "learning_rate": 0.00015152040030792918,
      "loss": 0.1641,
      "step": 2520
    },
    {
      "epoch": 0.7303695150115473,
      "grad_norm": 2.0826973915100098,
      "learning_rate": 0.0001513279445727483,
      "loss": 0.2108,
      "step": 2530
    },
    {
      "epoch": 0.733256351039261,
      "grad_norm": 3.501116991043091,
      "learning_rate": 0.00015113548883756737,
      "loss": 0.3336,
      "step": 2540
    },
    {
      "epoch": 0.7361431870669746,
      "grad_norm": 6.665590763092041,
      "learning_rate": 0.00015094303310238645,
      "loss": 0.4135,
      "step": 2550
    },
    {
      "epoch": 0.7390300230946882,
      "grad_norm": 2.4397244453430176,
      "learning_rate": 0.00015075057736720554,
      "loss": 0.2692,
      "step": 2560
    },
    {
      "epoch": 0.7419168591224018,
      "grad_norm": 2.134992837905884,
      "learning_rate": 0.00015055812163202465,
      "loss": 0.2572,
      "step": 2570
    },
    {
      "epoch": 0.7448036951501155,
      "grad_norm": 1.9313478469848633,
      "learning_rate": 0.00015036566589684373,
      "loss": 0.2168,
      "step": 2580
    },
    {
      "epoch": 0.7476905311778291,
      "grad_norm": 1.7434054613113403,
      "learning_rate": 0.0001501732101616628,
      "loss": 0.2051,
      "step": 2590
    },
    {
      "epoch": 0.7505773672055427,
      "grad_norm": 3.4484975337982178,
      "learning_rate": 0.00014998075442648192,
      "loss": 0.4252,
      "step": 2600
    },
    {
      "epoch": 0.7534642032332564,
      "grad_norm": 2.155467987060547,
      "learning_rate": 0.000149788298691301,
      "loss": 0.2834,
      "step": 2610
    },
    {
      "epoch": 0.75635103926097,
      "grad_norm": 2.9177699089050293,
      "learning_rate": 0.00014959584295612011,
      "loss": 0.2339,
      "step": 2620
    },
    {
      "epoch": 0.7592378752886836,
      "grad_norm": 1.7739527225494385,
      "learning_rate": 0.00014940338722093917,
      "loss": 0.2592,
      "step": 2630
    },
    {
      "epoch": 0.7621247113163973,
      "grad_norm": 2.228910446166992,
      "learning_rate": 0.00014921093148575828,
      "loss": 0.1903,
      "step": 2640
    },
    {
      "epoch": 0.7650115473441108,
      "grad_norm": 9.045823097229004,
      "learning_rate": 0.00014901847575057736,
      "loss": 0.3759,
      "step": 2650
    },
    {
      "epoch": 0.7678983833718245,
      "grad_norm": 1.3688503503799438,
      "learning_rate": 0.00014882602001539647,
      "loss": 0.2107,
      "step": 2660
    },
    {
      "epoch": 0.7707852193995381,
      "grad_norm": 3.195612668991089,
      "learning_rate": 0.00014863356428021556,
      "loss": 0.2408,
      "step": 2670
    },
    {
      "epoch": 0.7736720554272517,
      "grad_norm": 3.744544267654419,
      "learning_rate": 0.00014844110854503467,
      "loss": 0.4089,
      "step": 2680
    },
    {
      "epoch": 0.7765588914549654,
      "grad_norm": 2.4709033966064453,
      "learning_rate": 0.00014824865280985375,
      "loss": 0.3956,
      "step": 2690
    },
    {
      "epoch": 0.7794457274826789,
      "grad_norm": 1.6977964639663696,
      "learning_rate": 0.00014805619707467283,
      "loss": 0.3348,
      "step": 2700
    },
    {
      "epoch": 0.7823325635103926,
      "grad_norm": 2.8284380435943604,
      "learning_rate": 0.00014786374133949191,
      "loss": 0.2617,
      "step": 2710
    },
    {
      "epoch": 0.7852193995381063,
      "grad_norm": 1.3336572647094727,
      "learning_rate": 0.000147671285604311,
      "loss": 0.1834,
      "step": 2720
    },
    {
      "epoch": 0.7881062355658198,
      "grad_norm": 4.637543678283691,
      "learning_rate": 0.0001474788298691301,
      "loss": 0.2836,
      "step": 2730
    },
    {
      "epoch": 0.7909930715935335,
      "grad_norm": 4.390235424041748,
      "learning_rate": 0.0001472863741339492,
      "loss": 0.2744,
      "step": 2740
    },
    {
      "epoch": 0.7938799076212472,
      "grad_norm": 1.0232343673706055,
      "learning_rate": 0.0001470939183987683,
      "loss": 0.2828,
      "step": 2750
    },
    {
      "epoch": 0.7967667436489607,
      "grad_norm": 5.138052463531494,
      "learning_rate": 0.00014690146266358738,
      "loss": 0.2509,
      "step": 2760
    },
    {
      "epoch": 0.7996535796766744,
      "grad_norm": 1.7513929605484009,
      "learning_rate": 0.0001467090069284065,
      "loss": 0.2847,
      "step": 2770
    },
    {
      "epoch": 0.8025404157043879,
      "grad_norm": 13.449148178100586,
      "learning_rate": 0.00014651655119322555,
      "loss": 0.2787,
      "step": 2780
    },
    {
      "epoch": 0.8054272517321016,
      "grad_norm": 2.414588451385498,
      "learning_rate": 0.00014632409545804466,
      "loss": 0.2822,
      "step": 2790
    },
    {
      "epoch": 0.8083140877598153,
      "grad_norm": 1.7818480730056763,
      "learning_rate": 0.00014613163972286374,
      "loss": 0.3911,
      "step": 2800
    },
    {
      "epoch": 0.8112009237875288,
      "grad_norm": 8.308722496032715,
      "learning_rate": 0.00014593918398768285,
      "loss": 0.4514,
      "step": 2810
    },
    {
      "epoch": 0.8140877598152425,
      "grad_norm": 1.540053129196167,
      "learning_rate": 0.00014574672825250193,
      "loss": 0.2214,
      "step": 2820
    },
    {
      "epoch": 0.8169745958429562,
      "grad_norm": 3.4479098320007324,
      "learning_rate": 0.00014555427251732104,
      "loss": 0.3413,
      "step": 2830
    },
    {
      "epoch": 0.8198614318706697,
      "grad_norm": 1.0137927532196045,
      "learning_rate": 0.00014536181678214013,
      "loss": 0.273,
      "step": 2840
    },
    {
      "epoch": 0.8227482678983834,
      "grad_norm": 1.2138594388961792,
      "learning_rate": 0.0001451693610469592,
      "loss": 0.2136,
      "step": 2850
    },
    {
      "epoch": 0.825635103926097,
      "grad_norm": 4.299587726593018,
      "learning_rate": 0.0001449769053117783,
      "loss": 0.2518,
      "step": 2860
    },
    {
      "epoch": 0.8285219399538106,
      "grad_norm": 1.2344248294830322,
      "learning_rate": 0.00014478444957659737,
      "loss": 0.2968,
      "step": 2870
    },
    {
      "epoch": 0.8314087759815243,
      "grad_norm": 2.0993287563323975,
      "learning_rate": 0.00014459199384141648,
      "loss": 0.3345,
      "step": 2880
    },
    {
      "epoch": 0.8342956120092379,
      "grad_norm": 3.3448712825775146,
      "learning_rate": 0.00014439953810623557,
      "loss": 0.2604,
      "step": 2890
    },
    {
      "epoch": 0.8371824480369515,
      "grad_norm": 2.598262071609497,
      "learning_rate": 0.00014420708237105468,
      "loss": 0.2435,
      "step": 2900
    },
    {
      "epoch": 0.8400692840646651,
      "grad_norm": 3.6309096813201904,
      "learning_rate": 0.00014401462663587376,
      "loss": 0.2799,
      "step": 2910
    },
    {
      "epoch": 0.8429561200923787,
      "grad_norm": 1.9274691343307495,
      "learning_rate": 0.00014382217090069284,
      "loss": 0.3375,
      "step": 2920
    },
    {
      "epoch": 0.8458429561200924,
      "grad_norm": 2.0989534854888916,
      "learning_rate": 0.00014362971516551192,
      "loss": 0.2781,
      "step": 2930
    },
    {
      "epoch": 0.848729792147806,
      "grad_norm": 2.6845059394836426,
      "learning_rate": 0.00014343725943033103,
      "loss": 0.2679,
      "step": 2940
    },
    {
      "epoch": 0.8516166281755196,
      "grad_norm": 1.2196241617202759,
      "learning_rate": 0.00014324480369515012,
      "loss": 0.1652,
      "step": 2950
    },
    {
      "epoch": 0.8545034642032333,
      "grad_norm": 2.4487860202789307,
      "learning_rate": 0.00014305234795996923,
      "loss": 0.2831,
      "step": 2960
    },
    {
      "epoch": 0.8573903002309469,
      "grad_norm": 1.0288153886795044,
      "learning_rate": 0.0001428598922247883,
      "loss": 0.3099,
      "step": 2970
    },
    {
      "epoch": 0.8602771362586605,
      "grad_norm": 5.521131992340088,
      "learning_rate": 0.0001426674364896074,
      "loss": 0.3736,
      "step": 2980
    },
    {
      "epoch": 0.8631639722863741,
      "grad_norm": 10.391085624694824,
      "learning_rate": 0.0001424749807544265,
      "loss": 0.3892,
      "step": 2990
    },
    {
      "epoch": 0.8660508083140878,
      "grad_norm": 1.6073436737060547,
      "learning_rate": 0.00014228252501924558,
      "loss": 0.1532,
      "step": 3000
    },
    {
      "epoch": 0.8689376443418014,
      "grad_norm": 1.646189570426941,
      "learning_rate": 0.00014209006928406467,
      "loss": 0.2279,
      "step": 3010
    },
    {
      "epoch": 0.871824480369515,
      "grad_norm": 3.9993560314178467,
      "learning_rate": 0.00014189761354888375,
      "loss": 0.2396,
      "step": 3020
    },
    {
      "epoch": 0.8747113163972287,
      "grad_norm": 0.7342835664749146,
      "learning_rate": 0.00014170515781370286,
      "loss": 0.2302,
      "step": 3030
    },
    {
      "epoch": 0.8775981524249422,
      "grad_norm": 7.033677101135254,
      "learning_rate": 0.00014151270207852194,
      "loss": 0.4016,
      "step": 3040
    },
    {
      "epoch": 0.8804849884526559,
      "grad_norm": 1.582974910736084,
      "learning_rate": 0.00014132024634334105,
      "loss": 0.1923,
      "step": 3050
    },
    {
      "epoch": 0.8833718244803695,
      "grad_norm": 1.338618516921997,
      "learning_rate": 0.00014112779060816014,
      "loss": 0.2061,
      "step": 3060
    },
    {
      "epoch": 0.8862586605080831,
      "grad_norm": 1.6188544034957886,
      "learning_rate": 0.00014093533487297922,
      "loss": 0.1988,
      "step": 3070
    },
    {
      "epoch": 0.8891454965357968,
      "grad_norm": 3.0735881328582764,
      "learning_rate": 0.0001407428791377983,
      "loss": 0.3804,
      "step": 3080
    },
    {
      "epoch": 0.8920323325635104,
      "grad_norm": 1.432207703590393,
      "learning_rate": 0.0001405504234026174,
      "loss": 0.2456,
      "step": 3090
    },
    {
      "epoch": 0.894919168591224,
      "grad_norm": 2.8574018478393555,
      "learning_rate": 0.0001403579676674365,
      "loss": 0.3348,
      "step": 3100
    },
    {
      "epoch": 0.8978060046189377,
      "grad_norm": 8.990194320678711,
      "learning_rate": 0.00014016551193225558,
      "loss": 0.1998,
      "step": 3110
    },
    {
      "epoch": 0.9006928406466512,
      "grad_norm": 1.6565414667129517,
      "learning_rate": 0.00013997305619707469,
      "loss": 0.3492,
      "step": 3120
    },
    {
      "epoch": 0.9035796766743649,
      "grad_norm": 2.209592342376709,
      "learning_rate": 0.00013978060046189377,
      "loss": 0.2379,
      "step": 3130
    },
    {
      "epoch": 0.9064665127020786,
      "grad_norm": 12.271343231201172,
      "learning_rate": 0.00013958814472671288,
      "loss": 0.3748,
      "step": 3140
    },
    {
      "epoch": 0.9093533487297921,
      "grad_norm": 5.551967144012451,
      "learning_rate": 0.00013939568899153193,
      "loss": 0.3669,
      "step": 3150
    },
    {
      "epoch": 0.9122401847575058,
      "grad_norm": 2.3342530727386475,
      "learning_rate": 0.00013920323325635104,
      "loss": 0.2774,
      "step": 3160
    },
    {
      "epoch": 0.9151270207852193,
      "grad_norm": 2.3801510334014893,
      "learning_rate": 0.00013901077752117013,
      "loss": 0.266,
      "step": 3170
    },
    {
      "epoch": 0.918013856812933,
      "grad_norm": 1.350239634513855,
      "learning_rate": 0.00013881832178598924,
      "loss": 0.2954,
      "step": 3180
    },
    {
      "epoch": 0.9209006928406467,
      "grad_norm": 1.5436718463897705,
      "learning_rate": 0.00013862586605080832,
      "loss": 0.2885,
      "step": 3190
    },
    {
      "epoch": 0.9237875288683602,
      "grad_norm": 4.905273914337158,
      "learning_rate": 0.00013843341031562743,
      "loss": 0.5218,
      "step": 3200
    },
    {
      "epoch": 0.9266743648960739,
      "grad_norm": 2.0251803398132324,
      "learning_rate": 0.0001382409545804465,
      "loss": 0.2019,
      "step": 3210
    },
    {
      "epoch": 0.9295612009237876,
      "grad_norm": 2.906930685043335,
      "learning_rate": 0.0001380484988452656,
      "loss": 0.2357,
      "step": 3220
    },
    {
      "epoch": 0.9324480369515011,
      "grad_norm": 8.818778991699219,
      "learning_rate": 0.00013785604311008468,
      "loss": 0.2773,
      "step": 3230
    },
    {
      "epoch": 0.9353348729792148,
      "grad_norm": 1.8830937147140503,
      "learning_rate": 0.00013766358737490376,
      "loss": 0.1841,
      "step": 3240
    },
    {
      "epoch": 0.9382217090069284,
      "grad_norm": 0.6471140384674072,
      "learning_rate": 0.00013747113163972287,
      "loss": 0.2498,
      "step": 3250
    },
    {
      "epoch": 0.941108545034642,
      "grad_norm": 1.7399269342422485,
      "learning_rate": 0.00013727867590454195,
      "loss": 0.2111,
      "step": 3260
    },
    {
      "epoch": 0.9439953810623557,
      "grad_norm": 2.110259532928467,
      "learning_rate": 0.00013708622016936106,
      "loss": 0.2955,
      "step": 3270
    },
    {
      "epoch": 0.9468822170900693,
      "grad_norm": 1.6995480060577393,
      "learning_rate": 0.00013689376443418015,
      "loss": 0.182,
      "step": 3280
    },
    {
      "epoch": 0.9497690531177829,
      "grad_norm": 5.125089168548584,
      "learning_rate": 0.00013670130869899923,
      "loss": 0.2412,
      "step": 3290
    },
    {
      "epoch": 0.9526558891454965,
      "grad_norm": 1.7064229249954224,
      "learning_rate": 0.0001365088529638183,
      "loss": 0.295,
      "step": 3300
    },
    {
      "epoch": 0.9555427251732102,
      "grad_norm": 2.5189926624298096,
      "learning_rate": 0.00013631639722863742,
      "loss": 0.4405,
      "step": 3310
    },
    {
      "epoch": 0.9584295612009238,
      "grad_norm": 3.7778589725494385,
      "learning_rate": 0.0001361239414934565,
      "loss": 0.2355,
      "step": 3320
    },
    {
      "epoch": 0.9613163972286374,
      "grad_norm": 1.232675313949585,
      "learning_rate": 0.00013593148575827561,
      "loss": 0.2334,
      "step": 3330
    },
    {
      "epoch": 0.964203233256351,
      "grad_norm": 3.5722789764404297,
      "learning_rate": 0.0001357390300230947,
      "loss": 0.4382,
      "step": 3340
    },
    {
      "epoch": 0.9670900692840647,
      "grad_norm": 0.57366544008255,
      "learning_rate": 0.0001355465742879138,
      "loss": 0.2239,
      "step": 3350
    },
    {
      "epoch": 0.9699769053117783,
      "grad_norm": 3.3768138885498047,
      "learning_rate": 0.0001353541185527329,
      "loss": 0.4393,
      "step": 3360
    },
    {
      "epoch": 0.9728637413394919,
      "grad_norm": 0.7165973782539368,
      "learning_rate": 0.00013516166281755197,
      "loss": 0.2051,
      "step": 3370
    },
    {
      "epoch": 0.9757505773672055,
      "grad_norm": 0.7662757635116577,
      "learning_rate": 0.00013496920708237105,
      "loss": 0.3978,
      "step": 3380
    },
    {
      "epoch": 0.9786374133949192,
      "grad_norm": 3.9825785160064697,
      "learning_rate": 0.00013477675134719014,
      "loss": 0.2088,
      "step": 3390
    },
    {
      "epoch": 0.9815242494226328,
      "grad_norm": 2.4700944423675537,
      "learning_rate": 0.00013458429561200925,
      "loss": 0.1709,
      "step": 3400
    },
    {
      "epoch": 0.9844110854503464,
      "grad_norm": 9.097901344299316,
      "learning_rate": 0.00013439183987682833,
      "loss": 0.2608,
      "step": 3410
    },
    {
      "epoch": 0.9872979214780601,
      "grad_norm": 1.5507605075836182,
      "learning_rate": 0.00013419938414164744,
      "loss": 0.3609,
      "step": 3420
    },
    {
      "epoch": 0.9901847575057737,
      "grad_norm": 1.6726725101470947,
      "learning_rate": 0.00013400692840646652,
      "loss": 0.2997,
      "step": 3430
    },
    {
      "epoch": 0.9930715935334873,
      "grad_norm": 1.3993369340896606,
      "learning_rate": 0.0001338144726712856,
      "loss": 0.248,
      "step": 3440
    },
    {
      "epoch": 0.995958429561201,
      "grad_norm": 1.0328243970870972,
      "learning_rate": 0.0001336220169361047,
      "loss": 0.2011,
      "step": 3450
    },
    {
      "epoch": 0.9988452655889145,
      "grad_norm": 1.2725815773010254,
      "learning_rate": 0.0001334295612009238,
      "loss": 0.2095,
      "step": 3460
    },
    {
      "epoch": 1.001732101616628,
      "grad_norm": 7.114306449890137,
      "learning_rate": 0.00013323710546574288,
      "loss": 0.3462,
      "step": 3470
    },
    {
      "epoch": 1.0046189376443417,
      "grad_norm": 1.9956313371658325,
      "learning_rate": 0.000133044649730562,
      "loss": 0.2155,
      "step": 3480
    },
    {
      "epoch": 1.0075057736720554,
      "grad_norm": 3.494452476501465,
      "learning_rate": 0.00013285219399538107,
      "loss": 0.2642,
      "step": 3490
    },
    {
      "epoch": 1.010392609699769,
      "grad_norm": 3.673137664794922,
      "learning_rate": 0.00013265973826020016,
      "loss": 0.3841,
      "step": 3500
    },
    {
      "epoch": 1.0132794457274827,
      "grad_norm": 1.9620001316070557,
      "learning_rate": 0.00013246728252501927,
      "loss": 0.2558,
      "step": 3510
    },
    {
      "epoch": 1.0161662817551964,
      "grad_norm": 3.3750085830688477,
      "learning_rate": 0.00013227482678983832,
      "loss": 0.2503,
      "step": 3520
    },
    {
      "epoch": 1.0190531177829099,
      "grad_norm": 15.28236198425293,
      "learning_rate": 0.00013208237105465743,
      "loss": 0.3577,
      "step": 3530
    },
    {
      "epoch": 1.0219399538106235,
      "grad_norm": 1.2791718244552612,
      "learning_rate": 0.00013188991531947651,
      "loss": 0.2095,
      "step": 3540
    },
    {
      "epoch": 1.0248267898383372,
      "grad_norm": 1.414074420928955,
      "learning_rate": 0.00013169745958429562,
      "loss": 0.3571,
      "step": 3550
    },
    {
      "epoch": 1.0277136258660509,
      "grad_norm": 3.1331381797790527,
      "learning_rate": 0.0001315050038491147,
      "loss": 0.2249,
      "step": 3560
    },
    {
      "epoch": 1.0306004618937645,
      "grad_norm": 0.7102212905883789,
      "learning_rate": 0.00013131254811393382,
      "loss": 0.157,
      "step": 3570
    },
    {
      "epoch": 1.033487297921478,
      "grad_norm": 3.7503163814544678,
      "learning_rate": 0.0001311200923787529,
      "loss": 0.3118,
      "step": 3580
    },
    {
      "epoch": 1.0363741339491916,
      "grad_norm": 1.9977355003356934,
      "learning_rate": 0.00013092763664357198,
      "loss": 0.199,
      "step": 3590
    },
    {
      "epoch": 1.0392609699769053,
      "grad_norm": 2.5014853477478027,
      "learning_rate": 0.00013073518090839107,
      "loss": 0.2441,
      "step": 3600
    },
    {
      "epoch": 1.042147806004619,
      "grad_norm": 1.0104548931121826,
      "learning_rate": 0.00013054272517321018,
      "loss": 0.3933,
      "step": 3610
    },
    {
      "epoch": 1.0450346420323327,
      "grad_norm": 1.479341983795166,
      "learning_rate": 0.00013035026943802926,
      "loss": 0.3533,
      "step": 3620
    },
    {
      "epoch": 1.047921478060046,
      "grad_norm": 2.979874849319458,
      "learning_rate": 0.00013015781370284834,
      "loss": 0.3412,
      "step": 3630
    },
    {
      "epoch": 1.0508083140877598,
      "grad_norm": 1.2583204507827759,
      "learning_rate": 0.00012996535796766745,
      "loss": 0.1802,
      "step": 3640
    },
    {
      "epoch": 1.0536951501154734,
      "grad_norm": 2.2328410148620605,
      "learning_rate": 0.00012977290223248653,
      "loss": 0.1759,
      "step": 3650
    },
    {
      "epoch": 1.056581986143187,
      "grad_norm": 5.985633373260498,
      "learning_rate": 0.00012958044649730564,
      "loss": 0.2536,
      "step": 3660
    },
    {
      "epoch": 1.0594688221709008,
      "grad_norm": 1.0491085052490234,
      "learning_rate": 0.0001293879907621247,
      "loss": 0.2609,
      "step": 3670
    },
    {
      "epoch": 1.0623556581986142,
      "grad_norm": 1.6583253145217896,
      "learning_rate": 0.0001291955350269438,
      "loss": 0.213,
      "step": 3680
    },
    {
      "epoch": 1.0652424942263279,
      "grad_norm": 1.1616524457931519,
      "learning_rate": 0.0001290030792917629,
      "loss": 0.2693,
      "step": 3690
    },
    {
      "epoch": 1.0681293302540416,
      "grad_norm": 1.1005367040634155,
      "learning_rate": 0.000128810623556582,
      "loss": 0.2228,
      "step": 3700
    },
    {
      "epoch": 1.0710161662817552,
      "grad_norm": 1.9509685039520264,
      "learning_rate": 0.00012861816782140108,
      "loss": 0.1852,
      "step": 3710
    },
    {
      "epoch": 1.073903002309469,
      "grad_norm": 3.0951874256134033,
      "learning_rate": 0.0001284257120862202,
      "loss": 0.2479,
      "step": 3720
    },
    {
      "epoch": 1.0767898383371826,
      "grad_norm": 1.1241084337234497,
      "learning_rate": 0.00012823325635103928,
      "loss": 0.1973,
      "step": 3730
    },
    {
      "epoch": 1.079676674364896,
      "grad_norm": 5.044511795043945,
      "learning_rate": 0.00012804080061585836,
      "loss": 0.247,
      "step": 3740
    },
    {
      "epoch": 1.0825635103926097,
      "grad_norm": 0.8138891458511353,
      "learning_rate": 0.00012784834488067744,
      "loss": 0.1789,
      "step": 3750
    },
    {
      "epoch": 1.0854503464203233,
      "grad_norm": 0.7572546005249023,
      "learning_rate": 0.00012765588914549653,
      "loss": 0.2487,
      "step": 3760
    },
    {
      "epoch": 1.088337182448037,
      "grad_norm": 2.098151683807373,
      "learning_rate": 0.00012746343341031563,
      "loss": 0.2766,
      "step": 3770
    },
    {
      "epoch": 1.0912240184757507,
      "grad_norm": 1.3904168605804443,
      "learning_rate": 0.00012727097767513472,
      "loss": 0.1569,
      "step": 3780
    },
    {
      "epoch": 1.0941108545034641,
      "grad_norm": 10.096976280212402,
      "learning_rate": 0.00012707852193995383,
      "loss": 0.2325,
      "step": 3790
    },
    {
      "epoch": 1.0969976905311778,
      "grad_norm": 2.4215996265411377,
      "learning_rate": 0.0001268860662047729,
      "loss": 0.3121,
      "step": 3800
    },
    {
      "epoch": 1.0998845265588915,
      "grad_norm": 1.3270540237426758,
      "learning_rate": 0.000126693610469592,
      "loss": 0.2892,
      "step": 3810
    },
    {
      "epoch": 1.1027713625866051,
      "grad_norm": 4.856681823730469,
      "learning_rate": 0.00012650115473441108,
      "loss": 0.2598,
      "step": 3820
    },
    {
      "epoch": 1.1056581986143188,
      "grad_norm": 2.172314405441284,
      "learning_rate": 0.00012630869899923019,
      "loss": 0.1909,
      "step": 3830
    },
    {
      "epoch": 1.1085450346420322,
      "grad_norm": 1.081423044204712,
      "learning_rate": 0.00012611624326404927,
      "loss": 0.2803,
      "step": 3840
    },
    {
      "epoch": 1.111431870669746,
      "grad_norm": 2.683530330657959,
      "learning_rate": 0.00012592378752886838,
      "loss": 0.3728,
      "step": 3850
    },
    {
      "epoch": 1.1143187066974596,
      "grad_norm": 1.1673462390899658,
      "learning_rate": 0.00012573133179368746,
      "loss": 0.2068,
      "step": 3860
    },
    {
      "epoch": 1.1172055427251733,
      "grad_norm": 5.598372936248779,
      "learning_rate": 0.00012553887605850657,
      "loss": 0.2675,
      "step": 3870
    },
    {
      "epoch": 1.120092378752887,
      "grad_norm": 1.6943174600601196,
      "learning_rate": 0.00012534642032332565,
      "loss": 0.2679,
      "step": 3880
    },
    {
      "epoch": 1.1229792147806004,
      "grad_norm": 2.048356771469116,
      "learning_rate": 0.00012515396458814474,
      "loss": 0.2433,
      "step": 3890
    },
    {
      "epoch": 1.125866050808314,
      "grad_norm": 1.9627737998962402,
      "learning_rate": 0.00012496150885296382,
      "loss": 0.2061,
      "step": 3900
    },
    {
      "epoch": 1.1287528868360277,
      "grad_norm": 1.2743918895721436,
      "learning_rate": 0.0001247690531177829,
      "loss": 0.2461,
      "step": 3910
    },
    {
      "epoch": 1.1316397228637414,
      "grad_norm": 1.7911297082901,
      "learning_rate": 0.000124576597382602,
      "loss": 0.2797,
      "step": 3920
    },
    {
      "epoch": 1.134526558891455,
      "grad_norm": 2.731445550918579,
      "learning_rate": 0.0001243841416474211,
      "loss": 0.1892,
      "step": 3930
    },
    {
      "epoch": 1.1374133949191685,
      "grad_norm": 1.193131685256958,
      "learning_rate": 0.0001241916859122402,
      "loss": 0.1623,
      "step": 3940
    },
    {
      "epoch": 1.1403002309468822,
      "grad_norm": 3.0038602352142334,
      "learning_rate": 0.0001239992301770593,
      "loss": 0.1931,
      "step": 3950
    },
    {
      "epoch": 1.1431870669745958,
      "grad_norm": 2.9892261028289795,
      "learning_rate": 0.00012380677444187837,
      "loss": 0.29,
      "step": 3960
    },
    {
      "epoch": 1.1460739030023095,
      "grad_norm": 2.7911312580108643,
      "learning_rate": 0.00012361431870669745,
      "loss": 0.2473,
      "step": 3970
    },
    {
      "epoch": 1.1489607390300232,
      "grad_norm": 0.7067830562591553,
      "learning_rate": 0.00012342186297151656,
      "loss": 0.1807,
      "step": 3980
    },
    {
      "epoch": 1.1518475750577366,
      "grad_norm": 2.9371440410614014,
      "learning_rate": 0.00012322940723633565,
      "loss": 0.2696,
      "step": 3990
    },
    {
      "epoch": 1.1547344110854503,
      "grad_norm": 4.58062219619751,
      "learning_rate": 0.00012303695150115476,
      "loss": 0.2167,
      "step": 4000
    },
    {
      "epoch": 1.157621247113164,
      "grad_norm": 1.1317424774169922,
      "learning_rate": 0.00012284449576597384,
      "loss": 0.2374,
      "step": 4010
    },
    {
      "epoch": 1.1605080831408776,
      "grad_norm": 1.3263520002365112,
      "learning_rate": 0.00012265204003079292,
      "loss": 0.3226,
      "step": 4020
    },
    {
      "epoch": 1.1633949191685913,
      "grad_norm": 2.509235382080078,
      "learning_rate": 0.00012245958429561203,
      "loss": 0.1874,
      "step": 4030
    },
    {
      "epoch": 1.1662817551963047,
      "grad_norm": 5.577951431274414,
      "learning_rate": 0.00012226712856043109,
      "loss": 0.3223,
      "step": 4040
    },
    {
      "epoch": 1.1691685912240184,
      "grad_norm": 1.1040480136871338,
      "learning_rate": 0.0001220746728252502,
      "loss": 0.351,
      "step": 4050
    },
    {
      "epoch": 1.172055427251732,
      "grad_norm": 1.3542206287384033,
      "learning_rate": 0.00012188221709006928,
      "loss": 0.2393,
      "step": 4060
    },
    {
      "epoch": 1.1749422632794457,
      "grad_norm": 8.929429054260254,
      "learning_rate": 0.00012168976135488839,
      "loss": 0.3489,
      "step": 4070
    },
    {
      "epoch": 1.1778290993071594,
      "grad_norm": 0.9776579141616821,
      "learning_rate": 0.00012149730561970747,
      "loss": 0.1642,
      "step": 4080
    },
    {
      "epoch": 1.180715935334873,
      "grad_norm": 0.9327667951583862,
      "learning_rate": 0.00012130484988452657,
      "loss": 0.2283,
      "step": 4090
    },
    {
      "epoch": 1.1836027713625865,
      "grad_norm": 2.971132278442383,
      "learning_rate": 0.00012111239414934565,
      "loss": 0.3772,
      "step": 4100
    },
    {
      "epoch": 1.1864896073903002,
      "grad_norm": 0.7288361191749573,
      "learning_rate": 0.00012091993841416476,
      "loss": 0.2203,
      "step": 4110
    },
    {
      "epoch": 1.1893764434180139,
      "grad_norm": 2.6803371906280518,
      "learning_rate": 0.00012072748267898384,
      "loss": 0.2381,
      "step": 4120
    },
    {
      "epoch": 1.1922632794457275,
      "grad_norm": 2.5312082767486572,
      "learning_rate": 0.00012053502694380293,
      "loss": 0.3085,
      "step": 4130
    },
    {
      "epoch": 1.1951501154734412,
      "grad_norm": 2.8835625648498535,
      "learning_rate": 0.00012034257120862202,
      "loss": 0.2539,
      "step": 4140
    },
    {
      "epoch": 1.1980369515011549,
      "grad_norm": 5.774266719818115,
      "learning_rate": 0.0001201501154734411,
      "loss": 0.2235,
      "step": 4150
    },
    {
      "epoch": 1.2009237875288683,
      "grad_norm": 1.4359639883041382,
      "learning_rate": 0.00011995765973826021,
      "loss": 0.1964,
      "step": 4160
    },
    {
      "epoch": 1.203810623556582,
      "grad_norm": 2.441288948059082,
      "learning_rate": 0.00011976520400307928,
      "loss": 0.2656,
      "step": 4170
    },
    {
      "epoch": 1.2066974595842956,
      "grad_norm": 1.0713839530944824,
      "learning_rate": 0.0001195727482678984,
      "loss": 0.2288,
      "step": 4180
    },
    {
      "epoch": 1.2095842956120093,
      "grad_norm": 2.4623212814331055,
      "learning_rate": 0.00011938029253271748,
      "loss": 0.2309,
      "step": 4190
    },
    {
      "epoch": 1.212471131639723,
      "grad_norm": 1.4890068769454956,
      "learning_rate": 0.00011918783679753657,
      "loss": 0.1603,
      "step": 4200
    },
    {
      "epoch": 1.2153579676674364,
      "grad_norm": 2.5089356899261475,
      "learning_rate": 0.00011899538106235566,
      "loss": 0.3221,
      "step": 4210
    },
    {
      "epoch": 1.21824480369515,
      "grad_norm": 8.767484664916992,
      "learning_rate": 0.00011880292532717477,
      "loss": 0.2553,
      "step": 4220
    },
    {
      "epoch": 1.2211316397228638,
      "grad_norm": 6.408141613006592,
      "learning_rate": 0.00011861046959199385,
      "loss": 0.2479,
      "step": 4230
    },
    {
      "epoch": 1.2240184757505774,
      "grad_norm": 3.2469522953033447,
      "learning_rate": 0.00011841801385681294,
      "loss": 0.2312,
      "step": 4240
    },
    {
      "epoch": 1.226905311778291,
      "grad_norm": 4.0713677406311035,
      "learning_rate": 0.00011822555812163203,
      "loss": 0.2653,
      "step": 4250
    },
    {
      "epoch": 1.2297921478060045,
      "grad_norm": 3.3298840522766113,
      "learning_rate": 0.00011803310238645111,
      "loss": 0.1911,
      "step": 4260
    },
    {
      "epoch": 1.2326789838337182,
      "grad_norm": 2.484689950942993,
      "learning_rate": 0.00011784064665127022,
      "loss": 0.3314,
      "step": 4270
    },
    {
      "epoch": 1.2355658198614319,
      "grad_norm": 3.310241937637329,
      "learning_rate": 0.00011764819091608929,
      "loss": 0.2022,
      "step": 4280
    },
    {
      "epoch": 1.2384526558891455,
      "grad_norm": 0.7485854625701904,
      "learning_rate": 0.0001174557351809084,
      "loss": 0.2809,
      "step": 4290
    },
    {
      "epoch": 1.2413394919168592,
      "grad_norm": 9.434860229492188,
      "learning_rate": 0.00011726327944572748,
      "loss": 0.2832,
      "step": 4300
    },
    {
      "epoch": 1.2442263279445727,
      "grad_norm": 1.3814568519592285,
      "learning_rate": 0.00011707082371054658,
      "loss": 0.2651,
      "step": 4310
    },
    {
      "epoch": 1.2471131639722863,
      "grad_norm": 2.0638175010681152,
      "learning_rate": 0.00011687836797536566,
      "loss": 0.2047,
      "step": 4320
    },
    {
      "epoch": 1.25,
      "grad_norm": 2.4083986282348633,
      "learning_rate": 0.00011668591224018477,
      "loss": 0.168,
      "step": 4330
    },
    {
      "epoch": 1.2528868360277137,
      "grad_norm": 1.8417587280273438,
      "learning_rate": 0.00011649345650500385,
      "loss": 0.2174,
      "step": 4340
    },
    {
      "epoch": 1.2557736720554273,
      "grad_norm": 8.755910873413086,
      "learning_rate": 0.00011630100076982295,
      "loss": 0.2238,
      "step": 4350
    },
    {
      "epoch": 1.2586605080831408,
      "grad_norm": 0.8548382520675659,
      "learning_rate": 0.00011610854503464203,
      "loss": 0.1811,
      "step": 4360
    },
    {
      "epoch": 1.2615473441108545,
      "grad_norm": 1.6317321062088013,
      "learning_rate": 0.00011591608929946114,
      "loss": 0.2881,
      "step": 4370
    },
    {
      "epoch": 1.2644341801385681,
      "grad_norm": 0.7501399517059326,
      "learning_rate": 0.00011572363356428023,
      "loss": 0.2403,
      "step": 4380
    },
    {
      "epoch": 1.2673210161662818,
      "grad_norm": 1.4633558988571167,
      "learning_rate": 0.00011553117782909931,
      "loss": 0.2205,
      "step": 4390
    },
    {
      "epoch": 1.2702078521939955,
      "grad_norm": 2.764709234237671,
      "learning_rate": 0.0001153387220939184,
      "loss": 0.2128,
      "step": 4400
    },
    {
      "epoch": 1.273094688221709,
      "grad_norm": 1.4943703413009644,
      "learning_rate": 0.00011514626635873749,
      "loss": 0.2065,
      "step": 4410
    },
    {
      "epoch": 1.2759815242494226,
      "grad_norm": 5.957221031188965,
      "learning_rate": 0.0001149538106235566,
      "loss": 0.2054,
      "step": 4420
    },
    {
      "epoch": 1.2788683602771362,
      "grad_norm": 1.0770825147628784,
      "learning_rate": 0.00011476135488837567,
      "loss": 0.2781,
      "step": 4430
    },
    {
      "epoch": 1.28175519630485,
      "grad_norm": 1.3622511625289917,
      "learning_rate": 0.00011456889915319478,
      "loss": 0.2819,
      "step": 4440
    },
    {
      "epoch": 1.2846420323325636,
      "grad_norm": 2.7468321323394775,
      "learning_rate": 0.00011437644341801386,
      "loss": 0.3471,
      "step": 4450
    },
    {
      "epoch": 1.287528868360277,
      "grad_norm": 2.654961109161377,
      "learning_rate": 0.00011418398768283296,
      "loss": 0.1912,
      "step": 4460
    },
    {
      "epoch": 1.2904157043879907,
      "grad_norm": 14.97596549987793,
      "learning_rate": 0.00011399153194765204,
      "loss": 0.3157,
      "step": 4470
    },
    {
      "epoch": 1.2933025404157044,
      "grad_norm": 5.3996052742004395,
      "learning_rate": 0.00011379907621247115,
      "loss": 0.2411,
      "step": 4480
    },
    {
      "epoch": 1.296189376443418,
      "grad_norm": 2.8267288208007812,
      "learning_rate": 0.00011360662047729023,
      "loss": 0.1624,
      "step": 4490
    },
    {
      "epoch": 1.2990762124711317,
      "grad_norm": 2.0781943798065186,
      "learning_rate": 0.00011341416474210933,
      "loss": 0.2104,
      "step": 4500
    },
    {
      "epoch": 1.3019630484988451,
      "grad_norm": 1.4690821170806885,
      "learning_rate": 0.00011322170900692841,
      "loss": 0.3103,
      "step": 4510
    },
    {
      "epoch": 1.3048498845265588,
      "grad_norm": 1.428825855255127,
      "learning_rate": 0.00011302925327174749,
      "loss": 0.19,
      "step": 4520
    },
    {
      "epoch": 1.3077367205542725,
      "grad_norm": 0.6450685858726501,
      "learning_rate": 0.0001128367975365666,
      "loss": 0.1688,
      "step": 4530
    },
    {
      "epoch": 1.3106235565819861,
      "grad_norm": 12.03370475769043,
      "learning_rate": 0.00011264434180138567,
      "loss": 0.2917,
      "step": 4540
    },
    {
      "epoch": 1.3135103926096998,
      "grad_norm": 1.71218740940094,
      "learning_rate": 0.00011245188606620478,
      "loss": 0.3626,
      "step": 4550
    },
    {
      "epoch": 1.3163972286374133,
      "grad_norm": 2.5004565715789795,
      "learning_rate": 0.00011225943033102386,
      "loss": 0.2154,
      "step": 4560
    },
    {
      "epoch": 1.3192840646651272,
      "grad_norm": 1.3804094791412354,
      "learning_rate": 0.00011206697459584296,
      "loss": 0.3333,
      "step": 4570
    },
    {
      "epoch": 1.3221709006928406,
      "grad_norm": 2.367443084716797,
      "learning_rate": 0.00011187451886066204,
      "loss": 0.18,
      "step": 4580
    },
    {
      "epoch": 1.3250577367205543,
      "grad_norm": 2.3069305419921875,
      "learning_rate": 0.00011168206312548115,
      "loss": 0.2887,
      "step": 4590
    },
    {
      "epoch": 1.327944572748268,
      "grad_norm": 0.5832822918891907,
      "learning_rate": 0.00011148960739030024,
      "loss": 0.2106,
      "step": 4600
    },
    {
      "epoch": 1.3308314087759816,
      "grad_norm": 2.085214376449585,
      "learning_rate": 0.00011129715165511933,
      "loss": 0.1609,
      "step": 4610
    },
    {
      "epoch": 1.3337182448036953,
      "grad_norm": 2.251596450805664,
      "learning_rate": 0.00011110469591993841,
      "loss": 0.4495,
      "step": 4620
    },
    {
      "epoch": 1.3366050808314087,
      "grad_norm": 1.4358922243118286,
      "learning_rate": 0.00011091224018475752,
      "loss": 0.1959,
      "step": 4630
    },
    {
      "epoch": 1.3394919168591224,
      "grad_norm": 1.2256335020065308,
      "learning_rate": 0.00011071978444957661,
      "loss": 0.1987,
      "step": 4640
    },
    {
      "epoch": 1.342378752886836,
      "grad_norm": 2.586867570877075,
      "learning_rate": 0.00011052732871439569,
      "loss": 0.2928,
      "step": 4650
    },
    {
      "epoch": 1.3452655889145497,
      "grad_norm": 1.4324208498001099,
      "learning_rate": 0.00011033487297921479,
      "loss": 0.1621,
      "step": 4660
    },
    {
      "epoch": 1.3481524249422634,
      "grad_norm": 1.3309248685836792,
      "learning_rate": 0.00011014241724403387,
      "loss": 0.2147,
      "step": 4670
    },
    {
      "epoch": 1.3510392609699768,
      "grad_norm": 1.6279634237289429,
      "learning_rate": 0.00010994996150885297,
      "loss": 0.2223,
      "step": 4680
    },
    {
      "epoch": 1.3539260969976905,
      "grad_norm": 1.1809190511703491,
      "learning_rate": 0.00010975750577367205,
      "loss": 0.1566,
      "step": 4690
    },
    {
      "epoch": 1.3568129330254042,
      "grad_norm": 2.6442806720733643,
      "learning_rate": 0.00010956505003849116,
      "loss": 0.2603,
      "step": 4700
    },
    {
      "epoch": 1.3596997690531178,
      "grad_norm": 5.430359840393066,
      "learning_rate": 0.00010937259430331024,
      "loss": 0.3091,
      "step": 4710
    },
    {
      "epoch": 1.3625866050808315,
      "grad_norm": 1.9151287078857422,
      "learning_rate": 0.00010918013856812934,
      "loss": 0.1952,
      "step": 4720
    },
    {
      "epoch": 1.365473441108545,
      "grad_norm": 1.2787302732467651,
      "learning_rate": 0.00010898768283294842,
      "loss": 0.1828,
      "step": 4730
    },
    {
      "epoch": 1.3683602771362586,
      "grad_norm": 0.6774265766143799,
      "learning_rate": 0.00010879522709776753,
      "loss": 0.1755,
      "step": 4740
    },
    {
      "epoch": 1.3712471131639723,
      "grad_norm": 3.3845808506011963,
      "learning_rate": 0.00010860277136258661,
      "loss": 0.2239,
      "step": 4750
    },
    {
      "epoch": 1.374133949191686,
      "grad_norm": 1.2315351963043213,
      "learning_rate": 0.00010841031562740571,
      "loss": 0.1724,
      "step": 4760
    },
    {
      "epoch": 1.3770207852193996,
      "grad_norm": 1.517109751701355,
      "learning_rate": 0.00010821785989222479,
      "loss": 0.1857,
      "step": 4770
    },
    {
      "epoch": 1.379907621247113,
      "grad_norm": 1.8262912034988403,
      "learning_rate": 0.00010802540415704387,
      "loss": 0.2362,
      "step": 4780
    },
    {
      "epoch": 1.3827944572748267,
      "grad_norm": 0.9977124929428101,
      "learning_rate": 0.00010783294842186298,
      "loss": 0.2174,
      "step": 4790
    },
    {
      "epoch": 1.3856812933025404,
      "grad_norm": 1.1956498622894287,
      "learning_rate": 0.00010764049268668205,
      "loss": 0.1816,
      "step": 4800
    },
    {
      "epoch": 1.388568129330254,
      "grad_norm": 3.6255571842193604,
      "learning_rate": 0.00010744803695150116,
      "loss": 0.2492,
      "step": 4810
    },
    {
      "epoch": 1.3914549653579678,
      "grad_norm": 2.2280197143554688,
      "learning_rate": 0.00010725558121632025,
      "loss": 0.2468,
      "step": 4820
    },
    {
      "epoch": 1.3943418013856812,
      "grad_norm": 0.6801051497459412,
      "learning_rate": 0.00010706312548113934,
      "loss": 0.2738,
      "step": 4830
    },
    {
      "epoch": 1.3972286374133949,
      "grad_norm": 3.0080673694610596,
      "learning_rate": 0.00010687066974595843,
      "loss": 0.2038,
      "step": 4840
    },
    {
      "epoch": 1.4001154734411085,
      "grad_norm": 2.3315436840057373,
      "learning_rate": 0.00010667821401077753,
      "loss": 0.1938,
      "step": 4850
    },
    {
      "epoch": 1.4030023094688222,
      "grad_norm": 2.220329523086548,
      "learning_rate": 0.00010648575827559662,
      "loss": 0.278,
      "step": 4860
    },
    {
      "epoch": 1.4058891454965359,
      "grad_norm": 1.8860313892364502,
      "learning_rate": 0.00010629330254041571,
      "loss": 0.1839,
      "step": 4870
    },
    {
      "epoch": 1.4087759815242493,
      "grad_norm": 1.2354952096939087,
      "learning_rate": 0.0001061008468052348,
      "loss": 0.1791,
      "step": 4880
    },
    {
      "epoch": 1.411662817551963,
      "grad_norm": 1.5773154497146606,
      "learning_rate": 0.0001059083910700539,
      "loss": 0.2396,
      "step": 4890
    },
    {
      "epoch": 1.4145496535796767,
      "grad_norm": 1.3247385025024414,
      "learning_rate": 0.00010571593533487299,
      "loss": 0.2091,
      "step": 4900
    },
    {
      "epoch": 1.4174364896073903,
      "grad_norm": 2.104995012283325,
      "learning_rate": 0.00010552347959969207,
      "loss": 0.1896,
      "step": 4910
    },
    {
      "epoch": 1.420323325635104,
      "grad_norm": 5.326963901519775,
      "learning_rate": 0.00010533102386451117,
      "loss": 0.2252,
      "step": 4920
    },
    {
      "epoch": 1.4232101616628174,
      "grad_norm": 1.7734065055847168,
      "learning_rate": 0.00010513856812933025,
      "loss": 0.1662,
      "step": 4930
    },
    {
      "epoch": 1.426096997690531,
      "grad_norm": 1.441632628440857,
      "learning_rate": 0.00010494611239414935,
      "loss": 0.2298,
      "step": 4940
    },
    {
      "epoch": 1.4289838337182448,
      "grad_norm": 3.0892205238342285,
      "learning_rate": 0.00010475365665896843,
      "loss": 0.2321,
      "step": 4950
    },
    {
      "epoch": 1.4318706697459584,
      "grad_norm": 1.3473294973373413,
      "learning_rate": 0.00010456120092378754,
      "loss": 0.1805,
      "step": 4960
    },
    {
      "epoch": 1.4347575057736721,
      "grad_norm": 1.5122003555297852,
      "learning_rate": 0.00010436874518860662,
      "loss": 0.1723,
      "step": 4970
    },
    {
      "epoch": 1.4376443418013856,
      "grad_norm": 1.6003974676132202,
      "learning_rate": 0.00010417628945342572,
      "loss": 0.1943,
      "step": 4980
    },
    {
      "epoch": 1.4405311778290992,
      "grad_norm": 1.1463555097579956,
      "learning_rate": 0.0001039838337182448,
      "loss": 0.286,
      "step": 4990
    },
    {
      "epoch": 1.443418013856813,
      "grad_norm": 3.811113119125366,
      "learning_rate": 0.00010379137798306391,
      "loss": 0.2499,
      "step": 5000
    },
    {
      "epoch": 1.4463048498845266,
      "grad_norm": 2.785879611968994,
      "learning_rate": 0.000103598922247883,
      "loss": 0.2212,
      "step": 5010
    },
    {
      "epoch": 1.4491916859122402,
      "grad_norm": 2.361027717590332,
      "learning_rate": 0.00010340646651270209,
      "loss": 0.2541,
      "step": 5020
    },
    {
      "epoch": 1.4520785219399537,
      "grad_norm": 1.2994543313980103,
      "learning_rate": 0.00010321401077752117,
      "loss": 0.2697,
      "step": 5030
    },
    {
      "epoch": 1.4549653579676676,
      "grad_norm": 1.922585129737854,
      "learning_rate": 0.00010302155504234026,
      "loss": 0.1723,
      "step": 5040
    },
    {
      "epoch": 1.457852193995381,
      "grad_norm": 2.614694356918335,
      "learning_rate": 0.00010282909930715937,
      "loss": 0.2284,
      "step": 5050
    },
    {
      "epoch": 1.4607390300230947,
      "grad_norm": 1.4369192123413086,
      "learning_rate": 0.00010263664357197844,
      "loss": 0.2008,
      "step": 5060
    },
    {
      "epoch": 1.4636258660508084,
      "grad_norm": 5.522156715393066,
      "learning_rate": 0.00010244418783679755,
      "loss": 0.2354,
      "step": 5070
    },
    {
      "epoch": 1.4665127020785218,
      "grad_norm": 1.7027323246002197,
      "learning_rate": 0.00010225173210161663,
      "loss": 0.1671,
      "step": 5080
    },
    {
      "epoch": 1.4693995381062357,
      "grad_norm": 1.3495187759399414,
      "learning_rate": 0.00010205927636643572,
      "loss": 0.1872,
      "step": 5090
    },
    {
      "epoch": 1.4722863741339491,
      "grad_norm": 0.7336912155151367,
      "learning_rate": 0.00010186682063125481,
      "loss": 0.1777,
      "step": 5100
    },
    {
      "epoch": 1.4751732101616628,
      "grad_norm": 10.777290344238281,
      "learning_rate": 0.00010167436489607392,
      "loss": 0.381,
      "step": 5110
    },
    {
      "epoch": 1.4780600461893765,
      "grad_norm": 1.386451005935669,
      "learning_rate": 0.000101481909160893,
      "loss": 0.207,
      "step": 5120
    },
    {
      "epoch": 1.4809468822170901,
      "grad_norm": 0.9968231320381165,
      "learning_rate": 0.0001012894534257121,
      "loss": 0.2835,
      "step": 5130
    },
    {
      "epoch": 1.4838337182448038,
      "grad_norm": 3.289783000946045,
      "learning_rate": 0.00010109699769053118,
      "loss": 0.2446,
      "step": 5140
    },
    {
      "epoch": 1.4867205542725173,
      "grad_norm": 0.8243082165718079,
      "learning_rate": 0.00010090454195535029,
      "loss": 0.2301,
      "step": 5150
    },
    {
      "epoch": 1.489607390300231,
      "grad_norm": 2.380870819091797,
      "learning_rate": 0.00010071208622016937,
      "loss": 0.2258,
      "step": 5160
    },
    {
      "epoch": 1.4924942263279446,
      "grad_norm": 1.3789526224136353,
      "learning_rate": 0.00010051963048498844,
      "loss": 0.2054,
      "step": 5170
    },
    {
      "epoch": 1.4953810623556583,
      "grad_norm": 1.209998369216919,
      "learning_rate": 0.00010032717474980755,
      "loss": 0.1852,
      "step": 5180
    },
    {
      "epoch": 1.498267898383372,
      "grad_norm": 3.2876081466674805,
      "learning_rate": 0.00010013471901462663,
      "loss": 0.2136,
      "step": 5190
    },
    {
      "epoch": 1.5011547344110854,
      "grad_norm": 2.6030895709991455,
      "learning_rate": 9.994226327944573e-05,
      "loss": 0.2746,
      "step": 5200
    },
    {
      "epoch": 1.504041570438799,
      "grad_norm": 0.9590831995010376,
      "learning_rate": 9.974980754426483e-05,
      "loss": 0.3408,
      "step": 5210
    },
    {
      "epoch": 1.5069284064665127,
      "grad_norm": 3.5637261867523193,
      "learning_rate": 9.955735180908392e-05,
      "loss": 0.2203,
      "step": 5220
    },
    {
      "epoch": 1.5098152424942262,
      "grad_norm": 2.969714403152466,
      "learning_rate": 9.9364896073903e-05,
      "loss": 0.2153,
      "step": 5230
    },
    {
      "epoch": 1.51270207852194,
      "grad_norm": 1.2427434921264648,
      "learning_rate": 9.91724403387221e-05,
      "loss": 0.1682,
      "step": 5240
    },
    {
      "epoch": 1.5155889145496535,
      "grad_norm": 1.8668608665466309,
      "learning_rate": 9.897998460354118e-05,
      "loss": 0.1975,
      "step": 5250
    },
    {
      "epoch": 1.5184757505773672,
      "grad_norm": 0.8576165437698364,
      "learning_rate": 9.878752886836028e-05,
      "loss": 0.1317,
      "step": 5260
    },
    {
      "epoch": 1.5213625866050808,
      "grad_norm": 0.8361489772796631,
      "learning_rate": 9.859507313317938e-05,
      "loss": 0.1763,
      "step": 5270
    },
    {
      "epoch": 1.5242494226327945,
      "grad_norm": 3.6358296871185303,
      "learning_rate": 9.840261739799846e-05,
      "loss": 0.2678,
      "step": 5280
    },
    {
      "epoch": 1.5271362586605082,
      "grad_norm": 1.3071755170822144,
      "learning_rate": 9.821016166281756e-05,
      "loss": 0.2294,
      "step": 5290
    },
    {
      "epoch": 1.5300230946882216,
      "grad_norm": 1.6271921396255493,
      "learning_rate": 9.801770592763665e-05,
      "loss": 0.1447,
      "step": 5300
    },
    {
      "epoch": 1.5329099307159353,
      "grad_norm": 2.5679426193237305,
      "learning_rate": 9.782525019245575e-05,
      "loss": 0.2161,
      "step": 5310
    },
    {
      "epoch": 1.535796766743649,
      "grad_norm": 1.287044644355774,
      "learning_rate": 9.763279445727483e-05,
      "loss": 0.2626,
      "step": 5320
    },
    {
      "epoch": 1.5386836027713626,
      "grad_norm": 4.007719993591309,
      "learning_rate": 9.744033872209393e-05,
      "loss": 0.3747,
      "step": 5330
    },
    {
      "epoch": 1.5415704387990763,
      "grad_norm": 0.6637569665908813,
      "learning_rate": 9.724788298691302e-05,
      "loss": 0.2318,
      "step": 5340
    },
    {
      "epoch": 1.5444572748267897,
      "grad_norm": 1.2061069011688232,
      "learning_rate": 9.70554272517321e-05,
      "loss": 0.1937,
      "step": 5350
    },
    {
      "epoch": 1.5473441108545036,
      "grad_norm": 2.325096845626831,
      "learning_rate": 9.686297151655119e-05,
      "loss": 0.2167,
      "step": 5360
    },
    {
      "epoch": 1.550230946882217,
      "grad_norm": 1.3356012105941772,
      "learning_rate": 9.667051578137029e-05,
      "loss": 0.1954,
      "step": 5370
    },
    {
      "epoch": 1.5531177829099307,
      "grad_norm": 2.438126802444458,
      "learning_rate": 9.647806004618938e-05,
      "loss": 0.2444,
      "step": 5380
    },
    {
      "epoch": 1.5560046189376444,
      "grad_norm": 1.2195342779159546,
      "learning_rate": 9.628560431100846e-05,
      "loss": 0.2466,
      "step": 5390
    },
    {
      "epoch": 1.5588914549653579,
      "grad_norm": 0.9581784009933472,
      "learning_rate": 9.609314857582756e-05,
      "loss": 0.3489,
      "step": 5400
    },
    {
      "epoch": 1.5617782909930717,
      "grad_norm": 2.4792659282684326,
      "learning_rate": 9.590069284064666e-05,
      "loss": 0.29,
      "step": 5410
    },
    {
      "epoch": 1.5646651270207852,
      "grad_norm": 0.8000615239143372,
      "learning_rate": 9.570823710546575e-05,
      "loss": 0.2531,
      "step": 5420
    },
    {
      "epoch": 1.5675519630484989,
      "grad_norm": 1.662105679512024,
      "learning_rate": 9.551578137028484e-05,
      "loss": 0.1797,
      "step": 5430
    },
    {
      "epoch": 1.5704387990762125,
      "grad_norm": 2.933309555053711,
      "learning_rate": 9.532332563510393e-05,
      "loss": 0.2347,
      "step": 5440
    },
    {
      "epoch": 1.573325635103926,
      "grad_norm": 1.0144882202148438,
      "learning_rate": 9.513086989992303e-05,
      "loss": 0.1911,
      "step": 5450
    },
    {
      "epoch": 1.5762124711316399,
      "grad_norm": 2.763075590133667,
      "learning_rate": 9.493841416474211e-05,
      "loss": 0.1831,
      "step": 5460
    },
    {
      "epoch": 1.5790993071593533,
      "grad_norm": 3.6165521144866943,
      "learning_rate": 9.474595842956121e-05,
      "loss": 0.2237,
      "step": 5470
    },
    {
      "epoch": 1.581986143187067,
      "grad_norm": 2.985029697418213,
      "learning_rate": 9.455350269438029e-05,
      "loss": 0.2555,
      "step": 5480
    },
    {
      "epoch": 1.5848729792147807,
      "grad_norm": 2.1140475273132324,
      "learning_rate": 9.436104695919939e-05,
      "loss": 0.3251,
      "step": 5490
    },
    {
      "epoch": 1.587759815242494,
      "grad_norm": 2.3878583908081055,
      "learning_rate": 9.416859122401847e-05,
      "loss": 0.2135,
      "step": 5500
    },
    {
      "epoch": 1.590646651270208,
      "grad_norm": 0.8996657729148865,
      "learning_rate": 9.397613548883757e-05,
      "loss": 0.1747,
      "step": 5510
    },
    {
      "epoch": 1.5935334872979214,
      "grad_norm": 2.9634037017822266,
      "learning_rate": 9.378367975365666e-05,
      "loss": 0.2719,
      "step": 5520
    },
    {
      "epoch": 1.596420323325635,
      "grad_norm": 9.37791633605957,
      "learning_rate": 9.359122401847576e-05,
      "loss": 0.3524,
      "step": 5530
    },
    {
      "epoch": 1.5993071593533488,
      "grad_norm": 1.8161855936050415,
      "learning_rate": 9.339876828329484e-05,
      "loss": 0.2564,
      "step": 5540
    },
    {
      "epoch": 1.6021939953810622,
      "grad_norm": 1.4814691543579102,
      "learning_rate": 9.320631254811394e-05,
      "loss": 0.376,
      "step": 5550
    },
    {
      "epoch": 1.605080831408776,
      "grad_norm": 7.374812126159668,
      "learning_rate": 9.301385681293303e-05,
      "loss": 0.1975,
      "step": 5560
    },
    {
      "epoch": 1.6079676674364896,
      "grad_norm": 1.2804152965545654,
      "learning_rate": 9.282140107775212e-05,
      "loss": 0.2713,
      "step": 5570
    },
    {
      "epoch": 1.6108545034642032,
      "grad_norm": 1.093916416168213,
      "learning_rate": 9.262894534257121e-05,
      "loss": 0.1972,
      "step": 5580
    },
    {
      "epoch": 1.613741339491917,
      "grad_norm": 1.3290082216262817,
      "learning_rate": 9.243648960739031e-05,
      "loss": 0.2592,
      "step": 5590
    },
    {
      "epoch": 1.6166281755196303,
      "grad_norm": 1.3841832876205444,
      "learning_rate": 9.22440338722094e-05,
      "loss": 0.1599,
      "step": 5600
    },
    {
      "epoch": 1.6195150115473442,
      "grad_norm": 0.7137064933776855,
      "learning_rate": 9.205157813702849e-05,
      "loss": 0.2402,
      "step": 5610
    },
    {
      "epoch": 1.6224018475750577,
      "grad_norm": 1.0975559949874878,
      "learning_rate": 9.185912240184757e-05,
      "loss": 0.22,
      "step": 5620
    },
    {
      "epoch": 1.6252886836027713,
      "grad_norm": 5.331681251525879,
      "learning_rate": 9.166666666666667e-05,
      "loss": 0.2408,
      "step": 5630
    },
    {
      "epoch": 1.628175519630485,
      "grad_norm": 1.1842358112335205,
      "learning_rate": 9.147421093148576e-05,
      "loss": 0.1892,
      "step": 5640
    },
    {
      "epoch": 1.6310623556581985,
      "grad_norm": 1.2625956535339355,
      "learning_rate": 9.128175519630485e-05,
      "loss": 0.2003,
      "step": 5650
    },
    {
      "epoch": 1.6339491916859123,
      "grad_norm": 2.8599255084991455,
      "learning_rate": 9.108929946112394e-05,
      "loss": 0.212,
      "step": 5660
    },
    {
      "epoch": 1.6368360277136258,
      "grad_norm": 2.485016107559204,
      "learning_rate": 9.089684372594304e-05,
      "loss": 0.3162,
      "step": 5670
    },
    {
      "epoch": 1.6397228637413395,
      "grad_norm": 1.350156545639038,
      "learning_rate": 9.070438799076214e-05,
      "loss": 0.1826,
      "step": 5680
    },
    {
      "epoch": 1.6426096997690531,
      "grad_norm": 1.146393060684204,
      "learning_rate": 9.051193225558122e-05,
      "loss": 0.1573,
      "step": 5690
    },
    {
      "epoch": 1.6454965357967666,
      "grad_norm": 4.640774726867676,
      "learning_rate": 9.031947652040031e-05,
      "loss": 0.1851,
      "step": 5700
    },
    {
      "epoch": 1.6483833718244805,
      "grad_norm": 0.6822082996368408,
      "learning_rate": 9.012702078521941e-05,
      "loss": 0.2025,
      "step": 5710
    },
    {
      "epoch": 1.651270207852194,
      "grad_norm": 1.4660382270812988,
      "learning_rate": 8.99345650500385e-05,
      "loss": 0.2314,
      "step": 5720
    },
    {
      "epoch": 1.6541570438799076,
      "grad_norm": 0.6437276601791382,
      "learning_rate": 8.974210931485759e-05,
      "loss": 0.1931,
      "step": 5730
    },
    {
      "epoch": 1.6570438799076213,
      "grad_norm": 1.563296914100647,
      "learning_rate": 8.954965357967667e-05,
      "loss": 0.207,
      "step": 5740
    },
    {
      "epoch": 1.659930715935335,
      "grad_norm": 2.308838367462158,
      "learning_rate": 8.935719784449577e-05,
      "loss": 0.2524,
      "step": 5750
    },
    {
      "epoch": 1.6628175519630486,
      "grad_norm": 2.245077610015869,
      "learning_rate": 8.916474210931485e-05,
      "loss": 0.2047,
      "step": 5760
    },
    {
      "epoch": 1.665704387990762,
      "grad_norm": 1.7811574935913086,
      "learning_rate": 8.897228637413395e-05,
      "loss": 0.1914,
      "step": 5770
    },
    {
      "epoch": 1.6685912240184757,
      "grad_norm": 3.8792779445648193,
      "learning_rate": 8.877983063895304e-05,
      "loss": 0.2888,
      "step": 5780
    },
    {
      "epoch": 1.6714780600461894,
      "grad_norm": 6.075738906860352,
      "learning_rate": 8.858737490377214e-05,
      "loss": 0.1778,
      "step": 5790
    },
    {
      "epoch": 1.674364896073903,
      "grad_norm": 2.0503835678100586,
      "learning_rate": 8.839491916859122e-05,
      "loss": 0.2865,
      "step": 5800
    },
    {
      "epoch": 1.6772517321016167,
      "grad_norm": 3.1082427501678467,
      "learning_rate": 8.820246343341032e-05,
      "loss": 0.2635,
      "step": 5810
    },
    {
      "epoch": 1.6801385681293302,
      "grad_norm": 1.2224247455596924,
      "learning_rate": 8.801000769822942e-05,
      "loss": 0.274,
      "step": 5820
    },
    {
      "epoch": 1.6830254041570438,
      "grad_norm": 2.165173053741455,
      "learning_rate": 8.78175519630485e-05,
      "loss": 0.2422,
      "step": 5830
    },
    {
      "epoch": 1.6859122401847575,
      "grad_norm": 3.362105131149292,
      "learning_rate": 8.76250962278676e-05,
      "loss": 0.205,
      "step": 5840
    },
    {
      "epoch": 1.6887990762124712,
      "grad_norm": 1.3534049987792969,
      "learning_rate": 8.743264049268669e-05,
      "loss": 0.218,
      "step": 5850
    },
    {
      "epoch": 1.6916859122401848,
      "grad_norm": 0.7201281785964966,
      "learning_rate": 8.724018475750579e-05,
      "loss": 0.1352,
      "step": 5860
    },
    {
      "epoch": 1.6945727482678983,
      "grad_norm": 1.383217215538025,
      "learning_rate": 8.704772902232487e-05,
      "loss": 0.2277,
      "step": 5870
    },
    {
      "epoch": 1.6974595842956122,
      "grad_norm": 3.725404977798462,
      "learning_rate": 8.685527328714395e-05,
      "loss": 0.2033,
      "step": 5880
    },
    {
      "epoch": 1.7003464203233256,
      "grad_norm": 1.961517572402954,
      "learning_rate": 8.666281755196305e-05,
      "loss": 0.201,
      "step": 5890
    },
    {
      "epoch": 1.7032332563510393,
      "grad_norm": 10.651286125183105,
      "learning_rate": 8.647036181678215e-05,
      "loss": 0.3183,
      "step": 5900
    },
    {
      "epoch": 1.706120092378753,
      "grad_norm": 3.4502851963043213,
      "learning_rate": 8.627790608160123e-05,
      "loss": 0.1873,
      "step": 5910
    },
    {
      "epoch": 1.7090069284064664,
      "grad_norm": 1.376074194908142,
      "learning_rate": 8.608545034642033e-05,
      "loss": 0.215,
      "step": 5920
    },
    {
      "epoch": 1.7118937644341803,
      "grad_norm": 2.651148796081543,
      "learning_rate": 8.589299461123942e-05,
      "loss": 0.2901,
      "step": 5930
    },
    {
      "epoch": 1.7147806004618937,
      "grad_norm": 1.606379747390747,
      "learning_rate": 8.570053887605852e-05,
      "loss": 0.2313,
      "step": 5940
    },
    {
      "epoch": 1.7176674364896074,
      "grad_norm": 4.879351615905762,
      "learning_rate": 8.55080831408776e-05,
      "loss": 0.2823,
      "step": 5950
    },
    {
      "epoch": 1.720554272517321,
      "grad_norm": 1.4482945203781128,
      "learning_rate": 8.53156274056967e-05,
      "loss": 0.2358,
      "step": 5960
    },
    {
      "epoch": 1.7234411085450345,
      "grad_norm": 1.5660120248794556,
      "learning_rate": 8.512317167051579e-05,
      "loss": 0.1759,
      "step": 5970
    },
    {
      "epoch": 1.7263279445727484,
      "grad_norm": 1.154565453529358,
      "learning_rate": 8.493071593533488e-05,
      "loss": 0.3671,
      "step": 5980
    },
    {
      "epoch": 1.7292147806004619,
      "grad_norm": 1.1629350185394287,
      "learning_rate": 8.473826020015397e-05,
      "loss": 0.1721,
      "step": 5990
    },
    {
      "epoch": 1.7321016166281755,
      "grad_norm": 3.7621376514434814,
      "learning_rate": 8.454580446497305e-05,
      "loss": 0.2014,
      "step": 6000
    },
    {
      "epoch": 1.7349884526558892,
      "grad_norm": 3.300766706466675,
      "learning_rate": 8.435334872979215e-05,
      "loss": 0.2181,
      "step": 6010
    },
    {
      "epoch": 1.7378752886836026,
      "grad_norm": 1.6105533838272095,
      "learning_rate": 8.416089299461123e-05,
      "loss": 0.2309,
      "step": 6020
    },
    {
      "epoch": 1.7407621247113165,
      "grad_norm": 1.6800981760025024,
      "learning_rate": 8.396843725943033e-05,
      "loss": 0.1997,
      "step": 6030
    },
    {
      "epoch": 1.74364896073903,
      "grad_norm": 0.6548255085945129,
      "learning_rate": 8.377598152424943e-05,
      "loss": 0.2872,
      "step": 6040
    },
    {
      "epoch": 1.7465357967667436,
      "grad_norm": 1.6674046516418457,
      "learning_rate": 8.358352578906852e-05,
      "loss": 0.2125,
      "step": 6050
    },
    {
      "epoch": 1.7494226327944573,
      "grad_norm": 0.7314164638519287,
      "learning_rate": 8.33910700538876e-05,
      "loss": 0.2725,
      "step": 6060
    },
    {
      "epoch": 1.7523094688221708,
      "grad_norm": 1.7496997117996216,
      "learning_rate": 8.31986143187067e-05,
      "loss": 0.1854,
      "step": 6070
    },
    {
      "epoch": 1.7551963048498846,
      "grad_norm": 8.596126556396484,
      "learning_rate": 8.30061585835258e-05,
      "loss": 0.3318,
      "step": 6080
    },
    {
      "epoch": 1.758083140877598,
      "grad_norm": 5.857335090637207,
      "learning_rate": 8.281370284834488e-05,
      "loss": 0.2172,
      "step": 6090
    },
    {
      "epoch": 1.7609699769053118,
      "grad_norm": 2.164278984069824,
      "learning_rate": 8.262124711316398e-05,
      "loss": 0.2351,
      "step": 6100
    },
    {
      "epoch": 1.7638568129330254,
      "grad_norm": 2.4038848876953125,
      "learning_rate": 8.242879137798307e-05,
      "loss": 0.1706,
      "step": 6110
    },
    {
      "epoch": 1.7667436489607389,
      "grad_norm": 1.1288342475891113,
      "learning_rate": 8.223633564280217e-05,
      "loss": 0.1981,
      "step": 6120
    },
    {
      "epoch": 1.7696304849884528,
      "grad_norm": 2.8832082748413086,
      "learning_rate": 8.204387990762125e-05,
      "loss": 0.2614,
      "step": 6130
    },
    {
      "epoch": 1.7725173210161662,
      "grad_norm": 0.6959365010261536,
      "learning_rate": 8.185142417244034e-05,
      "loss": 0.1978,
      "step": 6140
    },
    {
      "epoch": 1.7754041570438799,
      "grad_norm": 3.1969876289367676,
      "learning_rate": 8.165896843725943e-05,
      "loss": 0.2661,
      "step": 6150
    },
    {
      "epoch": 1.7782909930715936,
      "grad_norm": 2.108030319213867,
      "learning_rate": 8.146651270207853e-05,
      "loss": 0.184,
      "step": 6160
    },
    {
      "epoch": 1.781177829099307,
      "grad_norm": 0.5927799940109253,
      "learning_rate": 8.127405696689761e-05,
      "loss": 0.1986,
      "step": 6170
    },
    {
      "epoch": 1.7840646651270209,
      "grad_norm": 2.315894365310669,
      "learning_rate": 8.108160123171671e-05,
      "loss": 0.2229,
      "step": 6180
    },
    {
      "epoch": 1.7869515011547343,
      "grad_norm": 1.9581621885299683,
      "learning_rate": 8.08891454965358e-05,
      "loss": 0.2308,
      "step": 6190
    },
    {
      "epoch": 1.789838337182448,
      "grad_norm": 1.457806944847107,
      "learning_rate": 8.06966897613549e-05,
      "loss": 0.211,
      "step": 6200
    },
    {
      "epoch": 1.7927251732101617,
      "grad_norm": 0.751487135887146,
      "learning_rate": 8.050423402617398e-05,
      "loss": 0.2063,
      "step": 6210
    },
    {
      "epoch": 1.7956120092378753,
      "grad_norm": 0.7953484654426575,
      "learning_rate": 8.031177829099308e-05,
      "loss": 0.2205,
      "step": 6220
    },
    {
      "epoch": 1.798498845265589,
      "grad_norm": 2.939570188522339,
      "learning_rate": 8.011932255581218e-05,
      "loss": 0.2712,
      "step": 6230
    },
    {
      "epoch": 1.8013856812933025,
      "grad_norm": 1.0496140718460083,
      "learning_rate": 7.992686682063126e-05,
      "loss": 0.2983,
      "step": 6240
    },
    {
      "epoch": 1.8042725173210161,
      "grad_norm": 3.7078194618225098,
      "learning_rate": 7.973441108545035e-05,
      "loss": 0.2018,
      "step": 6250
    },
    {
      "epoch": 1.8071593533487298,
      "grad_norm": 1.9235193729400635,
      "learning_rate": 7.954195535026944e-05,
      "loss": 0.2937,
      "step": 6260
    },
    {
      "epoch": 1.8100461893764435,
      "grad_norm": 2.345731258392334,
      "learning_rate": 7.934949961508853e-05,
      "loss": 0.3462,
      "step": 6270
    },
    {
      "epoch": 1.8129330254041571,
      "grad_norm": 1.4965107440948486,
      "learning_rate": 7.915704387990762e-05,
      "loss": 0.2068,
      "step": 6280
    },
    {
      "epoch": 1.8158198614318706,
      "grad_norm": 0.9224156737327576,
      "learning_rate": 7.896458814472671e-05,
      "loss": 0.2223,
      "step": 6290
    },
    {
      "epoch": 1.8187066974595842,
      "grad_norm": 2.775499105453491,
      "learning_rate": 7.877213240954581e-05,
      "loss": 0.1978,
      "step": 6300
    },
    {
      "epoch": 1.821593533487298,
      "grad_norm": 1.3270492553710938,
      "learning_rate": 7.85796766743649e-05,
      "loss": 0.2282,
      "step": 6310
    },
    {
      "epoch": 1.8244803695150116,
      "grad_norm": 2.6249501705169678,
      "learning_rate": 7.838722093918399e-05,
      "loss": 0.2315,
      "step": 6320
    },
    {
      "epoch": 1.8273672055427252,
      "grad_norm": 1.7376563549041748,
      "learning_rate": 7.819476520400308e-05,
      "loss": 0.1633,
      "step": 6330
    },
    {
      "epoch": 1.8302540415704387,
      "grad_norm": 2.1802902221679688,
      "learning_rate": 7.800230946882218e-05,
      "loss": 0.3957,
      "step": 6340
    },
    {
      "epoch": 1.8331408775981526,
      "grad_norm": 2.222564697265625,
      "learning_rate": 7.780985373364126e-05,
      "loss": 0.2135,
      "step": 6350
    },
    {
      "epoch": 1.836027713625866,
      "grad_norm": 0.74897301197052,
      "learning_rate": 7.761739799846036e-05,
      "loss": 0.1994,
      "step": 6360
    },
    {
      "epoch": 1.8389145496535797,
      "grad_norm": 1.6887826919555664,
      "learning_rate": 7.742494226327946e-05,
      "loss": 0.2314,
      "step": 6370
    },
    {
      "epoch": 1.8418013856812934,
      "grad_norm": 0.8879395723342896,
      "learning_rate": 7.723248652809855e-05,
      "loss": 0.2036,
      "step": 6380
    },
    {
      "epoch": 1.8446882217090068,
      "grad_norm": 1.0568639039993286,
      "learning_rate": 7.704003079291762e-05,
      "loss": 0.1402,
      "step": 6390
    },
    {
      "epoch": 1.8475750577367207,
      "grad_norm": 5.7510199546813965,
      "learning_rate": 7.684757505773672e-05,
      "loss": 0.219,
      "step": 6400
    },
    {
      "epoch": 1.8504618937644342,
      "grad_norm": 0.6673204898834229,
      "learning_rate": 7.665511932255581e-05,
      "loss": 0.2127,
      "step": 6410
    },
    {
      "epoch": 1.8533487297921478,
      "grad_norm": 1.474047064781189,
      "learning_rate": 7.646266358737491e-05,
      "loss": 0.2412,
      "step": 6420
    },
    {
      "epoch": 1.8562355658198615,
      "grad_norm": 1.2108428478240967,
      "learning_rate": 7.627020785219399e-05,
      "loss": 0.2948,
      "step": 6430
    },
    {
      "epoch": 1.859122401847575,
      "grad_norm": 4.466065406799316,
      "learning_rate": 7.607775211701309e-05,
      "loss": 0.2092,
      "step": 6440
    },
    {
      "epoch": 1.8620092378752888,
      "grad_norm": 4.028834342956543,
      "learning_rate": 7.588529638183219e-05,
      "loss": 0.2496,
      "step": 6450
    },
    {
      "epoch": 1.8648960739030023,
      "grad_norm": 19.443662643432617,
      "learning_rate": 7.569284064665127e-05,
      "loss": 0.2715,
      "step": 6460
    },
    {
      "epoch": 1.867782909930716,
      "grad_norm": 1.8988678455352783,
      "learning_rate": 7.550038491147036e-05,
      "loss": 0.192,
      "step": 6470
    },
    {
      "epoch": 1.8706697459584296,
      "grad_norm": 1.9340897798538208,
      "learning_rate": 7.530792917628946e-05,
      "loss": 0.268,
      "step": 6480
    },
    {
      "epoch": 1.873556581986143,
      "grad_norm": 1.4141223430633545,
      "learning_rate": 7.511547344110856e-05,
      "loss": 0.2971,
      "step": 6490
    },
    {
      "epoch": 1.876443418013857,
      "grad_norm": 2.2003235816955566,
      "learning_rate": 7.492301770592764e-05,
      "loss": 0.2238,
      "step": 6500
    },
    {
      "epoch": 1.8793302540415704,
      "grad_norm": 2.444739818572998,
      "learning_rate": 7.473056197074672e-05,
      "loss": 0.1777,
      "step": 6510
    },
    {
      "epoch": 1.882217090069284,
      "grad_norm": 1.6120741367340088,
      "learning_rate": 7.453810623556582e-05,
      "loss": 0.1401,
      "step": 6520
    },
    {
      "epoch": 1.8851039260969977,
      "grad_norm": 1.2538516521453857,
      "learning_rate": 7.434565050038492e-05,
      "loss": 0.2075,
      "step": 6530
    },
    {
      "epoch": 1.8879907621247112,
      "grad_norm": 3.124474287033081,
      "learning_rate": 7.4153194765204e-05,
      "loss": 0.1821,
      "step": 6540
    },
    {
      "epoch": 1.890877598152425,
      "grad_norm": 6.304029941558838,
      "learning_rate": 7.39607390300231e-05,
      "loss": 0.1773,
      "step": 6550
    },
    {
      "epoch": 1.8937644341801385,
      "grad_norm": 0.7144479751586914,
      "learning_rate": 7.376828329484219e-05,
      "loss": 0.161,
      "step": 6560
    },
    {
      "epoch": 1.8966512702078522,
      "grad_norm": 2.8881144523620605,
      "learning_rate": 7.357582755966129e-05,
      "loss": 0.222,
      "step": 6570
    },
    {
      "epoch": 1.8995381062355658,
      "grad_norm": 2.097445011138916,
      "learning_rate": 7.338337182448037e-05,
      "loss": 0.3138,
      "step": 6580
    },
    {
      "epoch": 1.9024249422632793,
      "grad_norm": 0.5982488393783569,
      "learning_rate": 7.319091608929947e-05,
      "loss": 0.2816,
      "step": 6590
    },
    {
      "epoch": 1.9053117782909932,
      "grad_norm": 2.275055408477783,
      "learning_rate": 7.299846035411856e-05,
      "loss": 0.3134,
      "step": 6600
    },
    {
      "epoch": 1.9081986143187066,
      "grad_norm": 0.8688391447067261,
      "learning_rate": 7.280600461893765e-05,
      "loss": 0.2896,
      "step": 6610
    },
    {
      "epoch": 1.9110854503464203,
      "grad_norm": 2.3087477684020996,
      "learning_rate": 7.261354888375674e-05,
      "loss": 0.2038,
      "step": 6620
    },
    {
      "epoch": 1.913972286374134,
      "grad_norm": 4.030955791473389,
      "learning_rate": 7.242109314857584e-05,
      "loss": 0.19,
      "step": 6630
    },
    {
      "epoch": 1.9168591224018474,
      "grad_norm": 1.268822431564331,
      "learning_rate": 7.222863741339492e-05,
      "loss": 0.3025,
      "step": 6640
    },
    {
      "epoch": 1.9197459584295613,
      "grad_norm": 12.451180458068848,
      "learning_rate": 7.2036181678214e-05,
      "loss": 0.3503,
      "step": 6650
    },
    {
      "epoch": 1.9226327944572748,
      "grad_norm": 2.7522263526916504,
      "learning_rate": 7.18437259430331e-05,
      "loss": 0.2053,
      "step": 6660
    },
    {
      "epoch": 1.9255196304849884,
      "grad_norm": 1.021539568901062,
      "learning_rate": 7.16512702078522e-05,
      "loss": 0.1835,
      "step": 6670
    },
    {
      "epoch": 1.928406466512702,
      "grad_norm": 0.6798906922340393,
      "learning_rate": 7.145881447267129e-05,
      "loss": 0.2326,
      "step": 6680
    },
    {
      "epoch": 1.9312933025404158,
      "grad_norm": 1.6275721788406372,
      "learning_rate": 7.126635873749038e-05,
      "loss": 0.3321,
      "step": 6690
    },
    {
      "epoch": 1.9341801385681294,
      "grad_norm": 0.8517276644706726,
      "learning_rate": 7.107390300230947e-05,
      "loss": 0.2213,
      "step": 6700
    },
    {
      "epoch": 1.9370669745958429,
      "grad_norm": 1.7076956033706665,
      "learning_rate": 7.088144726712857e-05,
      "loss": 0.1765,
      "step": 6710
    },
    {
      "epoch": 1.9399538106235565,
      "grad_norm": 0.992560088634491,
      "learning_rate": 7.068899153194765e-05,
      "loss": 0.189,
      "step": 6720
    },
    {
      "epoch": 1.9428406466512702,
      "grad_norm": 2.61301589012146,
      "learning_rate": 7.049653579676675e-05,
      "loss": 0.2368,
      "step": 6730
    },
    {
      "epoch": 1.9457274826789839,
      "grad_norm": 2.407742500305176,
      "learning_rate": 7.030408006158584e-05,
      "loss": 0.2011,
      "step": 6740
    },
    {
      "epoch": 1.9486143187066975,
      "grad_norm": 1.1030454635620117,
      "learning_rate": 7.011162432640494e-05,
      "loss": 0.2015,
      "step": 6750
    },
    {
      "epoch": 1.951501154734411,
      "grad_norm": 1.7438071966171265,
      "learning_rate": 6.991916859122402e-05,
      "loss": 0.4542,
      "step": 6760
    },
    {
      "epoch": 1.9543879907621247,
      "grad_norm": 1.5028098821640015,
      "learning_rate": 6.97267128560431e-05,
      "loss": 0.2045,
      "step": 6770
    },
    {
      "epoch": 1.9572748267898383,
      "grad_norm": 0.832660973072052,
      "learning_rate": 6.95342571208622e-05,
      "loss": 0.3499,
      "step": 6780
    },
    {
      "epoch": 1.960161662817552,
      "grad_norm": 5.240871906280518,
      "learning_rate": 6.93418013856813e-05,
      "loss": 0.1965,
      "step": 6790
    },
    {
      "epoch": 1.9630484988452657,
      "grad_norm": 1.2971272468566895,
      "learning_rate": 6.914934565050038e-05,
      "loss": 0.1983,
      "step": 6800
    },
    {
      "epoch": 1.9659353348729791,
      "grad_norm": 2.0662686824798584,
      "learning_rate": 6.895688991531948e-05,
      "loss": 0.3741,
      "step": 6810
    },
    {
      "epoch": 1.968822170900693,
      "grad_norm": 0.7419613003730774,
      "learning_rate": 6.876443418013857e-05,
      "loss": 0.1742,
      "step": 6820
    },
    {
      "epoch": 1.9717090069284064,
      "grad_norm": 4.165463924407959,
      "learning_rate": 6.857197844495767e-05,
      "loss": 0.235,
      "step": 6830
    },
    {
      "epoch": 1.9745958429561201,
      "grad_norm": 1.0380257368087769,
      "learning_rate": 6.837952270977675e-05,
      "loss": 0.2107,
      "step": 6840
    },
    {
      "epoch": 1.9774826789838338,
      "grad_norm": 0.9387643337249756,
      "learning_rate": 6.818706697459585e-05,
      "loss": 0.2005,
      "step": 6850
    },
    {
      "epoch": 1.9803695150115472,
      "grad_norm": 2.7640380859375,
      "learning_rate": 6.799461123941494e-05,
      "loss": 0.1797,
      "step": 6860
    },
    {
      "epoch": 1.9832563510392611,
      "grad_norm": 0.6359995603561401,
      "learning_rate": 6.780215550423403e-05,
      "loss": 0.2599,
      "step": 6870
    },
    {
      "epoch": 1.9861431870669746,
      "grad_norm": 2.2196285724639893,
      "learning_rate": 6.760969976905312e-05,
      "loss": 0.3368,
      "step": 6880
    },
    {
      "epoch": 1.9890300230946882,
      "grad_norm": 1.8980833292007446,
      "learning_rate": 6.741724403387222e-05,
      "loss": 0.3157,
      "step": 6890
    },
    {
      "epoch": 1.991916859122402,
      "grad_norm": 1.5227938890457153,
      "learning_rate": 6.72247882986913e-05,
      "loss": 0.1548,
      "step": 6900
    },
    {
      "epoch": 1.9948036951501154,
      "grad_norm": 2.6356518268585205,
      "learning_rate": 6.703233256351039e-05,
      "loss": 0.2051,
      "step": 6910
    },
    {
      "epoch": 1.9976905311778292,
      "grad_norm": 4.726588249206543,
      "learning_rate": 6.683987682832948e-05,
      "loss": 0.2139,
      "step": 6920
    },
    {
      "epoch": 2.0005773672055427,
      "grad_norm": 1.721454381942749,
      "learning_rate": 6.664742109314858e-05,
      "loss": 0.1827,
      "step": 6930
    },
    {
      "epoch": 2.003464203233256,
      "grad_norm": 4.830652236938477,
      "learning_rate": 6.645496535796767e-05,
      "loss": 0.2366,
      "step": 6940
    },
    {
      "epoch": 2.00635103926097,
      "grad_norm": 3.619009494781494,
      "learning_rate": 6.626250962278676e-05,
      "loss": 0.1872,
      "step": 6950
    },
    {
      "epoch": 2.0092378752886835,
      "grad_norm": 3.8312647342681885,
      "learning_rate": 6.607005388760585e-05,
      "loss": 0.1872,
      "step": 6960
    },
    {
      "epoch": 2.0121247113163974,
      "grad_norm": 1.1249581575393677,
      "learning_rate": 6.587759815242495e-05,
      "loss": 0.3055,
      "step": 6970
    },
    {
      "epoch": 2.015011547344111,
      "grad_norm": 2.207777500152588,
      "learning_rate": 6.568514241724403e-05,
      "loss": 0.1766,
      "step": 6980
    },
    {
      "epoch": 2.0178983833718247,
      "grad_norm": 1.300890564918518,
      "learning_rate": 6.549268668206313e-05,
      "loss": 0.184,
      "step": 6990
    },
    {
      "epoch": 2.020785219399538,
      "grad_norm": 1.2200461626052856,
      "learning_rate": 6.530023094688223e-05,
      "loss": 0.1756,
      "step": 7000
    },
    {
      "epoch": 2.0236720554272516,
      "grad_norm": 4.2242255210876465,
      "learning_rate": 6.510777521170132e-05,
      "loss": 0.2103,
      "step": 7010
    },
    {
      "epoch": 2.0265588914549655,
      "grad_norm": 2.9153945446014404,
      "learning_rate": 6.49153194765204e-05,
      "loss": 0.2154,
      "step": 7020
    },
    {
      "epoch": 2.029445727482679,
      "grad_norm": 2.171065092086792,
      "learning_rate": 6.472286374133949e-05,
      "loss": 0.1686,
      "step": 7030
    },
    {
      "epoch": 2.032332563510393,
      "grad_norm": 0.9652217030525208,
      "learning_rate": 6.453040800615858e-05,
      "loss": 0.2203,
      "step": 7040
    },
    {
      "epoch": 2.0352193995381063,
      "grad_norm": 1.4860241413116455,
      "learning_rate": 6.433795227097768e-05,
      "loss": 0.2008,
      "step": 7050
    },
    {
      "epoch": 2.0381062355658197,
      "grad_norm": 3.4675660133361816,
      "learning_rate": 6.414549653579676e-05,
      "loss": 0.3283,
      "step": 7060
    },
    {
      "epoch": 2.0409930715935336,
      "grad_norm": 3.3061251640319824,
      "learning_rate": 6.395304080061586e-05,
      "loss": 0.1782,
      "step": 7070
    },
    {
      "epoch": 2.043879907621247,
      "grad_norm": 1.2223650217056274,
      "learning_rate": 6.376058506543496e-05,
      "loss": 0.1781,
      "step": 7080
    },
    {
      "epoch": 2.046766743648961,
      "grad_norm": 0.9348529577255249,
      "learning_rate": 6.356812933025405e-05,
      "loss": 0.2236,
      "step": 7090
    },
    {
      "epoch": 2.0496535796766744,
      "grad_norm": 1.399999737739563,
      "learning_rate": 6.337567359507313e-05,
      "loss": 0.2618,
      "step": 7100
    },
    {
      "epoch": 2.052540415704388,
      "grad_norm": 2.148583173751831,
      "learning_rate": 6.318321785989223e-05,
      "loss": 0.1932,
      "step": 7110
    },
    {
      "epoch": 2.0554272517321017,
      "grad_norm": 2.275782585144043,
      "learning_rate": 6.299076212471133e-05,
      "loss": 0.1741,
      "step": 7120
    },
    {
      "epoch": 2.058314087759815,
      "grad_norm": 1.794968605041504,
      "learning_rate": 6.279830638953041e-05,
      "loss": 0.1762,
      "step": 7130
    },
    {
      "epoch": 2.061200923787529,
      "grad_norm": 3.20688796043396,
      "learning_rate": 6.26058506543495e-05,
      "loss": 0.2395,
      "step": 7140
    },
    {
      "epoch": 2.0640877598152425,
      "grad_norm": 1.580950140953064,
      "learning_rate": 6.24133949191686e-05,
      "loss": 0.1834,
      "step": 7150
    },
    {
      "epoch": 2.066974595842956,
      "grad_norm": 3.1717023849487305,
      "learning_rate": 6.222093918398768e-05,
      "loss": 0.1775,
      "step": 7160
    },
    {
      "epoch": 2.06986143187067,
      "grad_norm": 0.7792921662330627,
      "learning_rate": 6.202848344880677e-05,
      "loss": 0.1763,
      "step": 7170
    },
    {
      "epoch": 2.0727482678983833,
      "grad_norm": 1.4496129751205444,
      "learning_rate": 6.183602771362586e-05,
      "loss": 0.1787,
      "step": 7180
    },
    {
      "epoch": 2.075635103926097,
      "grad_norm": 0.7379891872406006,
      "learning_rate": 6.164357197844496e-05,
      "loss": 0.1791,
      "step": 7190
    },
    {
      "epoch": 2.0785219399538106,
      "grad_norm": 10.642041206359863,
      "learning_rate": 6.145111624326406e-05,
      "loss": 0.2761,
      "step": 7200
    },
    {
      "epoch": 2.081408775981524,
      "grad_norm": 0.7633614540100098,
      "learning_rate": 6.125866050808314e-05,
      "loss": 0.1491,
      "step": 7210
    },
    {
      "epoch": 2.084295612009238,
      "grad_norm": 2.0060815811157227,
      "learning_rate": 6.106620477290224e-05,
      "loss": 0.2476,
      "step": 7220
    },
    {
      "epoch": 2.0871824480369514,
      "grad_norm": 1.3465676307678223,
      "learning_rate": 6.0873749037721325e-05,
      "loss": 0.2288,
      "step": 7230
    },
    {
      "epoch": 2.0900692840646653,
      "grad_norm": 1.359173059463501,
      "learning_rate": 6.068129330254042e-05,
      "loss": 0.216,
      "step": 7240
    },
    {
      "epoch": 2.0929561200923787,
      "grad_norm": 0.828046977519989,
      "learning_rate": 6.048883756735951e-05,
      "loss": 0.2418,
      "step": 7250
    },
    {
      "epoch": 2.095842956120092,
      "grad_norm": 1.2933759689331055,
      "learning_rate": 6.029638183217861e-05,
      "loss": 0.3081,
      "step": 7260
    },
    {
      "epoch": 2.098729792147806,
      "grad_norm": 0.9779127240180969,
      "learning_rate": 6.01039260969977e-05,
      "loss": 0.1963,
      "step": 7270
    },
    {
      "epoch": 2.1016166281755195,
      "grad_norm": 0.7576581835746765,
      "learning_rate": 5.991147036181679e-05,
      "loss": 0.2401,
      "step": 7280
    },
    {
      "epoch": 2.1045034642032334,
      "grad_norm": 0.5875297784805298,
      "learning_rate": 5.971901462663587e-05,
      "loss": 0.1886,
      "step": 7290
    },
    {
      "epoch": 2.107390300230947,
      "grad_norm": 2.4450864791870117,
      "learning_rate": 5.9526558891454965e-05,
      "loss": 0.1807,
      "step": 7300
    },
    {
      "epoch": 2.1102771362586603,
      "grad_norm": 2.573160409927368,
      "learning_rate": 5.9334103156274055e-05,
      "loss": 0.2158,
      "step": 7310
    },
    {
      "epoch": 2.113163972286374,
      "grad_norm": 1.5424673557281494,
      "learning_rate": 5.914164742109315e-05,
      "loss": 0.1675,
      "step": 7320
    },
    {
      "epoch": 2.1160508083140877,
      "grad_norm": 7.723022937774658,
      "learning_rate": 5.894919168591224e-05,
      "loss": 0.1941,
      "step": 7330
    },
    {
      "epoch": 2.1189376443418015,
      "grad_norm": 1.2513946294784546,
      "learning_rate": 5.875673595073134e-05,
      "loss": 0.2383,
      "step": 7340
    },
    {
      "epoch": 2.121824480369515,
      "grad_norm": 2.6434874534606934,
      "learning_rate": 5.856428021555043e-05,
      "loss": 0.1663,
      "step": 7350
    },
    {
      "epoch": 2.1247113163972284,
      "grad_norm": 1.4080718755722046,
      "learning_rate": 5.8371824480369516e-05,
      "loss": 0.2402,
      "step": 7360
    },
    {
      "epoch": 2.1275981524249423,
      "grad_norm": 1.1519759893417358,
      "learning_rate": 5.817936874518861e-05,
      "loss": 0.1978,
      "step": 7370
    },
    {
      "epoch": 2.1304849884526558,
      "grad_norm": 1.973572015762329,
      "learning_rate": 5.79869130100077e-05,
      "loss": 0.2056,
      "step": 7380
    },
    {
      "epoch": 2.1333718244803697,
      "grad_norm": 3.216824531555176,
      "learning_rate": 5.77944572748268e-05,
      "loss": 0.2145,
      "step": 7390
    },
    {
      "epoch": 2.136258660508083,
      "grad_norm": 2.131768226623535,
      "learning_rate": 5.760200153964589e-05,
      "loss": 0.1681,
      "step": 7400
    },
    {
      "epoch": 2.1391454965357966,
      "grad_norm": 2.4384167194366455,
      "learning_rate": 5.740954580446497e-05,
      "loss": 0.3123,
      "step": 7410
    },
    {
      "epoch": 2.1420323325635104,
      "grad_norm": 2.356907606124878,
      "learning_rate": 5.721709006928406e-05,
      "loss": 0.187,
      "step": 7420
    },
    {
      "epoch": 2.144919168591224,
      "grad_norm": 1.0443947315216064,
      "learning_rate": 5.7024634334103156e-05,
      "loss": 0.3537,
      "step": 7430
    },
    {
      "epoch": 2.147806004618938,
      "grad_norm": 1.9787514209747314,
      "learning_rate": 5.6832178598922246e-05,
      "loss": 0.1541,
      "step": 7440
    },
    {
      "epoch": 2.1506928406466512,
      "grad_norm": 1.4194390773773193,
      "learning_rate": 5.663972286374134e-05,
      "loss": 0.1421,
      "step": 7450
    },
    {
      "epoch": 2.153579676674365,
      "grad_norm": 4.249236106872559,
      "learning_rate": 5.644726712856043e-05,
      "loss": 0.4143,
      "step": 7460
    },
    {
      "epoch": 2.1564665127020786,
      "grad_norm": 1.7933279275894165,
      "learning_rate": 5.625481139337953e-05,
      "loss": 0.1779,
      "step": 7470
    },
    {
      "epoch": 2.159353348729792,
      "grad_norm": 2.899082899093628,
      "learning_rate": 5.606235565819862e-05,
      "loss": 0.2107,
      "step": 7480
    },
    {
      "epoch": 2.162240184757506,
      "grad_norm": 1.8534929752349854,
      "learning_rate": 5.586989992301771e-05,
      "loss": 0.209,
      "step": 7490
    },
    {
      "epoch": 2.1651270207852193,
      "grad_norm": 12.3837308883667,
      "learning_rate": 5.5677444187836804e-05,
      "loss": 0.2528,
      "step": 7500
    },
    {
      "epoch": 2.168013856812933,
      "grad_norm": 1.4413572549819946,
      "learning_rate": 5.548498845265589e-05,
      "loss": 0.1801,
      "step": 7510
    },
    {
      "epoch": 2.1709006928406467,
      "grad_norm": 2.3552465438842773,
      "learning_rate": 5.529253271747499e-05,
      "loss": 0.2621,
      "step": 7520
    },
    {
      "epoch": 2.17378752886836,
      "grad_norm": 1.5946035385131836,
      "learning_rate": 5.510007698229408e-05,
      "loss": 0.1621,
      "step": 7530
    },
    {
      "epoch": 2.176674364896074,
      "grad_norm": 7.375341892242432,
      "learning_rate": 5.490762124711316e-05,
      "loss": 0.2521,
      "step": 7540
    },
    {
      "epoch": 2.1795612009237875,
      "grad_norm": 1.3919460773468018,
      "learning_rate": 5.471516551193225e-05,
      "loss": 0.1721,
      "step": 7550
    },
    {
      "epoch": 2.1824480369515014,
      "grad_norm": 2.5479230880737305,
      "learning_rate": 5.452270977675135e-05,
      "loss": 0.184,
      "step": 7560
    },
    {
      "epoch": 2.185334872979215,
      "grad_norm": 1.1165591478347778,
      "learning_rate": 5.433025404157044e-05,
      "loss": 0.1603,
      "step": 7570
    },
    {
      "epoch": 2.1882217090069283,
      "grad_norm": 1.8963793516159058,
      "learning_rate": 5.413779830638953e-05,
      "loss": 0.1577,
      "step": 7580
    },
    {
      "epoch": 2.191108545034642,
      "grad_norm": 2.3967974185943604,
      "learning_rate": 5.394534257120862e-05,
      "loss": 0.197,
      "step": 7590
    },
    {
      "epoch": 2.1939953810623556,
      "grad_norm": 2.04772686958313,
      "learning_rate": 5.375288683602772e-05,
      "loss": 0.2057,
      "step": 7600
    },
    {
      "epoch": 2.1968822170900695,
      "grad_norm": 0.9281691312789917,
      "learning_rate": 5.356043110084681e-05,
      "loss": 0.3311,
      "step": 7610
    },
    {
      "epoch": 2.199769053117783,
      "grad_norm": 1.1048707962036133,
      "learning_rate": 5.33679753656659e-05,
      "loss": 0.2239,
      "step": 7620
    },
    {
      "epoch": 2.2026558891454964,
      "grad_norm": 2.110752820968628,
      "learning_rate": 5.3175519630484995e-05,
      "loss": 0.2143,
      "step": 7630
    },
    {
      "epoch": 2.2055427251732103,
      "grad_norm": 1.9683308601379395,
      "learning_rate": 5.2983063895304084e-05,
      "loss": 0.1695,
      "step": 7640
    },
    {
      "epoch": 2.2084295612009237,
      "grad_norm": 1.2039222717285156,
      "learning_rate": 5.279060816012318e-05,
      "loss": 0.2715,
      "step": 7650
    },
    {
      "epoch": 2.2113163972286376,
      "grad_norm": 2.964505195617676,
      "learning_rate": 5.259815242494227e-05,
      "loss": 0.1805,
      "step": 7660
    },
    {
      "epoch": 2.214203233256351,
      "grad_norm": 2.268237590789795,
      "learning_rate": 5.240569668976135e-05,
      "loss": 0.2608,
      "step": 7670
    },
    {
      "epoch": 2.2170900692840645,
      "grad_norm": 2.512824058532715,
      "learning_rate": 5.221324095458044e-05,
      "loss": 0.2198,
      "step": 7680
    },
    {
      "epoch": 2.2199769053117784,
      "grad_norm": 0.645779550075531,
      "learning_rate": 5.202078521939954e-05,
      "loss": 0.2356,
      "step": 7690
    },
    {
      "epoch": 2.222863741339492,
      "grad_norm": 4.363288402557373,
      "learning_rate": 5.182832948421863e-05,
      "loss": 0.1316,
      "step": 7700
    },
    {
      "epoch": 2.2257505773672057,
      "grad_norm": 6.412913799285889,
      "learning_rate": 5.1635873749037724e-05,
      "loss": 0.2211,
      "step": 7710
    },
    {
      "epoch": 2.228637413394919,
      "grad_norm": 1.8412623405456543,
      "learning_rate": 5.1443418013856814e-05,
      "loss": 0.2197,
      "step": 7720
    },
    {
      "epoch": 2.2315242494226326,
      "grad_norm": 1.6844428777694702,
      "learning_rate": 5.125096227867591e-05,
      "loss": 0.1956,
      "step": 7730
    },
    {
      "epoch": 2.2344110854503465,
      "grad_norm": 3.581115484237671,
      "learning_rate": 5.1058506543495e-05,
      "loss": 0.2332,
      "step": 7740
    },
    {
      "epoch": 2.23729792147806,
      "grad_norm": 3.395516872406006,
      "learning_rate": 5.086605080831409e-05,
      "loss": 0.2293,
      "step": 7750
    },
    {
      "epoch": 2.240184757505774,
      "grad_norm": 1.1458545923233032,
      "learning_rate": 5.0673595073133186e-05,
      "loss": 0.1611,
      "step": 7760
    },
    {
      "epoch": 2.2430715935334873,
      "grad_norm": 2.3986382484436035,
      "learning_rate": 5.0481139337952275e-05,
      "loss": 0.2353,
      "step": 7770
    },
    {
      "epoch": 2.2459584295612007,
      "grad_norm": 2.257981777191162,
      "learning_rate": 5.028868360277137e-05,
      "loss": 0.3524,
      "step": 7780
    },
    {
      "epoch": 2.2488452655889146,
      "grad_norm": 0.9510466456413269,
      "learning_rate": 5.009622786759046e-05,
      "loss": 0.2004,
      "step": 7790
    },
    {
      "epoch": 2.251732101616628,
      "grad_norm": 0.5607468485832214,
      "learning_rate": 4.990377213240955e-05,
      "loss": 0.1761,
      "step": 7800
    },
    {
      "epoch": 2.254618937644342,
      "grad_norm": 2.441321611404419,
      "learning_rate": 4.971131639722864e-05,
      "loss": 0.2157,
      "step": 7810
    },
    {
      "epoch": 2.2575057736720554,
      "grad_norm": 2.092398166656494,
      "learning_rate": 4.9518860662047736e-05,
      "loss": 0.146,
      "step": 7820
    },
    {
      "epoch": 2.2603926096997693,
      "grad_norm": 0.9234526753425598,
      "learning_rate": 4.932640492686682e-05,
      "loss": 0.1799,
      "step": 7830
    },
    {
      "epoch": 2.2632794457274827,
      "grad_norm": 1.6161104440689087,
      "learning_rate": 4.9133949191685915e-05,
      "loss": 0.1577,
      "step": 7840
    },
    {
      "epoch": 2.266166281755196,
      "grad_norm": 0.7561256885528564,
      "learning_rate": 4.8941493456505005e-05,
      "loss": 0.2095,
      "step": 7850
    },
    {
      "epoch": 2.26905311778291,
      "grad_norm": 2.3739545345306396,
      "learning_rate": 4.8749037721324095e-05,
      "loss": 0.2075,
      "step": 7860
    },
    {
      "epoch": 2.2719399538106235,
      "grad_norm": 2.654541254043579,
      "learning_rate": 4.855658198614319e-05,
      "loss": 0.2237,
      "step": 7870
    },
    {
      "epoch": 2.274826789838337,
      "grad_norm": 1.168681025505066,
      "learning_rate": 4.836412625096228e-05,
      "loss": 0.3029,
      "step": 7880
    },
    {
      "epoch": 2.277713625866051,
      "grad_norm": 1.119437575340271,
      "learning_rate": 4.817167051578138e-05,
      "loss": 0.1748,
      "step": 7890
    },
    {
      "epoch": 2.2806004618937643,
      "grad_norm": 0.86188805103302,
      "learning_rate": 4.797921478060046e-05,
      "loss": 0.2419,
      "step": 7900
    },
    {
      "epoch": 2.283487297921478,
      "grad_norm": 1.516201376914978,
      "learning_rate": 4.7786759045419556e-05,
      "loss": 0.1565,
      "step": 7910
    },
    {
      "epoch": 2.2863741339491916,
      "grad_norm": 0.8049386739730835,
      "learning_rate": 4.7594303310238645e-05,
      "loss": 0.1562,
      "step": 7920
    },
    {
      "epoch": 2.2892609699769055,
      "grad_norm": 1.8518552780151367,
      "learning_rate": 4.740184757505774e-05,
      "loss": 0.2506,
      "step": 7930
    },
    {
      "epoch": 2.292147806004619,
      "grad_norm": 1.31242835521698,
      "learning_rate": 4.720939183987683e-05,
      "loss": 0.2739,
      "step": 7940
    },
    {
      "epoch": 2.2950346420323324,
      "grad_norm": 1.388990044593811,
      "learning_rate": 4.701693610469593e-05,
      "loss": 0.2403,
      "step": 7950
    },
    {
      "epoch": 2.2979214780600463,
      "grad_norm": 2.9749984741210938,
      "learning_rate": 4.682448036951501e-05,
      "loss": 0.1918,
      "step": 7960
    },
    {
      "epoch": 2.3008083140877598,
      "grad_norm": 1.0494500398635864,
      "learning_rate": 4.6632024634334107e-05,
      "loss": 0.223,
      "step": 7970
    },
    {
      "epoch": 2.303695150115473,
      "grad_norm": 1.8402563333511353,
      "learning_rate": 4.6439568899153196e-05,
      "loss": 0.1411,
      "step": 7980
    },
    {
      "epoch": 2.306581986143187,
      "grad_norm": 1.2134382724761963,
      "learning_rate": 4.6247113163972286e-05,
      "loss": 0.194,
      "step": 7990
    },
    {
      "epoch": 2.3094688221709005,
      "grad_norm": 5.150371074676514,
      "learning_rate": 4.605465742879138e-05,
      "loss": 0.2385,
      "step": 8000
    },
    {
      "epoch": 2.3123556581986144,
      "grad_norm": 11.628164291381836,
      "learning_rate": 4.586220169361047e-05,
      "loss": 0.2097,
      "step": 8010
    },
    {
      "epoch": 2.315242494226328,
      "grad_norm": 1.7527579069137573,
      "learning_rate": 4.566974595842957e-05,
      "loss": 0.283,
      "step": 8020
    },
    {
      "epoch": 2.3181293302540418,
      "grad_norm": 2.656296968460083,
      "learning_rate": 4.547729022324865e-05,
      "loss": 0.3035,
      "step": 8030
    },
    {
      "epoch": 2.321016166281755,
      "grad_norm": 1.6972270011901855,
      "learning_rate": 4.528483448806775e-05,
      "loss": 0.1659,
      "step": 8040
    },
    {
      "epoch": 2.3239030023094687,
      "grad_norm": 1.2814428806304932,
      "learning_rate": 4.5092378752886836e-05,
      "loss": 0.1734,
      "step": 8050
    },
    {
      "epoch": 2.3267898383371826,
      "grad_norm": 2.561347484588623,
      "learning_rate": 4.489992301770593e-05,
      "loss": 0.2822,
      "step": 8060
    },
    {
      "epoch": 2.329676674364896,
      "grad_norm": 2.7033004760742188,
      "learning_rate": 4.470746728252502e-05,
      "loss": 0.2941,
      "step": 8070
    },
    {
      "epoch": 2.3325635103926095,
      "grad_norm": 3.2399370670318604,
      "learning_rate": 4.451501154734412e-05,
      "loss": 0.1721,
      "step": 8080
    },
    {
      "epoch": 2.3354503464203233,
      "grad_norm": 1.6341087818145752,
      "learning_rate": 4.43225558121632e-05,
      "loss": 0.1932,
      "step": 8090
    },
    {
      "epoch": 2.338337182448037,
      "grad_norm": 1.2383261919021606,
      "learning_rate": 4.41301000769823e-05,
      "loss": 0.2332,
      "step": 8100
    },
    {
      "epoch": 2.3412240184757507,
      "grad_norm": 6.414398670196533,
      "learning_rate": 4.393764434180139e-05,
      "loss": 0.2041,
      "step": 8110
    },
    {
      "epoch": 2.344110854503464,
      "grad_norm": 0.5969727635383606,
      "learning_rate": 4.374518860662048e-05,
      "loss": 0.1877,
      "step": 8120
    },
    {
      "epoch": 2.346997690531178,
      "grad_norm": 1.944622278213501,
      "learning_rate": 4.355273287143957e-05,
      "loss": 0.1816,
      "step": 8130
    },
    {
      "epoch": 2.3498845265588915,
      "grad_norm": 11.488838195800781,
      "learning_rate": 4.336027713625866e-05,
      "loss": 0.292,
      "step": 8140
    },
    {
      "epoch": 2.352771362586605,
      "grad_norm": 1.7432665824890137,
      "learning_rate": 4.316782140107775e-05,
      "loss": 0.1908,
      "step": 8150
    },
    {
      "epoch": 2.355658198614319,
      "grad_norm": 1.5145615339279175,
      "learning_rate": 4.297536566589684e-05,
      "loss": 0.1501,
      "step": 8160
    },
    {
      "epoch": 2.3585450346420322,
      "grad_norm": 3.9027292728424072,
      "learning_rate": 4.278290993071594e-05,
      "loss": 0.4031,
      "step": 8170
    },
    {
      "epoch": 2.361431870669746,
      "grad_norm": 0.9698968529701233,
      "learning_rate": 4.259045419553503e-05,
      "loss": 0.1994,
      "step": 8180
    },
    {
      "epoch": 2.3643187066974596,
      "grad_norm": 5.882491111755371,
      "learning_rate": 4.2397998460354124e-05,
      "loss": 0.1801,
      "step": 8190
    },
    {
      "epoch": 2.367205542725173,
      "grad_norm": 1.4335423707962036,
      "learning_rate": 4.220554272517321e-05,
      "loss": 0.1917,
      "step": 8200
    },
    {
      "epoch": 2.370092378752887,
      "grad_norm": 1.992926836013794,
      "learning_rate": 4.201308698999231e-05,
      "loss": 0.1977,
      "step": 8210
    },
    {
      "epoch": 2.3729792147806004,
      "grad_norm": 0.9160973429679871,
      "learning_rate": 4.182063125481139e-05,
      "loss": 0.1807,
      "step": 8220
    },
    {
      "epoch": 2.3758660508083143,
      "grad_norm": 1.3323116302490234,
      "learning_rate": 4.162817551963049e-05,
      "loss": 0.1619,
      "step": 8230
    },
    {
      "epoch": 2.3787528868360277,
      "grad_norm": 1.980461835861206,
      "learning_rate": 4.143571978444958e-05,
      "loss": 0.1973,
      "step": 8240
    },
    {
      "epoch": 2.381639722863741,
      "grad_norm": 0.8932486772537231,
      "learning_rate": 4.124326404926867e-05,
      "loss": 0.1942,
      "step": 8250
    },
    {
      "epoch": 2.384526558891455,
      "grad_norm": 2.9463608264923096,
      "learning_rate": 4.1050808314087764e-05,
      "loss": 0.3463,
      "step": 8260
    },
    {
      "epoch": 2.3874133949191685,
      "grad_norm": 0.9292469620704651,
      "learning_rate": 4.0858352578906854e-05,
      "loss": 0.1496,
      "step": 8270
    },
    {
      "epoch": 2.3903002309468824,
      "grad_norm": 0.8937719464302063,
      "learning_rate": 4.066589684372594e-05,
      "loss": 0.1639,
      "step": 8280
    },
    {
      "epoch": 2.393187066974596,
      "grad_norm": 3.0960264205932617,
      "learning_rate": 4.047344110854503e-05,
      "loss": 0.1735,
      "step": 8290
    },
    {
      "epoch": 2.3960739030023097,
      "grad_norm": 0.761458158493042,
      "learning_rate": 4.028098537336413e-05,
      "loss": 0.1763,
      "step": 8300
    },
    {
      "epoch": 2.398960739030023,
      "grad_norm": 1.0483850240707397,
      "learning_rate": 4.008852963818322e-05,
      "loss": 0.2239,
      "step": 8310
    },
    {
      "epoch": 2.4018475750577366,
      "grad_norm": 1.426534652709961,
      "learning_rate": 3.9896073903002315e-05,
      "loss": 0.1904,
      "step": 8320
    },
    {
      "epoch": 2.4047344110854505,
      "grad_norm": 1.2577890157699585,
      "learning_rate": 3.9703618167821404e-05,
      "loss": 0.1925,
      "step": 8330
    },
    {
      "epoch": 2.407621247113164,
      "grad_norm": 2.119621992111206,
      "learning_rate": 3.95111624326405e-05,
      "loss": 0.2066,
      "step": 8340
    },
    {
      "epoch": 2.4105080831408774,
      "grad_norm": 2.3690316677093506,
      "learning_rate": 3.931870669745958e-05,
      "loss": 0.22,
      "step": 8350
    },
    {
      "epoch": 2.4133949191685913,
      "grad_norm": 2.9025251865386963,
      "learning_rate": 3.912625096227868e-05,
      "loss": 0.1976,
      "step": 8360
    },
    {
      "epoch": 2.4162817551963047,
      "grad_norm": 1.3941802978515625,
      "learning_rate": 3.893379522709777e-05,
      "loss": 0.1604,
      "step": 8370
    },
    {
      "epoch": 2.4191685912240186,
      "grad_norm": 2.385702133178711,
      "learning_rate": 3.874133949191686e-05,
      "loss": 0.1903,
      "step": 8380
    },
    {
      "epoch": 2.422055427251732,
      "grad_norm": 2.916958808898926,
      "learning_rate": 3.8548883756735955e-05,
      "loss": 0.1624,
      "step": 8390
    },
    {
      "epoch": 2.424942263279446,
      "grad_norm": 2.2648119926452637,
      "learning_rate": 3.8356428021555045e-05,
      "loss": 0.2086,
      "step": 8400
    },
    {
      "epoch": 2.4278290993071594,
      "grad_norm": 0.7788357734680176,
      "learning_rate": 3.8163972286374134e-05,
      "loss": 0.1776,
      "step": 8410
    },
    {
      "epoch": 2.430715935334873,
      "grad_norm": 2.3576149940490723,
      "learning_rate": 3.7971516551193224e-05,
      "loss": 0.1892,
      "step": 8420
    },
    {
      "epoch": 2.4336027713625867,
      "grad_norm": 2.2881650924682617,
      "learning_rate": 3.777906081601232e-05,
      "loss": 0.1921,
      "step": 8430
    },
    {
      "epoch": 2.4364896073903,
      "grad_norm": 1.4808827638626099,
      "learning_rate": 3.758660508083141e-05,
      "loss": 0.1437,
      "step": 8440
    },
    {
      "epoch": 2.4393764434180136,
      "grad_norm": 1.0180299282073975,
      "learning_rate": 3.7394149345650506e-05,
      "loss": 0.1506,
      "step": 8450
    },
    {
      "epoch": 2.4422632794457275,
      "grad_norm": 1.5936729907989502,
      "learning_rate": 3.7201693610469595e-05,
      "loss": 0.2374,
      "step": 8460
    },
    {
      "epoch": 2.445150115473441,
      "grad_norm": 2.5226762294769287,
      "learning_rate": 3.7009237875288685e-05,
      "loss": 0.1777,
      "step": 8470
    },
    {
      "epoch": 2.448036951501155,
      "grad_norm": 2.8727643489837646,
      "learning_rate": 3.6816782140107774e-05,
      "loss": 0.1878,
      "step": 8480
    },
    {
      "epoch": 2.4509237875288683,
      "grad_norm": 1.699596881866455,
      "learning_rate": 3.662432640492687e-05,
      "loss": 0.2533,
      "step": 8490
    },
    {
      "epoch": 2.453810623556582,
      "grad_norm": 3.8620412349700928,
      "learning_rate": 3.643187066974596e-05,
      "loss": 0.1713,
      "step": 8500
    },
    {
      "epoch": 2.4566974595842956,
      "grad_norm": 0.9951182007789612,
      "learning_rate": 3.623941493456505e-05,
      "loss": 0.21,
      "step": 8510
    },
    {
      "epoch": 2.459584295612009,
      "grad_norm": 10.309110641479492,
      "learning_rate": 3.6046959199384146e-05,
      "loss": 0.2901,
      "step": 8520
    },
    {
      "epoch": 2.462471131639723,
      "grad_norm": 3.7868635654449463,
      "learning_rate": 3.5854503464203236e-05,
      "loss": 0.1711,
      "step": 8530
    },
    {
      "epoch": 2.4653579676674364,
      "grad_norm": 1.4185819625854492,
      "learning_rate": 3.5662047729022325e-05,
      "loss": 0.1506,
      "step": 8540
    },
    {
      "epoch": 2.46824480369515,
      "grad_norm": 0.8817757964134216,
      "learning_rate": 3.5469591993841415e-05,
      "loss": 0.1756,
      "step": 8550
    },
    {
      "epoch": 2.4711316397228638,
      "grad_norm": 1.1522984504699707,
      "learning_rate": 3.527713625866051e-05,
      "loss": 0.1935,
      "step": 8560
    },
    {
      "epoch": 2.474018475750577,
      "grad_norm": 2.7352724075317383,
      "learning_rate": 3.50846805234796e-05,
      "loss": 0.208,
      "step": 8570
    },
    {
      "epoch": 2.476905311778291,
      "grad_norm": 1.1735068559646606,
      "learning_rate": 3.48922247882987e-05,
      "loss": 0.1587,
      "step": 8580
    },
    {
      "epoch": 2.4797921478060045,
      "grad_norm": 1.2928667068481445,
      "learning_rate": 3.4699769053117786e-05,
      "loss": 0.1571,
      "step": 8590
    },
    {
      "epoch": 2.4826789838337184,
      "grad_norm": 1.896597146987915,
      "learning_rate": 3.4507313317936876e-05,
      "loss": 0.2408,
      "step": 8600
    },
    {
      "epoch": 2.485565819861432,
      "grad_norm": 0.8346269130706787,
      "learning_rate": 3.4314857582755965e-05,
      "loss": 0.2748,
      "step": 8610
    },
    {
      "epoch": 2.4884526558891453,
      "grad_norm": 2.9001758098602295,
      "learning_rate": 3.412240184757506e-05,
      "loss": 0.2093,
      "step": 8620
    },
    {
      "epoch": 2.491339491916859,
      "grad_norm": 2.248201608657837,
      "learning_rate": 3.392994611239415e-05,
      "loss": 0.1505,
      "step": 8630
    },
    {
      "epoch": 2.4942263279445727,
      "grad_norm": 3.3459832668304443,
      "learning_rate": 3.373749037721324e-05,
      "loss": 0.3899,
      "step": 8640
    },
    {
      "epoch": 2.4971131639722866,
      "grad_norm": 2.872469663619995,
      "learning_rate": 3.354503464203234e-05,
      "loss": 0.1993,
      "step": 8650
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.5316381454467773,
      "learning_rate": 3.335257890685143e-05,
      "loss": 0.1835,
      "step": 8660
    },
    {
      "epoch": 2.502886836027714,
      "grad_norm": 1.8081978559494019,
      "learning_rate": 3.3160123171670516e-05,
      "loss": 0.2005,
      "step": 8670
    },
    {
      "epoch": 2.5057736720554273,
      "grad_norm": 7.602380752563477,
      "learning_rate": 3.2967667436489606e-05,
      "loss": 0.2371,
      "step": 8680
    },
    {
      "epoch": 2.508660508083141,
      "grad_norm": 1.2648873329162598,
      "learning_rate": 3.27752117013087e-05,
      "loss": 0.199,
      "step": 8690
    },
    {
      "epoch": 2.5115473441108547,
      "grad_norm": 2.4315998554229736,
      "learning_rate": 3.258275596612779e-05,
      "loss": 0.1699,
      "step": 8700
    },
    {
      "epoch": 2.514434180138568,
      "grad_norm": 1.2266172170639038,
      "learning_rate": 3.239030023094689e-05,
      "loss": 0.218,
      "step": 8710
    },
    {
      "epoch": 2.5173210161662816,
      "grad_norm": 1.9350857734680176,
      "learning_rate": 3.219784449576598e-05,
      "loss": 0.1839,
      "step": 8720
    },
    {
      "epoch": 2.5202078521939955,
      "grad_norm": 1.3471719026565552,
      "learning_rate": 3.200538876058507e-05,
      "loss": 0.1889,
      "step": 8730
    },
    {
      "epoch": 2.523094688221709,
      "grad_norm": 2.446444511413574,
      "learning_rate": 3.1812933025404156e-05,
      "loss": 0.1835,
      "step": 8740
    },
    {
      "epoch": 2.525981524249423,
      "grad_norm": 1.616603970527649,
      "learning_rate": 3.1620477290223246e-05,
      "loss": 0.1503,
      "step": 8750
    },
    {
      "epoch": 2.5288683602771362,
      "grad_norm": 1.9376487731933594,
      "learning_rate": 3.142802155504234e-05,
      "loss": 0.2006,
      "step": 8760
    },
    {
      "epoch": 2.53175519630485,
      "grad_norm": 3.9691712856292725,
      "learning_rate": 3.123556581986143e-05,
      "loss": 0.222,
      "step": 8770
    },
    {
      "epoch": 2.5346420323325636,
      "grad_norm": 4.0747294425964355,
      "learning_rate": 3.104311008468053e-05,
      "loss": 0.2068,
      "step": 8780
    },
    {
      "epoch": 2.537528868360277,
      "grad_norm": 2.202374219894409,
      "learning_rate": 3.085065434949962e-05,
      "loss": 0.2077,
      "step": 8790
    },
    {
      "epoch": 2.540415704387991,
      "grad_norm": 1.3343356847763062,
      "learning_rate": 3.065819861431871e-05,
      "loss": 0.1624,
      "step": 8800
    },
    {
      "epoch": 2.5433025404157044,
      "grad_norm": 3.2936642169952393,
      "learning_rate": 3.04657428791378e-05,
      "loss": 0.2344,
      "step": 8810
    },
    {
      "epoch": 2.546189376443418,
      "grad_norm": 1.731505036354065,
      "learning_rate": 3.027328714395689e-05,
      "loss": 0.1701,
      "step": 8820
    },
    {
      "epoch": 2.5490762124711317,
      "grad_norm": 1.3069608211517334,
      "learning_rate": 3.0080831408775983e-05,
      "loss": 0.3174,
      "step": 8830
    },
    {
      "epoch": 2.551963048498845,
      "grad_norm": 1.2592421770095825,
      "learning_rate": 2.9888375673595076e-05,
      "loss": 0.1802,
      "step": 8840
    },
    {
      "epoch": 2.554849884526559,
      "grad_norm": 0.8772491812705994,
      "learning_rate": 2.969591993841417e-05,
      "loss": 0.2349,
      "step": 8850
    },
    {
      "epoch": 2.5577367205542725,
      "grad_norm": 0.7926144003868103,
      "learning_rate": 2.9503464203233255e-05,
      "loss": 0.3558,
      "step": 8860
    },
    {
      "epoch": 2.5606235565819864,
      "grad_norm": 1.1462167501449585,
      "learning_rate": 2.9311008468052348e-05,
      "loss": 0.1711,
      "step": 8870
    },
    {
      "epoch": 2.5635103926097,
      "grad_norm": 0.7745834589004517,
      "learning_rate": 2.911855273287144e-05,
      "loss": 0.2844,
      "step": 8880
    },
    {
      "epoch": 2.5663972286374133,
      "grad_norm": 1.1584876775741577,
      "learning_rate": 2.8926096997690533e-05,
      "loss": 0.1626,
      "step": 8890
    },
    {
      "epoch": 2.569284064665127,
      "grad_norm": 0.8239560127258301,
      "learning_rate": 2.8733641262509626e-05,
      "loss": 0.1851,
      "step": 8900
    },
    {
      "epoch": 2.5721709006928406,
      "grad_norm": 1.0271000862121582,
      "learning_rate": 2.854118552732872e-05,
      "loss": 0.1828,
      "step": 8910
    },
    {
      "epoch": 2.575057736720554,
      "grad_norm": 3.9572699069976807,
      "learning_rate": 2.834872979214781e-05,
      "loss": 0.2813,
      "step": 8920
    },
    {
      "epoch": 2.577944572748268,
      "grad_norm": 0.7497757077217102,
      "learning_rate": 2.8156274056966898e-05,
      "loss": 0.2549,
      "step": 8930
    },
    {
      "epoch": 2.5808314087759814,
      "grad_norm": 2.2299699783325195,
      "learning_rate": 2.7963818321785988e-05,
      "loss": 0.1648,
      "step": 8940
    },
    {
      "epoch": 2.5837182448036953,
      "grad_norm": 0.9247962236404419,
      "learning_rate": 2.777136258660508e-05,
      "loss": 0.1736,
      "step": 8950
    },
    {
      "epoch": 2.5866050808314087,
      "grad_norm": 3.6680281162261963,
      "learning_rate": 2.7578906851424174e-05,
      "loss": 0.1861,
      "step": 8960
    },
    {
      "epoch": 2.5894919168591226,
      "grad_norm": 2.586716651916504,
      "learning_rate": 2.7386451116243267e-05,
      "loss": 0.1622,
      "step": 8970
    },
    {
      "epoch": 2.592378752886836,
      "grad_norm": 1.3770250082015991,
      "learning_rate": 2.719399538106236e-05,
      "loss": 0.2947,
      "step": 8980
    },
    {
      "epoch": 2.5952655889145495,
      "grad_norm": 3.7395598888397217,
      "learning_rate": 2.7001539645881446e-05,
      "loss": 0.2151,
      "step": 8990
    },
    {
      "epoch": 2.5981524249422634,
      "grad_norm": 2.0116493701934814,
      "learning_rate": 2.680908391070054e-05,
      "loss": 0.2199,
      "step": 9000
    },
    {
      "epoch": 2.601039260969977,
      "grad_norm": 0.6439405679702759,
      "learning_rate": 2.661662817551963e-05,
      "loss": 0.1856,
      "step": 9010
    },
    {
      "epoch": 2.6039260969976903,
      "grad_norm": 0.6250158548355103,
      "learning_rate": 2.6424172440338724e-05,
      "loss": 0.337,
      "step": 9020
    },
    {
      "epoch": 2.606812933025404,
      "grad_norm": 1.4256131649017334,
      "learning_rate": 2.6231716705157817e-05,
      "loss": 0.1922,
      "step": 9030
    },
    {
      "epoch": 2.6096997690531176,
      "grad_norm": 4.0425543785095215,
      "learning_rate": 2.6039260969976907e-05,
      "loss": 0.2147,
      "step": 9040
    },
    {
      "epoch": 2.6125866050808315,
      "grad_norm": 1.2829763889312744,
      "learning_rate": 2.5846805234795996e-05,
      "loss": 0.1593,
      "step": 9050
    },
    {
      "epoch": 2.615473441108545,
      "grad_norm": 2.34981107711792,
      "learning_rate": 2.565434949961509e-05,
      "loss": 0.1614,
      "step": 9060
    },
    {
      "epoch": 2.618360277136259,
      "grad_norm": 2.480480432510376,
      "learning_rate": 2.546189376443418e-05,
      "loss": 0.1717,
      "step": 9070
    },
    {
      "epoch": 2.6212471131639723,
      "grad_norm": 2.5072977542877197,
      "learning_rate": 2.5269438029253272e-05,
      "loss": 0.1992,
      "step": 9080
    },
    {
      "epoch": 2.6241339491916857,
      "grad_norm": 2.88822603225708,
      "learning_rate": 2.5076982294072365e-05,
      "loss": 0.2686,
      "step": 9090
    },
    {
      "epoch": 2.6270207852193996,
      "grad_norm": 0.7544775009155273,
      "learning_rate": 2.4884526558891454e-05,
      "loss": 0.1808,
      "step": 9100
    },
    {
      "epoch": 2.629907621247113,
      "grad_norm": 9.933693885803223,
      "learning_rate": 2.4692070823710547e-05,
      "loss": 0.2456,
      "step": 9110
    },
    {
      "epoch": 2.6327944572748265,
      "grad_norm": 3.670557737350464,
      "learning_rate": 2.449961508852964e-05,
      "loss": 0.1607,
      "step": 9120
    },
    {
      "epoch": 2.6356812933025404,
      "grad_norm": 4.939868450164795,
      "learning_rate": 2.430715935334873e-05,
      "loss": 0.3319,
      "step": 9130
    },
    {
      "epoch": 2.6385681293302543,
      "grad_norm": 2.2298614978790283,
      "learning_rate": 2.4114703618167823e-05,
      "loss": 0.1881,
      "step": 9140
    },
    {
      "epoch": 2.6414549653579678,
      "grad_norm": 2.0576210021972656,
      "learning_rate": 2.3922247882986915e-05,
      "loss": 0.19,
      "step": 9150
    },
    {
      "epoch": 2.644341801385681,
      "grad_norm": 3.222290277481079,
      "learning_rate": 2.372979214780601e-05,
      "loss": 0.2154,
      "step": 9160
    },
    {
      "epoch": 2.647228637413395,
      "grad_norm": 6.8376007080078125,
      "learning_rate": 2.3537336412625098e-05,
      "loss": 0.1664,
      "step": 9170
    },
    {
      "epoch": 2.6501154734411085,
      "grad_norm": 0.6173899173736572,
      "learning_rate": 2.334488067744419e-05,
      "loss": 0.1789,
      "step": 9180
    },
    {
      "epoch": 2.653002309468822,
      "grad_norm": 1.874105453491211,
      "learning_rate": 2.315242494226328e-05,
      "loss": 0.2037,
      "step": 9190
    },
    {
      "epoch": 2.655889145496536,
      "grad_norm": 2.1660315990448,
      "learning_rate": 2.295996920708237e-05,
      "loss": 0.182,
      "step": 9200
    },
    {
      "epoch": 2.6587759815242493,
      "grad_norm": 1.35490882396698,
      "learning_rate": 2.2767513471901463e-05,
      "loss": 0.2005,
      "step": 9210
    },
    {
      "epoch": 2.661662817551963,
      "grad_norm": 3.184419631958008,
      "learning_rate": 2.2575057736720556e-05,
      "loss": 0.1688,
      "step": 9220
    },
    {
      "epoch": 2.6645496535796767,
      "grad_norm": 4.556469917297363,
      "learning_rate": 2.2382602001539645e-05,
      "loss": 0.2346,
      "step": 9230
    },
    {
      "epoch": 2.6674364896073905,
      "grad_norm": 1.0270494222640991,
      "learning_rate": 2.2190146266358738e-05,
      "loss": 0.2204,
      "step": 9240
    },
    {
      "epoch": 2.670323325635104,
      "grad_norm": 2.8100686073303223,
      "learning_rate": 2.199769053117783e-05,
      "loss": 0.1983,
      "step": 9250
    },
    {
      "epoch": 2.6732101616628174,
      "grad_norm": 2.561359405517578,
      "learning_rate": 2.180523479599692e-05,
      "loss": 0.1667,
      "step": 9260
    },
    {
      "epoch": 2.6760969976905313,
      "grad_norm": 1.9727176427841187,
      "learning_rate": 2.1612779060816014e-05,
      "loss": 0.1552,
      "step": 9270
    },
    {
      "epoch": 2.678983833718245,
      "grad_norm": 0.8854110836982727,
      "learning_rate": 2.1420323325635107e-05,
      "loss": 0.1682,
      "step": 9280
    },
    {
      "epoch": 2.6818706697459582,
      "grad_norm": 1.2057799100875854,
      "learning_rate": 2.12278675904542e-05,
      "loss": 0.1475,
      "step": 9290
    },
    {
      "epoch": 2.684757505773672,
      "grad_norm": 2.1241276264190674,
      "learning_rate": 2.103541185527329e-05,
      "loss": 0.2271,
      "step": 9300
    },
    {
      "epoch": 2.6876443418013856,
      "grad_norm": 1.6744985580444336,
      "learning_rate": 2.084295612009238e-05,
      "loss": 0.2418,
      "step": 9310
    },
    {
      "epoch": 2.6905311778290995,
      "grad_norm": 2.258167028427124,
      "learning_rate": 2.065050038491147e-05,
      "loss": 0.2257,
      "step": 9320
    },
    {
      "epoch": 2.693418013856813,
      "grad_norm": 4.218689918518066,
      "learning_rate": 2.045804464973056e-05,
      "loss": 0.1517,
      "step": 9330
    },
    {
      "epoch": 2.696304849884527,
      "grad_norm": 9.529999732971191,
      "learning_rate": 2.0265588914549654e-05,
      "loss": 0.2678,
      "step": 9340
    },
    {
      "epoch": 2.6991916859122402,
      "grad_norm": 1.7180218696594238,
      "learning_rate": 2.0073133179368747e-05,
      "loss": 0.2902,
      "step": 9350
    },
    {
      "epoch": 2.7020785219399537,
      "grad_norm": 2.081862211227417,
      "learning_rate": 1.9880677444187836e-05,
      "loss": 0.276,
      "step": 9360
    },
    {
      "epoch": 2.7049653579676676,
      "grad_norm": 1.2311687469482422,
      "learning_rate": 1.968822170900693e-05,
      "loss": 0.1912,
      "step": 9370
    },
    {
      "epoch": 2.707852193995381,
      "grad_norm": 1.6871349811553955,
      "learning_rate": 1.9495765973826022e-05,
      "loss": 0.1864,
      "step": 9380
    },
    {
      "epoch": 2.7107390300230945,
      "grad_norm": 2.2551252841949463,
      "learning_rate": 1.9303310238645112e-05,
      "loss": 0.156,
      "step": 9390
    },
    {
      "epoch": 2.7136258660508084,
      "grad_norm": 2.378277063369751,
      "learning_rate": 1.9110854503464205e-05,
      "loss": 0.2623,
      "step": 9400
    },
    {
      "epoch": 2.716512702078522,
      "grad_norm": 1.9876413345336914,
      "learning_rate": 1.8918398768283298e-05,
      "loss": 0.1666,
      "step": 9410
    },
    {
      "epoch": 2.7193995381062357,
      "grad_norm": 2.064756155014038,
      "learning_rate": 1.8725943033102387e-05,
      "loss": 0.1435,
      "step": 9420
    },
    {
      "epoch": 2.722286374133949,
      "grad_norm": 1.370247721672058,
      "learning_rate": 1.853348729792148e-05,
      "loss": 0.1571,
      "step": 9430
    },
    {
      "epoch": 2.725173210161663,
      "grad_norm": 1.3385013341903687,
      "learning_rate": 1.834103156274057e-05,
      "loss": 0.1989,
      "step": 9440
    },
    {
      "epoch": 2.7280600461893765,
      "grad_norm": 10.117476463317871,
      "learning_rate": 1.8148575827559662e-05,
      "loss": 0.2722,
      "step": 9450
    },
    {
      "epoch": 2.73094688221709,
      "grad_norm": 2.0231192111968994,
      "learning_rate": 1.7956120092378752e-05,
      "loss": 0.2401,
      "step": 9460
    },
    {
      "epoch": 2.733833718244804,
      "grad_norm": 1.709854245185852,
      "learning_rate": 1.7763664357197845e-05,
      "loss": 0.2299,
      "step": 9470
    },
    {
      "epoch": 2.7367205542725173,
      "grad_norm": 4.684963703155518,
      "learning_rate": 1.7571208622016938e-05,
      "loss": 0.1699,
      "step": 9480
    },
    {
      "epoch": 2.7396073903002307,
      "grad_norm": 1.2619813680648804,
      "learning_rate": 1.7378752886836027e-05,
      "loss": 0.2691,
      "step": 9490
    },
    {
      "epoch": 2.7424942263279446,
      "grad_norm": 0.737987220287323,
      "learning_rate": 1.718629715165512e-05,
      "loss": 0.2049,
      "step": 9500
    },
    {
      "epoch": 2.745381062355658,
      "grad_norm": 2.971848964691162,
      "learning_rate": 1.6993841416474213e-05,
      "loss": 0.2,
      "step": 9510
    },
    {
      "epoch": 2.748267898383372,
      "grad_norm": 2.9120092391967773,
      "learning_rate": 1.6801385681293303e-05,
      "loss": 0.2097,
      "step": 9520
    },
    {
      "epoch": 2.7511547344110854,
      "grad_norm": 2.5513155460357666,
      "learning_rate": 1.6608929946112396e-05,
      "loss": 0.1701,
      "step": 9530
    },
    {
      "epoch": 2.7540415704387993,
      "grad_norm": 0.8224678635597229,
      "learning_rate": 1.641647421093149e-05,
      "loss": 0.2094,
      "step": 9540
    },
    {
      "epoch": 2.7569284064665127,
      "grad_norm": 1.0792441368103027,
      "learning_rate": 1.6224018475750578e-05,
      "loss": 0.1507,
      "step": 9550
    },
    {
      "epoch": 2.759815242494226,
      "grad_norm": 3.13207745552063,
      "learning_rate": 1.603156274056967e-05,
      "loss": 0.1968,
      "step": 9560
    },
    {
      "epoch": 2.76270207852194,
      "grad_norm": 2.502312183380127,
      "learning_rate": 1.583910700538876e-05,
      "loss": 0.179,
      "step": 9570
    },
    {
      "epoch": 2.7655889145496535,
      "grad_norm": 1.801371455192566,
      "learning_rate": 1.564665127020785e-05,
      "loss": 0.1726,
      "step": 9580
    },
    {
      "epoch": 2.768475750577367,
      "grad_norm": 2.087307929992676,
      "learning_rate": 1.5454195535026943e-05,
      "loss": 0.215,
      "step": 9590
    },
    {
      "epoch": 2.771362586605081,
      "grad_norm": 3.478883743286133,
      "learning_rate": 1.5261739799846036e-05,
      "loss": 0.2423,
      "step": 9600
    },
    {
      "epoch": 2.7742494226327947,
      "grad_norm": 1.572797417640686,
      "learning_rate": 1.5069284064665129e-05,
      "loss": 0.1814,
      "step": 9610
    },
    {
      "epoch": 2.777136258660508,
      "grad_norm": 11.79937744140625,
      "learning_rate": 1.4876828329484218e-05,
      "loss": 0.248,
      "step": 9620
    },
    {
      "epoch": 2.7800230946882216,
      "grad_norm": 3.3870553970336914,
      "learning_rate": 1.4684372594303311e-05,
      "loss": 0.1808,
      "step": 9630
    },
    {
      "epoch": 2.7829099307159355,
      "grad_norm": 1.5624632835388184,
      "learning_rate": 1.4491916859122404e-05,
      "loss": 0.1935,
      "step": 9640
    },
    {
      "epoch": 2.785796766743649,
      "grad_norm": 5.176436424255371,
      "learning_rate": 1.4299461123941494e-05,
      "loss": 0.1798,
      "step": 9650
    },
    {
      "epoch": 2.7886836027713624,
      "grad_norm": 1.014398217201233,
      "learning_rate": 1.4107005388760585e-05,
      "loss": 0.1549,
      "step": 9660
    },
    {
      "epoch": 2.7915704387990763,
      "grad_norm": 0.5487238168716431,
      "learning_rate": 1.3914549653579678e-05,
      "loss": 0.221,
      "step": 9670
    },
    {
      "epoch": 2.7944572748267897,
      "grad_norm": 2.0259084701538086,
      "learning_rate": 1.3722093918398767e-05,
      "loss": 0.2385,
      "step": 9680
    },
    {
      "epoch": 2.7973441108545036,
      "grad_norm": 2.9400763511657715,
      "learning_rate": 1.352963818321786e-05,
      "loss": 0.1779,
      "step": 9690
    },
    {
      "epoch": 2.800230946882217,
      "grad_norm": 1.968881368637085,
      "learning_rate": 1.3337182448036953e-05,
      "loss": 0.1861,
      "step": 9700
    },
    {
      "epoch": 2.803117782909931,
      "grad_norm": 1.313029170036316,
      "learning_rate": 1.3144726712856043e-05,
      "loss": 0.1977,
      "step": 9710
    },
    {
      "epoch": 2.8060046189376444,
      "grad_norm": 0.8272596001625061,
      "learning_rate": 1.2952270977675136e-05,
      "loss": 0.1446,
      "step": 9720
    },
    {
      "epoch": 2.808891454965358,
      "grad_norm": 1.9981099367141724,
      "learning_rate": 1.2759815242494227e-05,
      "loss": 0.1674,
      "step": 9730
    },
    {
      "epoch": 2.8117782909930717,
      "grad_norm": 0.5598970055580139,
      "learning_rate": 1.256735950731332e-05,
      "loss": 0.1833,
      "step": 9740
    },
    {
      "epoch": 2.814665127020785,
      "grad_norm": 0.9563601016998291,
      "learning_rate": 1.237490377213241e-05,
      "loss": 0.1659,
      "step": 9750
    },
    {
      "epoch": 2.8175519630484986,
      "grad_norm": 0.8068744540214539,
      "learning_rate": 1.2182448036951502e-05,
      "loss": 0.2064,
      "step": 9760
    },
    {
      "epoch": 2.8204387990762125,
      "grad_norm": 1.0031436681747437,
      "learning_rate": 1.1989992301770594e-05,
      "loss": 0.2302,
      "step": 9770
    },
    {
      "epoch": 2.823325635103926,
      "grad_norm": 4.296989440917969,
      "learning_rate": 1.1797536566589685e-05,
      "loss": 0.3319,
      "step": 9780
    },
    {
      "epoch": 2.82621247113164,
      "grad_norm": 1.0535502433776855,
      "learning_rate": 1.1605080831408776e-05,
      "loss": 0.2122,
      "step": 9790
    },
    {
      "epoch": 2.8290993071593533,
      "grad_norm": 1.2334169149398804,
      "learning_rate": 1.1412625096227867e-05,
      "loss": 0.1938,
      "step": 9800
    },
    {
      "epoch": 2.831986143187067,
      "grad_norm": 2.4252843856811523,
      "learning_rate": 1.122016936104696e-05,
      "loss": 0.1665,
      "step": 9810
    },
    {
      "epoch": 2.8348729792147807,
      "grad_norm": 1.2481675148010254,
      "learning_rate": 1.1027713625866051e-05,
      "loss": 0.1879,
      "step": 9820
    },
    {
      "epoch": 2.837759815242494,
      "grad_norm": 2.263279914855957,
      "learning_rate": 1.0835257890685143e-05,
      "loss": 0.1776,
      "step": 9830
    },
    {
      "epoch": 2.840646651270208,
      "grad_norm": 2.8604514598846436,
      "learning_rate": 1.0642802155504236e-05,
      "loss": 0.1804,
      "step": 9840
    },
    {
      "epoch": 2.8435334872979214,
      "grad_norm": 1.36301851272583,
      "learning_rate": 1.0450346420323325e-05,
      "loss": 0.1869,
      "step": 9850
    },
    {
      "epoch": 2.846420323325635,
      "grad_norm": 1.2634689807891846,
      "learning_rate": 1.0257890685142418e-05,
      "loss": 0.1924,
      "step": 9860
    },
    {
      "epoch": 2.8493071593533488,
      "grad_norm": 0.9485814571380615,
      "learning_rate": 1.006543494996151e-05,
      "loss": 0.151,
      "step": 9870
    },
    {
      "epoch": 2.852193995381062,
      "grad_norm": 2.0041744709014893,
      "learning_rate": 9.8729792147806e-06,
      "loss": 0.175,
      "step": 9880
    },
    {
      "epoch": 2.855080831408776,
      "grad_norm": 2.718273639678955,
      "learning_rate": 9.680523479599693e-06,
      "loss": 0.1828,
      "step": 9890
    },
    {
      "epoch": 2.8579676674364896,
      "grad_norm": 1.8464909791946411,
      "learning_rate": 9.488067744418785e-06,
      "loss": 0.1625,
      "step": 9900
    },
    {
      "epoch": 2.8608545034642034,
      "grad_norm": 1.0152686834335327,
      "learning_rate": 9.295612009237876e-06,
      "loss": 0.1877,
      "step": 9910
    },
    {
      "epoch": 2.863741339491917,
      "grad_norm": 2.1775639057159424,
      "learning_rate": 9.103156274056967e-06,
      "loss": 0.2331,
      "step": 9920
    },
    {
      "epoch": 2.8666281755196303,
      "grad_norm": 1.8134889602661133,
      "learning_rate": 8.910700538876058e-06,
      "loss": 0.1643,
      "step": 9930
    },
    {
      "epoch": 2.8695150115473442,
      "grad_norm": 1.7860709428787231,
      "learning_rate": 8.718244803695151e-06,
      "loss": 0.297,
      "step": 9940
    },
    {
      "epoch": 2.8724018475750577,
      "grad_norm": 0.9794937372207642,
      "learning_rate": 8.525789068514243e-06,
      "loss": 0.1969,
      "step": 9950
    },
    {
      "epoch": 2.875288683602771,
      "grad_norm": 1.4755067825317383,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.1829,
      "step": 9960
    },
    {
      "epoch": 2.878175519630485,
      "grad_norm": 2.6462273597717285,
      "learning_rate": 8.140877598152425e-06,
      "loss": 0.2039,
      "step": 9970
    },
    {
      "epoch": 2.8810623556581985,
      "grad_norm": 2.578198194503784,
      "learning_rate": 7.948421862971516e-06,
      "loss": 0.2225,
      "step": 9980
    },
    {
      "epoch": 2.8839491916859123,
      "grad_norm": 2.3805718421936035,
      "learning_rate": 7.755966127790607e-06,
      "loss": 0.1725,
      "step": 9990
    },
    {
      "epoch": 2.886836027713626,
      "grad_norm": 2.803161144256592,
      "learning_rate": 7.5635103926097e-06,
      "loss": 0.177,
      "step": 10000
    },
    {
      "epoch": 2.8897228637413397,
      "grad_norm": 2.720080614089966,
      "learning_rate": 7.3710546574287916e-06,
      "loss": 0.1932,
      "step": 10010
    },
    {
      "epoch": 2.892609699769053,
      "grad_norm": 1.4152064323425293,
      "learning_rate": 7.178598922247884e-06,
      "loss": 0.1721,
      "step": 10020
    },
    {
      "epoch": 2.8954965357967666,
      "grad_norm": 1.3681464195251465,
      "learning_rate": 6.986143187066975e-06,
      "loss": 0.2244,
      "step": 10030
    },
    {
      "epoch": 2.8983833718244805,
      "grad_norm": 1.1221047639846802,
      "learning_rate": 6.793687451886066e-06,
      "loss": 0.2345,
      "step": 10040
    },
    {
      "epoch": 2.901270207852194,
      "grad_norm": 1.7747269868850708,
      "learning_rate": 6.601231716705158e-06,
      "loss": 0.2256,
      "step": 10050
    },
    {
      "epoch": 2.9041570438799074,
      "grad_norm": 1.1111301183700562,
      "learning_rate": 6.408775981524249e-06,
      "loss": 0.1505,
      "step": 10060
    },
    {
      "epoch": 2.9070438799076213,
      "grad_norm": 5.174751281738281,
      "learning_rate": 6.2163202463433415e-06,
      "loss": 0.1797,
      "step": 10070
    },
    {
      "epoch": 2.909930715935335,
      "grad_norm": 1.0904350280761719,
      "learning_rate": 6.023864511162433e-06,
      "loss": 0.1694,
      "step": 10080
    },
    {
      "epoch": 2.9128175519630486,
      "grad_norm": 4.0632004737854,
      "learning_rate": 5.831408775981524e-06,
      "loss": 0.2121,
      "step": 10090
    },
    {
      "epoch": 2.915704387990762,
      "grad_norm": 1.0721904039382935,
      "learning_rate": 5.638953040800616e-06,
      "loss": 0.1504,
      "step": 10100
    },
    {
      "epoch": 2.918591224018476,
      "grad_norm": 0.8493458032608032,
      "learning_rate": 5.446497305619708e-06,
      "loss": 0.1786,
      "step": 10110
    },
    {
      "epoch": 2.9214780600461894,
      "grad_norm": 0.8261533975601196,
      "learning_rate": 5.254041570438799e-06,
      "loss": 0.2499,
      "step": 10120
    },
    {
      "epoch": 2.924364896073903,
      "grad_norm": 1.7858078479766846,
      "learning_rate": 5.061585835257891e-06,
      "loss": 0.1716,
      "step": 10130
    },
    {
      "epoch": 2.9272517321016167,
      "grad_norm": 0.8734239935874939,
      "learning_rate": 4.869130100076983e-06,
      "loss": 0.2137,
      "step": 10140
    },
    {
      "epoch": 2.93013856812933,
      "grad_norm": 4.156388759613037,
      "learning_rate": 4.676674364896074e-06,
      "loss": 0.1762,
      "step": 10150
    },
    {
      "epoch": 2.9330254041570436,
      "grad_norm": 1.2523155212402344,
      "learning_rate": 4.484218629715166e-06,
      "loss": 0.199,
      "step": 10160
    },
    {
      "epoch": 2.9359122401847575,
      "grad_norm": 2.0851829051971436,
      "learning_rate": 4.291762894534258e-06,
      "loss": 0.157,
      "step": 10170
    },
    {
      "epoch": 2.9387990762124714,
      "grad_norm": 1.7216143608093262,
      "learning_rate": 4.099307159353348e-06,
      "loss": 0.1517,
      "step": 10180
    },
    {
      "epoch": 2.941685912240185,
      "grad_norm": 1.0619843006134033,
      "learning_rate": 3.9068514241724404e-06,
      "loss": 0.1683,
      "step": 10190
    },
    {
      "epoch": 2.9445727482678983,
      "grad_norm": 1.244276523590088,
      "learning_rate": 3.714395688991532e-06,
      "loss": 0.2225,
      "step": 10200
    },
    {
      "epoch": 2.947459584295612,
      "grad_norm": 1.2473280429840088,
      "learning_rate": 3.521939953810624e-06,
      "loss": 0.1698,
      "step": 10210
    },
    {
      "epoch": 2.9503464203233256,
      "grad_norm": 1.983153223991394,
      "learning_rate": 3.329484218629715e-06,
      "loss": 0.1815,
      "step": 10220
    },
    {
      "epoch": 2.953233256351039,
      "grad_norm": 0.7868083715438843,
      "learning_rate": 3.137028483448807e-06,
      "loss": 0.1831,
      "step": 10230
    },
    {
      "epoch": 2.956120092378753,
      "grad_norm": 0.8622392416000366,
      "learning_rate": 2.9445727482678987e-06,
      "loss": 0.1877,
      "step": 10240
    },
    {
      "epoch": 2.9590069284064664,
      "grad_norm": 0.9557976722717285,
      "learning_rate": 2.75211701308699e-06,
      "loss": 0.1682,
      "step": 10250
    },
    {
      "epoch": 2.9618937644341803,
      "grad_norm": 1.2238686084747314,
      "learning_rate": 2.559661277906082e-06,
      "loss": 0.1852,
      "step": 10260
    },
    {
      "epoch": 2.9647806004618937,
      "grad_norm": 1.2217886447906494,
      "learning_rate": 2.3672055427251732e-06,
      "loss": 0.2217,
      "step": 10270
    },
    {
      "epoch": 2.9676674364896076,
      "grad_norm": 2.3821139335632324,
      "learning_rate": 2.174749807544265e-06,
      "loss": 0.1429,
      "step": 10280
    },
    {
      "epoch": 2.970554272517321,
      "grad_norm": 2.1394286155700684,
      "learning_rate": 1.9822940723633565e-06,
      "loss": 0.2124,
      "step": 10290
    },
    {
      "epoch": 2.9734411085450345,
      "grad_norm": 1.3783674240112305,
      "learning_rate": 1.7898383371824482e-06,
      "loss": 0.2164,
      "step": 10300
    },
    {
      "epoch": 2.9763279445727484,
      "grad_norm": 2.3197243213653564,
      "learning_rate": 1.5973826020015396e-06,
      "loss": 0.1766,
      "step": 10310
    },
    {
      "epoch": 2.979214780600462,
      "grad_norm": 1.0648902654647827,
      "learning_rate": 1.4049268668206315e-06,
      "loss": 0.369,
      "step": 10320
    },
    {
      "epoch": 2.9821016166281753,
      "grad_norm": 2.6312754154205322,
      "learning_rate": 1.212471131639723e-06,
      "loss": 0.1502,
      "step": 10330
    },
    {
      "epoch": 2.984988452655889,
      "grad_norm": 0.7248427271842957,
      "learning_rate": 1.0200153964588146e-06,
      "loss": 0.1553,
      "step": 10340
    },
    {
      "epoch": 2.9878752886836026,
      "grad_norm": 0.9284637570381165,
      "learning_rate": 8.275596612779062e-07,
      "loss": 0.2539,
      "step": 10350
    },
    {
      "epoch": 2.9907621247113165,
      "grad_norm": 0.7594056129455566,
      "learning_rate": 6.351039260969977e-07,
      "loss": 0.1732,
      "step": 10360
    },
    {
      "epoch": 2.99364896073903,
      "grad_norm": 0.8993295431137085,
      "learning_rate": 4.426481909160893e-07,
      "loss": 0.1968,
      "step": 10370
    },
    {
      "epoch": 2.996535796766744,
      "grad_norm": 1.0719774961471558,
      "learning_rate": 2.5019245573518093e-07,
      "loss": 0.2111,
      "step": 10380
    },
    {
      "epoch": 2.9994226327944573,
      "grad_norm": 2.5095841884613037,
      "learning_rate": 5.773672055427252e-08,
      "loss": 0.1842,
      "step": 10390
    }
  ],
  "logging_steps": 10,
  "max_steps": 10392,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8265491130875904.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
